"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[78096],{603905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>f});var r=a(667294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=r.createContext({}),c=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},m=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,s=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),p=c(a),d=i,f=p["".concat(s,".").concat(d)]||p[d]||u[d]||n;return a?r.createElement(f,l(l({ref:t},m),{},{components:a})):r.createElement(f,l({ref:t},m))}));function f(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,l=new Array(n);l[0]=d;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[p]="string"==typeof e?e:i,l[1]=o;for(var c=2;c<n;c++)l[c]=a[c];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},563194:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>n,metadata:()=>o,toc:()=>c});var r=a(487462),i=(a(667294),a(603905));const n={},l="Linear Discriminant Analysis (LDA)",o={unversionedId:"ai/ml-algorithms/linear-discriminant-analysis-lda",id:"ai/ml-algorithms/linear-discriminant-analysis-lda",title:"Linear Discriminant Analysis (LDA)",description:"Hi, Logistic Regression is a classification algorithm traditionally limited to only two-class classification problems.",source:"@site/docs/ai/ml-algorithms/linear-discriminant-analysis-lda.md",sourceDirName:"ai/ml-algorithms",slug:"/ai/ml-algorithms/linear-discriminant-analysis-lda",permalink:"/ai/ml-algorithms/linear-discriminant-analysis-lda",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/ml-algorithms/linear-discriminant-analysis-lda.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Learning Vector Quantization (LVQ)",permalink:"/ai/ml-algorithms/learning-vector-quantization-lvq"},next:{title:"Linear regression",permalink:"/ai/ml-algorithms/linear-regression"}},s={},c=[],m={toc:c},p="wrapper";function u(e){let{components:t,...a}=e;return(0,i.kt)(p,(0,r.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"linear-discriminant-analysis-lda"},"Linear Discriminant Analysis (LDA)"),(0,i.kt)("p",null,"Hi, Logistic Regression is a classification algorithm traditionally limited to only two-class classification problems."),(0,i.kt)("p",null,"If you have more than two classes then the Linear Discriminant Analysis algorithm is the preferred linear classification technique."),(0,i.kt)("p",null,"The representation of LDA is pretty straight forward. It consists of statistical properties of your data, calculated for each class. For a single input variable this includes:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The mean value for each class.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The variance calculated across all classes."))),(0,i.kt)("p",null,"Predictions are made by calculating a discriminate value for each class and making a prediction for the class with the largest value."),(0,i.kt)("p",null,"The technique assumes that the data has a Gaussian distribution (bell curve), so it is a good idea to remove outliers from your data before hand."),(0,i.kt)("p",null,"It's a simple and powerful method for classification predictive modeling problems."))}u.isMDXComponent=!0}}]);