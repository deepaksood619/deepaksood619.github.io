"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[67200],{603905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var r=n(667294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},s=Object.keys(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,s=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(n),m=o,d=u["".concat(l,".").concat(m)]||u[m]||h[m]||s;return n?r.createElement(d,a(a({ref:t},p),{},{components:n})):r.createElement(d,a({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var s=n.length,a=new Array(s);a[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:o,a[1]=i;for(var c=2;c<s;c++)a[c]=n[c];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},355776:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var r=n(487462),o=(n(667294),n(603905));const s={},a="NGINX",i={unversionedId:"devops/others/servers/nginx/readme",id:"devops/others/servers/nginx/readme",title:"NGINX",description:"Designed to address the C10K problem: How can web servers handle 10,000 clients at the same time. With each new incoming connection, NGINX creates a file descriptor, which consumes less memory than an entire thread or process. Because its architecture is event-driven rather than process-based, NGINX also reduces the need for context switching that occurs in process-per-connection web servers.",source:"@site/docs/devops/others/servers/nginx/readme.md",sourceDirName:"devops/others/servers/nginx",slug:"/devops/others/servers/nginx/",permalink:"/devops/others/servers/nginx/",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/devops/others/servers/nginx/readme.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Gunicorn",permalink:"/devops/others/servers/gunicorn"},next:{title:"Configs",permalink:"/devops/others/servers/nginx/configs"}},l={},c=[{value:"NGINX / HAProxy",id:"nginx--haproxy",level:2},{value:"Installation",id:"installation",level:2},{value:"Improvements",id:"improvements",level:2},{value:"Architecture",id:"architecture",level:2},{value:"nginx 3rd party modules",id:"nginx-3rd-party-modules",level:2},{value:"VTS",id:"vts",level:2},{value:"Others",id:"others",level:2}],p={toc:c},u="wrapper";function h(e){let{components:t,...s}=e;return(0,o.kt)(u,(0,r.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"nginx"},"NGINX"),(0,o.kt)("p",null,"Designed to address the C10K problem: How can web servers handle 10,000 clients at the same time. With each new incoming connection, NGINX creates a file descriptor, which consumes less memory than an entire thread or process. Because its architecture is event-driven rather than process-based, NGINX also reduces the need for context switching that occurs in process-per-connection web servers."),(0,o.kt)("h2",{id:"nginx--haproxy"},"NGINX / HAProxy"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Load balancers"),(0,o.kt)("li",{parentName:"ul"},"Very efficient pings"),(0,o.kt)("li",{parentName:"ul"},"Can manage tens of thousands connection from a client from a single instance")),(0,o.kt)("h2",{id:"installation"},"Installation"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"sudo apt-get update\nsudo apt-get install nginx --yes\nsudo ufw app list\nsudo ufw status\nnginx -v\nsudo systemctl start nginx   #start nginx\nsudo systemctl status nginx  #check status of nginx\ncurl http://127.0.0.1        #test nginx\nsudo systemctl stop nginx    #stop nginx\n\nsudo nginx -t #test the config\nsudo nginx -s reload # reload the config\n")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-16-04"},"https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-16-04")),(0,o.kt)("h2",{id:"improvements"},"Improvements"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"worker_processes - nginx uses a fixed number of workers, each of which handles incoming requests. The general rule of thumb is that you should have one worker for each CPU-core your server contains."),(0,o.kt)("li",{parentName:"ul"},"worker_connections")),(0,o.kt)("p",null,"worker_connectionssets the number of connections every worker process can handle. The default is 512, but it can usually be increased."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"gzip compression"),(0,o.kt)("li",{parentName:"ul"},"Client Caching"),(0,o.kt)("li",{parentName:"ul"},"Filehandle Cache"),(0,o.kt)("li",{parentName:"ul"},"Caching")),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g\ninactive=60m;")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Disable access logs"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Switch from TCP to UNIX domain sockets"))),(0,o.kt)("p",null,"When communicating to processes on the same machine UNIX sockets have better performance the TCP because there's less copying and fewer context switches."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Setup upstream load balancing")),(0,o.kt)("p",null,"Multiple upstream backends on the same machine produce higher throughout than a single one."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Adjust client timeouts."),(0,o.kt)("li",{parentName:"ul"},"Adjust output buffers."),(0,o.kt)("li",{parentName:"ul"},"/etc/sysctl.conf tuning."),(0,o.kt)("li",{parentName:"ul"},"Monitor")),(0,o.kt)("p",null,"Continually monitor the number of open connections, free memory and number of waiting threads and set alerts if thresholds are breached. Install the NGINX stub_status module."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"proxy_buffering off;"),(0,o.kt)("li",{parentName:"ul"},"Nginx recommends pinning the number of workers to number of PC cores (just like we did with Apache's mpm_event configuration), by settingworker_processestoauto(default is 1) in/etc/nginx/nginx.conf.")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"http://www.softwareprojects.com/resources/programming/t-optimizing-nginx-and-php-fpm-for-high-traffic-sites-2081.html"},"http://www.softwareprojects.com/resources/programming/t-optimizing-nginx-and-php-fpm-for-high-traffic-sites-2081.html")),(0,o.kt)("h2",{id:"architecture"},"Architecture"),(0,o.kt)("p",null,"NGINX stands out with an innovative event-driven architecture that allows it to scale to hundreds of thousands of concurrent connections on modern hardware."),(0,o.kt)("p",null,"There's one worker process per core to make efficient use of hardware resources, the ability to interleave multiple connections within a single worker process, and the capability to switch from connection to connection almost instantaneously as network traffic arrives. Put this magic together and you create the massively scalable HTTP application delivery engine that is NGINX."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale"},"https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.aosabook.org/en/nginx.html"},"https://www.aosabook.org/en/nginx.html")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:n(730798).Z,width:"600",height:"1935"})),(0,o.kt)("h2",{id:"nginx-3rd-party-modules"},"nginx 3rd party modules"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.nginx.com/resources/wiki/modules"},"https://www.nginx.com/resources/wiki/modules")),(0,o.kt)("h2",{id:"vts"},"VTS"),(0,o.kt)("p",null,"A virtual host and upstream traffic status module"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://medium.com/@shevtsovav/ready-for-scraping-nginx-metrics-nginx-vts-exporter-prometheus-grafana-26c14816ae7c"},"https://medium.com/@shevtsovav/ready-for-scraping-nginx-metrics-nginx-vts-exporter-prometheus-grafana-26c14816ae7c")),(0,o.kt)("h2",{id:"others"},"Others"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/ingress-nginx"},"https://github.com/kubernetes/ingress-nginx")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.freecodecamp.org/news/the-nginx-handbook"},"https://www.freecodecamp.org/news/the-nginx-handbook")))}h.isMDXComponent=!0},730798:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/DevOps-Others-NGINX-image1-83d82e595e4bb4e7ee7c8e00760e0851.jpg"}}]);