"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[40799],{603905:(e,t,a)=>{a.d(t,{Zo:()=>s,kt:()=>N});var n=a(667294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var m=n.createContext({}),p=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},s=function(e){var t=p(e.components);return n.createElement(m.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},k=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,m=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),u=p(a),k=r,N=u["".concat(m,".").concat(k)]||u[k]||c[k]||i;return a?n.createElement(N,l(l({ref:t},s),{},{components:a})):n.createElement(N,l({ref:t},s))}));function N(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=k;var o={};for(var m in t)hasOwnProperty.call(t,m)&&(o[m]=t[m]);o.originalType=e,o[u]="string"==typeof e?e:r,l[1]=o;for(var p=2;p<i;p++)l[p]=a[p];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}k.displayName="MDXCreateElement"},60161:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>l,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>p});var n=a(487462),r=(a(667294),a(603905));const i={},l="Syllabus",o={unversionedId:"ai/move-37/syllabus",id:"ai/move-37/syllabus",title:"Syllabus",description:"1. Markov Decision Processes",source:"@site/docs/ai/move-37/syllabus.md",sourceDirName:"ai/move-37",slug:"/ai/move-37/syllabus",permalink:"/ai/move-37/syllabus",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/move-37/syllabus.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Reinforcement Learning",permalink:"/ai/move-37/reinforcement-learning"},next:{title:"NLP",permalink:"/ai/nlp/"}},m={},p=[],s={toc:p},u="wrapper";function c(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"syllabus"},"Syllabus"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Markov Decision Processes"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Introduction"),(0,r.kt)("li",{parentName:"ul"},"Sensor Networks"),(0,r.kt)("li",{parentName:"ul"},"Supply Chain Management"),(0,r.kt)("li",{parentName:"ul"},"Energy Efficiency"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Policy Functions)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Bellman Equation)"),(0,r.kt)("li",{parentName:"ul"},"Markov Decision Processes"),(0,r.kt)("li",{parentName:"ul"},"The Bellman Equations"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Dynamic Programming"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Route Planning"),(0,r.kt)("li",{parentName:"ul"},"Options Pricing"),(0,r.kt)("li",{parentName:"ul"},"Scheduling"),(0,r.kt)("li",{parentName:"ul"},"Operating Systems"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (History of DP)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Value Iteration)"),(0,r.kt)("li",{parentName:"ul"},"Dynamic Programming"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Monte Carlo Methods"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Medical Diagnosis"),(0,r.kt)("li",{parentName:"ul"},"Network Routing Optimization"),(0,r.kt)("li",{parentName:"ul"},"Physics Research"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Exploration vs Exploitation)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Greedy Policies)"),(0,r.kt)("li",{parentName:"ul"},"MC Prediction and MC Control"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Model Free Learning"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Delivery Management"),(0,r.kt)("li",{parentName:"ul"},"Automated Trading"),(0,r.kt)("li",{parentName:"ul"},"Backgammon"),(0,r.kt)("li",{parentName:"ul"},"Dopamine in Neuroscience"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (SARSA)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Q Learning)"),(0,r.kt)("li",{parentName:"ul"},"Temporal Difference Learning"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"RL in Continuous Spaces"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Self Driving Cars"),(0,r.kt)("li",{parentName:"ul"},"Delivery Drones"),(0,r.kt)("li",{parentName:"ul"},"Rescue Robots"),(0,r.kt)("li",{parentName:"ul"},"Assembly Robots"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Control Theory)"),(0,r.kt)("li",{parentName:"ul"},"Midterm Assignment (Make a Bipedal Robot Walk )"),(0,r.kt)("li",{parentName:"ul"},"Continuous Space Techniques"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Deep Reinforcement Learning"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Traffic Optimization"),(0,r.kt)("li",{parentName:"ul"},"Gaming"),(0,r.kt)("li",{parentName:"ul"},"Meta Learning"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Deep Q Learning)"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (DQN Improvements)"),(0,r.kt)("li",{parentName:"ul"},"The Evolution of Deep Q Learning"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Policy Based Methods"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Web System Configuration"),(0,r.kt)("li",{parentName:"ul"},"Text Summarization"),(0,r.kt)("li",{parentName:"ul"},"AI Assisted Design"),(0,r.kt)("li",{parentName:"ul"},"Portfolio Optimization"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Evolutionary Algorithms)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (REINFORCE)"),(0,r.kt)("li",{parentName:"ul"},"Stochastic Policy Search"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Policy Gradient Methods"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Dialogue Systems"),(0,r.kt)("li",{parentName:"ul"},"Photo Editing"),(0,r.kt)("li",{parentName:"ul"},"Language Translation"),(0,r.kt)("li",{parentName:"ul"},"Tutoring Systems"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Evolved Policy Gradients)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (TRPO)"),(0,r.kt)("li",{parentName:"ul"},"Generalized Advatange Estimation"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Actor Critic Methods"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Advanced Trading Techniques"),(0,r.kt)("li",{parentName:"ul"},"Human-Machine Cooperation"),(0,r.kt)("li",{parentName:"ul"},"Insurance Cost Analysis"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Actor Critic Algorithms)"),(0,r.kt)("li",{parentName:"ul"},"Homework Assignment (Bayesian Actor Critic)"),(0,r.kt)("li",{parentName:"ul"},"Asynchronous Advantage Actor Critic"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Multi Agent RL"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Move 37"),(0,r.kt)("li",{parentName:"ul"},"Transporation Networks"),(0,r.kt)("li",{parentName:"ul"},"Decentralized Autonomous Organizations"),(0,r.kt)("li",{parentName:"ul"},"The Future of AI"),(0,r.kt)("li",{parentName:"ul"},"Reading Assignment (Cooperative Agents)"),(0,r.kt)("li",{parentName:"ul"},"Inverse Reinforcement Learning"),(0,r.kt)("li",{parentName:"ul"},"Final Project (Multi Agent Research Project)")))))}c.isMDXComponent=!0}}]);