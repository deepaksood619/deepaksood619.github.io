"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[98628],{603905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var i=n(667294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),c=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=c(e.components);return i.createElement(s.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},d=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(n),d=a,h=u["".concat(s,".").concat(d)]||u[d]||m[d]||o;return n?i.createElement(h,r(r({ref:t},p),{},{components:n})):i.createElement(h,r({ref:t},p))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,r=new Array(o);r[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:a,r[1]=l;for(var c=2;c<o;c++)r[c]=n[c];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}d.displayName="MDXCreateElement"},125422:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var i=n(487462),a=(n(667294),n(603905));const o={},r="CV - Libraries / Tools",l={unversionedId:"ai/computer-vision-cv/cv-libraries-tools",id:"ai/computer-vision-cv/cv-libraries-tools",title:"CV - Libraries / Tools",description:"YOLO - You Only Look Once",source:"@site/docs/ai/computer-vision-cv/cv-libraries-tools.md",sourceDirName:"ai/computer-vision-cv",slug:"/ai/computer-vision-cv/cv-libraries-tools",permalink:"/ai/computer-vision-cv/cv-libraries-tools",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/computer-vision-cv/cv-libraries-tools.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Computer Vision",permalink:"/ai/computer-vision-cv/"},next:{title:"Image / Data Labeling Tools",permalink:"/ai/computer-vision-cv/image-data-labeling-tools"}},s={},c=[{value:"YOLO - You Only Look Once",id:"yolo---you-only-look-once",level:2},{value:"SSD - Single Shot MultiBox Detector",id:"ssd---single-shot-multibox-detector",level:2},{value:"OpenCV (CV2)",id:"opencv-cv2",level:2},{value:"Functions",id:"functions",level:2},{value:"MLKit Vision APIs",id:"mlkit-vision-apis",level:2},{value:"Key capabilities",id:"key-capabilities",level:3},{value:"Image Similarity API",id:"image-similarity-api",level:2},{value:"Darknet",id:"darknet",level:2}],p={toc:c},u="wrapper";function m(e){let{components:t,...n}=e;return(0,a.kt)(u,(0,i.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"cv---libraries--tools"},"CV - Libraries / Tools"),(0,a.kt)("h2",{id:"yolo---you-only-look-once"},"YOLO - You Only Look Once"),(0,a.kt)("h2",{id:"ssd---single-shot-multibox-detector"},"SSD - Single Shot MultiBox Detector"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Single Shot:"),"this means that the tasks of object localization and classificationare done in asingleforward passof the network"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"MultiBox:"),"this is the name of a technique for bounding box regression developed by Szegedy et al."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Detector:"),"The network is an object detector that also classifies those detected objects")),(0,a.kt)("h2",{id:"opencv-cv2"},"OpenCV (CV2)"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Most used computer vision library. Highly efficient. Facilitates real-time image processing.")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=P4Z8_qe2Cu0"},"https://www.youtube.com/watch?v=P4Z8_qe2Cu0")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.freecodecamp.org/news/opencv-full-course"},"https://www.freecodecamp.org/news/opencv-full-course")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.freecodecamp.org/news/how-to-use-opencv-and-python-for-computer-vision-and-ai"},"https://www.freecodecamp.org/news/how-to-use-opencv-and-python-for-computer-vision-and-ai")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://learnopencv.com"},"https://learnopencv.com")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://opencv.org"},"https://opencv.org")),(0,a.kt)("p",null,"pip install opencv-python"),(0,a.kt)("h2",{id:"functions"},"Functions"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\n\ncv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\ncv2.Canny(blur_gray, low_threshold, high_threshold)\n\ncv2.GaussianBlur(gray,(kernel_size, kernel_size), 0)\n\ncv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n")),(0,a.kt)("p",null,"First off, rho and theta are the distance and angular resolution of our grid in Hough space. Remember that, in Hough space, we have a grid laid out along the (\u0398, \u03c1) axis. You need to specifyrhoin units of pixels andthetain units of radians."),(0,a.kt)("p",null,"Thethresholdparameter specifies the minimum number of votes (intersections in a given grid cell) a candidate line needs to have to make it into the output."),(0,a.kt)("p",null,"min_line_lengthis the minimum length of a line (in pixels) that you will accept in the output, andmax_line_gapis the maximum distance (again, in pixels) between segments that you will allow to be connected into a single line."),(0,a.kt)("h2",{id:"mlkit-vision-apis"},"MLKit Vision APIs"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Barcode scanning"),(0,a.kt)("li",{parentName:"ul"},"Face detection")),(0,a.kt)("p",null,"With ML Kit's face detection API, you can detect faces in an image, identify key facial features, and get the contours of detected faces. Note that the APIdetects faces, it does notrecognize people."),(0,a.kt)("p",null,"With face detection, you can get the information you need to perform tasks like embellishing selfies and portraits, or generating avatars from a user's photo. Because ML Kit can perform face detection in real time, you can use it in applications like video chat or games that respond to the player's expressions."),(0,a.kt)("h3",{id:"key-capabilities"},"Key capabilities"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Recognize and locate facial features. Get the coordinates of the eyes, ears, cheeks, nose, and mouth of every face detected."),(0,a.kt)("li",{parentName:"ul"},"Get the contours of facial features Get the contours of detected faces and their eyes, eyebrows, lips, and nose."),(0,a.kt)("li",{parentName:"ul"},"Recognize facial expressions Determine whether a person is smiling or has their eyes closed."),(0,a.kt)("li",{parentName:"ul"},"Track faces across video frames Get an identifier for each unique detected face. The identifier is consistent across invocations, so you can perform image manipulation on a particular person in a video stream."),(0,a.kt)("li",{parentName:"ul"},"Process video frames in real time Face detection is performed on the device, and is fast enough to be used in real-time applications, such as video manipulation.")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://developers.google.com/ml-kit/vision/face-detection"},"https://developers.google.com/ml-kit/vision/face-detection")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/ipazc/mtcnn"},"https://github.com/ipazc/mtcnn")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/ageitgey/face_recognition"},"https://github.com/ageitgey/face_recognition")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.pyimagesearch.com/2019/03/11/liveness-detection-with-opencv"},"https://www.pyimagesearch.com/2019/03/11/liveness-detection-with-opencv")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Image labeling"),(0,a.kt)("li",{parentName:"ul"},"Object detection and tracking"),(0,a.kt)("li",{parentName:"ul"},"Text recognition"),(0,a.kt)("li",{parentName:"ul"},"Digital ink recognition"),(0,a.kt)("li",{parentName:"ul"},"Pose detection")),(0,a.kt)("h2",{id:"image-similarity-api"},"Image Similarity API"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://deepai.org/machine-learning-model/image-similarity"},"https://deepai.org/machine-learning-model/image-similarity")),(0,a.kt)("h2",{id:"darknet"},"Darknet"),(0,a.kt)("p",null,"Convolutional Neural Networks"),(0,a.kt)("p",null,"YOLOv4 / Scaled-YOLOv4 / YOLO - Neural Networks for Object Detection (Windows and Linux version of Darknet)"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/pjreddie/darknet"},"https://github.com/pjreddie/darknet")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/AlexeyAB/darknet"},"https://github.com/AlexeyAB/darknet")),(0,a.kt)("p",null,"Pillow - images/Python Imaging Library"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://python-pillow.org"},"https://python-pillow.org")))}m.isMDXComponent=!0}}]);