"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[52774],{603905:(t,e,n)=>{n.d(e,{Zo:()=>d,kt:()=>g});var a=n(667294);function r(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function i(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,a)}return n}function l(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?i(Object(n),!0).forEach((function(e){r(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function o(t,e){if(null==t)return{};var n,a,r=function(t,e){if(null==t)return{};var n,a,r={},i=Object.keys(t);for(a=0;a<i.length;a++)n=i[a],e.indexOf(n)>=0||(r[n]=t[n]);return r}(t,e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(t);for(a=0;a<i.length;a++)n=i[a],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(r[n]=t[n])}return r}var s=a.createContext({}),p=function(t){var e=a.useContext(s),n=e;return t&&(n="function"==typeof t?t(e):l(l({},e),t)),n},d=function(t){var e=p(t.components);return a.createElement(s.Provider,{value:e},t.children)},m="mdxType",u={inlineCode:"code",wrapper:function(t){var e=t.children;return a.createElement(a.Fragment,{},e)}},c=a.forwardRef((function(t,e){var n=t.components,r=t.mdxType,i=t.originalType,s=t.parentName,d=o(t,["components","mdxType","originalType","parentName"]),m=p(n),c=r,g=m["".concat(s,".").concat(c)]||m[c]||u[c]||i;return n?a.createElement(g,l(l({ref:e},d),{},{components:n})):a.createElement(g,l({ref:e},d))}));function g(t,e){var n=arguments,r=e&&e.mdxType;if("string"==typeof t||r){var i=n.length,l=new Array(i);l[0]=c;var o={};for(var s in e)hasOwnProperty.call(e,s)&&(o[s]=e[s]);o.originalType=t,o[m]="string"==typeof t?t:r,l[1]=o;for(var p=2;p<i;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},367834:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>p});var a=n(487462),r=(n(667294),n(603905));const i={},l="NLTK",o={unversionedId:"ai/nlp/nltk",id:"ai/nlp/nltk",title:"NLTK",description:"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing.",source:"@site/docs/ai/nlp/nltk.md",sourceDirName:"ai/nlp",slug:"/ai/nlp/nltk",permalink:"/ai/nlp/nltk",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/nlp/nltk.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"NLP Concepts",permalink:"/ai/nlp/nlp-concepts"},next:{title:"Numpy",permalink:"/ai/numpy/"}},s={},p=[{value:"Commands",id:"commands",level:2},{value:"NLTK&#39;s Frequency Distributionss",id:"nltks-frequency-distributionss",level:3},{value:"Corpus",id:"corpus",level:3},{value:"Others",id:"others",level:2},{value:"python - indian-namematch 1.3.0",id:"python---indian-namematch-130",level:3}],d={toc:p},m="wrapper";function u(t){let{components:e,...i}=t;return(0,r.kt)(m,(0,a.Z)({},d,i,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"nltk"},"NLTK"),(0,r.kt)("p",null,"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing."),(0,r.kt)("p",null,"NLTK supports classification, tokenization, stemming ",(0,r.kt)("strong",{parentName:"p"},"(lemmatization better than stemming)"),", tagging, parsing, and semantic reasoning functionalities."),(0,r.kt)("p",null,"Library highlights"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Lexical_analysis"},"Lexical analysis"),": Word and text tokenizer"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/N-gram"},"n-gram")," and collocations"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Part-of-speech_tagging"},"Part-of-speech tagger")),(0,r.kt)("li",{parentName:"ul"},"Tree model and Text",(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Chunking_(computational_linguistics)"},"chunker")," for capturing"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Named-entity_recognition"},"Named-entity recognition"))),(0,r.kt)("h2",{id:"commands"},"Commands"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import nltk\nnltk.download()\n\nfrom nltk.book import *\ntext1\nlen(text6)\ntexts()\nsents()\n    The sents() function divides the text up into its sentences, where each sentence is a list of words\n\ntext1.concordance("monstrous") #A concordance view shows us every occurrence of a given word, together with some context\ntext2.similar("monstrous")\ntext2.common_contexts(["monstrous", "very"])\ntext4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])\ntext6.dispersion_plot(["Arthur", "Holy", "Grail"])\ntext6.generate()\ntext6.count("Grail")\ntext6.count("grail")\nfdist1 = FreqDist(text1)\nfdist1.most_common(50)\nfdist1.plot(50, cumulative=True)\n\ncfd = nltk.ConditionalFreqDist(\n...           (genre, word)\n...           for genre in brown.categories()\n...           for word in brown.words(categories=genre))\ngenres = [\'news\', \'religion\', \'hobbies\', \'science_fiction\', \'romance\', \'humor\']\nmodals = [\'can\', \'could\', \'may\', \'might\', \'must\', \'will\']\ncfd.tabulate(conditions=genres, samples=modals)\n')),(0,r.kt)("h3",{id:"nltks-frequency-distributionss"},"NLTK's Frequency Distributionss"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Example")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Description")))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist = FreqDist(samples)"),(0,r.kt)("td",{parentName:"tr",align:null},"create a frequency distribution containing the given samples")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist","[sample]"," += 1"),(0,r.kt)("td",{parentName:"tr",align:null},"increment the count for this sample")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist","['monstrous']"),(0,r.kt)("td",{parentName:"tr",align:null},"count of the number of times a given sample occurred")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.freq('monstrous')"),(0,r.kt)("td",{parentName:"tr",align:null},"frequency of a given sample")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.N()"),(0,r.kt)("td",{parentName:"tr",align:null},"total number of samples")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.most_common(n)"),(0,r.kt)("td",{parentName:"tr",align:null},"the n most common samples and their frequencies")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"for sample in fdist:"),(0,r.kt)("td",{parentName:"tr",align:null},"iterate over the samples")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.max()"),(0,r.kt)("td",{parentName:"tr",align:null},"sample with the greatest count")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.tabulate()"),(0,r.kt)("td",{parentName:"tr",align:null},"tabulate the frequency distribution")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.plot()"),(0,r.kt)("td",{parentName:"tr",align:null},"graphical plot of the frequency distribution")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist.plot(cumulative=True)"),(0,r.kt)("td",{parentName:"tr",align:null},"cumulative plot of the frequency distribution")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist1"),(0,r.kt)("td",{parentName:"tr",align:null},"= fdist2")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fdist1 < fdist2"),(0,r.kt)("td",{parentName:"tr",align:null},"test if samples in fdist1 occur less frequently than in fdist2")))),(0,r.kt)("h3",{id:"corpus"},"Corpus"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"nltk.chat.chatbots()\nnltk.corpus.gutenberg.fileids()\nemma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\nlen(gutenberg.raw('austen-emma.txt'))\n    The raw() function gives us the contents of the file without any linguistic processing.\n\nfrom nltk.corpus import webtext\nwebtext.fileids()\n\nfrom nltk.corpus import nps_chat\nnps_chat.posts('10-19-20s_706posts.xml')\n\nThe Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics.\nfirst million-word electronic corpus of English\nfrom nltk.corpus import brown\nbrown.categories()\nbrown.words(categories='news')\nbrown.words(fileids=['cg22'])\nbrown.sents(categories=['news', 'editorial', 'reviews'])\n\nfrom nltk.corpus import reuters\nreuters.fileids()\nreuters.categories()\nreuters.categories(['training/9865', 'training/9880'])\n\nfrom nltk.corpus import inaugural\ninaugural.fileids()\ncfd = nltk.ConditionalFreqDist(\n...           (target, fileid[:4])\n...           for fileid in inaugural.fileids()\n...           for w in inaugural.words(fileid)\n...           for target in ['america', 'citizen']\n...           if w.lower().startswith(target))\ncfd.plot()\nnltk.corpus.indian.words('hindi.pos')\nnltk.corpus.cess_esp.words()\nnltk.corpus.floresta.words()\nnltk.corpus.udhr.fileids() #univeral declaration of human rights in 300 languages\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"image",src:n(721965).Z,width:"1100",height:"245"})),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Example")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Description")))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fileids()"),(0,r.kt)("td",{parentName:"tr",align:null},"the files of the corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"fileids(","[categories]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the files of the corpus corresponding to these categories")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"categories()"),(0,r.kt)("td",{parentName:"tr",align:null},"the categories of the corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"categories(","[fileids]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the categories of the corpus corresponding to these files")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"raw()"),(0,r.kt)("td",{parentName:"tr",align:null},"the raw content of the corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"raw(fileids=","[f1,f2,f3]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the raw content of the specified files")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"raw(categories=","[c1,c2]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the raw content of the specified categories")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"words()"),(0,r.kt)("td",{parentName:"tr",align:null},"the words of the whole corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"words(fileids=","[f1,f2,f3]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the words of the specified fileids")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"words(categories=","[c1,c2]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the words of the specified categories")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"sents()"),(0,r.kt)("td",{parentName:"tr",align:null},"the sentences of the whole corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"sents(fileids=","[f1,f2,f3]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the sentences of the specified fileids")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"sents(categories=","[c1,c2]",")"),(0,r.kt)("td",{parentName:"tr",align:null},"the sentences of the specified categories")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"abspath(fileid)"),(0,r.kt)("td",{parentName:"tr",align:null},"the location of the given file on disk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"encoding(fileid)"),(0,r.kt)("td",{parentName:"tr",align:null},"the encoding of the file (if known)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"open(fileid)"),(0,r.kt)("td",{parentName:"tr",align:null},"open a stream for reading the given corpus file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"root"),(0,r.kt)("td",{parentName:"tr",align:null},"if the path to the root of locally installed corpus")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"readme()"),(0,r.kt)("td",{parentName:"tr",align:null},"if the path to the root of locally installed corpus the contents of the README file of the corpus")))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/nltk/nltk"},"https://github.com/nltk/nltk")),(0,r.kt)("h2",{id:"others"},"Others"),(0,r.kt)("h3",{id:"python---indian-namematch-130"},"python - indian-namematch 1.3.0"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://pypi.org/project/indian-namematch"},"https://pypi.org/project/indian-namematch")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e"},"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e")))}u.isMDXComponent=!0},721965:(t,e,n)=>{n.d(e,{Z:()=>a});const a=n.p+"assets/images/NLP_NLTK-image1-4b5a5ce00ba5805513a93673231690cd.jpg"}}]);