"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[79611],{603905:(e,n,a)=>{a.d(n,{Zo:()=>c,kt:()=>m});var t=a(667294);function o(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){o(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function s(e,n){if(null==e)return{};var a,t,o=function(e,n){if(null==e)return{};var a,t,o={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(o[a]=e[a]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var i=t.createContext({}),d=function(e){var n=t.useContext(i),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},c=function(e){var n=d(e.components);return t.createElement(i.Provider,{value:n},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},f=t.forwardRef((function(e,n){var a=e.components,o=e.mdxType,r=e.originalType,i=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=d(a),f=o,m=p["".concat(i,".").concat(f)]||p[f]||u[f]||r;return a?t.createElement(m,l(l({ref:n},c),{},{components:a})):t.createElement(m,l({ref:n},c))}));function m(e,n){var a=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=a.length,l=new Array(r);l[0]=f;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s[p]="string"==typeof e?e:o,l[1]=s;for(var d=2;d<r;d++)l[d]=a[d];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}f.displayName="MDXCreateElement"},517468:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var t=a(487462),o=(a(667294),a(603905));const r={},l="CheatSheet",s={unversionedId:"ai/pandas/cheatsheet",id:"ai/pandas/cheatsheet",title:"CheatSheet",description:"Importing data",source:"@site/docs/ai/pandas/cheatsheet.md",sourceDirName:"ai/pandas",slug:"/ai/pandas/cheatsheet",permalink:"/ai/pandas/cheatsheet",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/pandas/cheatsheet.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Pandas",permalink:"/ai/pandas/"},next:{title:"Commands",permalink:"/ai/pandas/commands"}},i={},d=[{value:"Importing data",id:"importing-data",level:2},{value:"Exporting data",id:"exporting-data",level:2},{value:"Create test objects",id:"create-test-objects",level:2},{value:"Useful for testing",id:"useful-for-testing",level:3},{value:"Viewing/inspecting data",id:"viewinginspecting-data",level:2},{value:"Selection",id:"selection",level:2},{value:"Data cleaning",id:"data-cleaning",level:2},{value:"Conversions",id:"conversions",level:2},{value:"Filter, sort &amp; groupby",id:"filter-sort--groupby",level:2},{value:"Join/Combine",id:"joincombine",level:2},{value:"Statistics",id:"statistics",level:2},{value:"Series",id:"series",level:2}],c={toc:d},p="wrapper";function u(e){let{components:n,...r}=e;return(0,o.kt)(p,(0,t.Z)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"cheatsheet"},"CheatSheet"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.kaggle.com/grroverpr/pandas-cheatsheet"},"https://www.kaggle.com/grroverpr/pandas-cheatsheet")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df # A pandas DataFrame object\n\ns # A pandas Series object\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_rows = 100\n")),(0,o.kt)("h2",{id:"importing-data"},"Importing data"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"pd.read_csv(filename) # From a CSV file\npd.read_table(filename) # From a delimited text file (like TSV)\npd.read_excel(filename) # From an Excel file\npd.read_sql(query, connection_object) # Reads from a SQL table/database\npd.read_json(json_string) # Reads from a JSON formatted string, URL or file\npd.read_html(url) # Parses an html URL, string or file and extracts tables to a list of dataframes\npd.read_clipboard() # Takes the contents of your clipboard and passes it to read_table()\npd.DataFrame(dict) # From a dict, keys for columns names, values for data as lists\n")),(0,o.kt)("h2",{id:"exporting-data"},"Exporting data"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df.to_csv(filename) # Writes to a CSV file\ndf.to_excel(filename) # Writes to an Excel file\ndf.to_sql(table_name, connection_object) # Writes to a SQL table\ndf.to_json(filename) # Writes to a file in JSON format\ndf.to_html(filename) # Saves as an HTML table\ndf.to_clipboard() # Writes to the clipboard\n")),(0,o.kt)("h2",{id:"create-test-objects"},"Create test objects"),(0,o.kt)("h3",{id:"useful-for-testing"},"Useful for testing"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"pd.DataFrame(np.random.rand(20,5)) # 5 columns and 20 rows of random floats\npd.Series(my_list) # Creates a series from an iterable my_list\ndf.index = pd.date_range('1900/1/30', periods=df.shape[0]) # Adds a date index\n")),(0,o.kt)("h2",{id:"viewinginspecting-data"},"Viewing/inspecting data"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df.head(n) # First n rows of the DataFrame\ndf.tail(n) # Last n rows of the DataFrame\ndf.shape() # Number of rows and columns\ndf.info(verbose=True) # Index, Datatype and Memory information\ndf.describe() # Summary statistics for numerical columns\n    df.describe().apply(lambda x: format(x, 'f')) # remove scientific notation\ndf.columns.values\ndf['loan_staus].unique()\ns.value_counts(dropna=False) # Views unique values and columns\ndf.apply(pd.Series.value_counts) # Unique values and counts for all columns\n")),(0,o.kt)("h2",{id:"selection"},"Selection"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df[col] # Returns column with label col as Series\ndf[col1, col2] # Returns Columns as a new DataFrame\ns.iloc[0] # Selection by position\ns.loc[0] # Selection by index\n    df.loc[:, ['earliest_cr_line', 'earliest_cr_line_date', 'mnths_since_earliest_cr_line']][df['mnths_since_earliest_cr_line'] < 100]\ndf.iloc[0,:] # First row\ndf.iloc[0,0] # First element of first column\ndf.isin(['a','b','c'])\nnp.where(condition, value if true, value if false)\n    Checks if a condition is true, returns a specifed value if the condition is true or another specified value if the condition is false\n    df['good_bad'] = np.where(df['loan_status'].isin(['Charged Off',\n                                                        'Late (31-120 days)',\n                                                        'Does not meet the credit policy. Status:Charged Off',\n                                            'Default']), 0, 1)\n")),(0,o.kt)("h2",{id:"data-cleaning"},"Data cleaning"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df.columns = ['a','b','c'] # Renames columns\npd.isnull() # Checks for null values, Returns Boolean Array\npd.notnull() # Opposite of s.isnull()\ndf.dropna() # Drops all rows that contain null values\ndf.dropna(axis=1) # Drops all columns that contain null values\ndf.dropna(axis=1,thresh=n) # Drops all rows have less than n non null values\ndf.fillna(s.mean()) # Replaces all null values with the mean (mean can be replaced with almost any function from the statistics section)\ns.astype(float) # Converts the datatype of the series to float\ns.replace(1, 'one') # Replaces all values equal to 1 with 'one'\ns.replace([1,3],['one','three']) # Replaces all 1 with 'one' and 3 with 'three'\ndf.rename(columns=lambda x: x+1) # Mass renaming of columns\ndf.rename(columns={'old_name': 'new_name'}) # Selective renaming\ndf.set_index('column_one') # Changes the index\ndf.rename(index=lambda x: x+1) # Mass renaming of index\n")),(0,o.kt)("h2",{id:"conversions"},"Conversions"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"pd.to_numeric(df['col_name']\npd.to_datetime(df['col_name'])\npd.get_dummies(df['grade'], prefix='grade', prefix_sep = ':')\n")),(0,o.kt)("h2",{id:"filter-sort--groupby"},"Filter, sort & groupby"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df[df[col] > 0.5] # Rows where the col column is greater than 0.5\ndf[(df[col] > 0.5) & (df[col] < 0.7)] # Rows where 0.7 > col > 0.5\ndf.sort_values(col1) # Sorts values by col1 in ascending order\ndf.sort_values(col2, ascending=False) # Sorts values by col2 in descending order\ndf.sort_values([col1, col2], ascending=[True,False]) # Sorts values by col1 in ascending order then col2 in descending order\ndf.groupby(col) # Returns a groupby object for values from one column\ndf.groupby([col1, col2]) # Returns a groupby object values from multiple columns\ndf.groupby(col1)[col2].mean() # Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\ndf.pivot_table(index=col1, values=[col2,col3],aggfunc=mean) # Creates a pivot table that groups by col1 and calculates the mean of col2 and col3\ndf.groupby(col1).agg(np.mean) # Finds the average across all columns for every unique column 1 group\ndf.apply(np.mean) # Applies a function across each column\ndf.apply(np.max,  axis=1) # Applies a function across each row\n")),(0,o.kt)("h2",{id:"joincombine"},"Join/Combine"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df1.append(df2) # Adds the rows in df1 to the end of df2 (columns should be identical)\npd.concat([df1, df2], axis=1) # Adds the columns in df1 to the end of df2 (rows should be identical)\ndf1.join(df2, on=col1, how='inner') # SQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'\n")),(0,o.kt)("h2",{id:"statistics"},"Statistics"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"These can all be applied to a series as well")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"df.mean() # Returns the mean of all columns\ndf.corr() # Returns the correlation between columns in a DataFrame\ndf.count() # Returns the number of non-null values in each DataFrame column\ndf.max() # Returns the highest value in each column\ndf.min() # Returns the lowest value in each column\ndf.median() # Returns the median of each column\ndf.std() # Returns the standard deviation of each column\n")),(0,o.kt)("p",null,"The pandas library is built on NumPy and provides easy-to-use data structures and data analysis tools for the Python programming language."),(0,o.kt)("h2",{id:"series"},"Series"),(0,o.kt)("p",null,"A one-dimensional labeled array capable of holding any data type"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"s = pd.Series([3,-5,7,4], index=['a','b','c','d'])")),(0,o.kt)("p",null,"DataFrame"),(0,o.kt)("p",null,"A two-dimensional labeled data structure with columns of potentially different types"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:a(765070).Z,width:"1683",height:"1190"})),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image",src:a(620238).Z,width:"1683",height:"1190"})))}u.isMDXComponent=!0},765070:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/CheatSheet-image1-1f2748487727068c06555f0188d213c1.jpg"},620238:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/CheatSheet-image2-a5b7308e6921bd5b75dd657b686d9aaa.jpg"}}]);