"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[10251],{603905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>d});var r=a(667294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),l=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=l(e.components);return r.createElement(s.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),u=l(a),m=n,d=u["".concat(s,".").concat(m)]||u[m]||h[m]||i;return a?r.createElement(d,o(o({ref:t},c),{},{components:a})):r.createElement(d,o({ref:t},c))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,o=new Array(i);o[0]=m;var p={};for(var s in t)hasOwnProperty.call(t,s)&&(p[s]=t[s]);p.originalType=e,p[u]="string"==typeof e?e:n,o[1]=p;for(var l=2;l<i;l++)o[l]=a[l];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}m.displayName="MDXCreateElement"},783986:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>p,toc:()=>l});var r=a(487462),n=(a(667294),a(603905));const i={},o="Others",p={unversionedId:"technologies/apache/others",id:"technologies/apache/others",title:"Others",description:"Apache Tez",source:"@site/docs/technologies/apache/others.md",sourceDirName:"technologies/apache",slug:"/technologies/apache/others",permalink:"/technologies/apache/others",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/technologies/apache/others.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Data Pipeline Architecture",permalink:"/technologies/apache/data-pipeline-architecture"},next:{title:"Brokers",permalink:"/technologies/brokers/"}},s={},l=[{value:"Apache Tez",id:"apache-tez",level:2},{value:"Apache Spark",id:"apache-spark",level:2},{value:"Features",id:"features",level:3},{value:"Apache Superset",id:"apache-superset",level:2},{value:"Features",id:"features-1",level:3},{value:"Apache Beam",id:"apache-beam",level:2},{value:"Apache Storm",id:"apache-storm",level:2},{value:"Apache Flink- Stateful Computations over Data Streams",id:"apache-flink--stateful-computations-over-data-streams",level:2},{value:"Apache OpenWhisk (Incubating)",id:"apache-openwhisk-incubating",level:2},{value:"Architecture",id:"architecture",level:2}],c={toc:l},u="wrapper";function h(e){let{components:t,...i}=e;return(0,n.kt)(u,(0,r.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"others"},"Others"),(0,n.kt)("h2",{id:"apache-tez"},"Apache Tez"),(0,n.kt)("p",null,"The Apache TEZ\xae project is aimed at building an application framework which allows for a complex directed-acyclic-graph of tasks for processing data. It is currently built atop ",(0,n.kt)("a",{parentName:"p",href:"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html"},"Apache Hadoop YARN"),"."),(0,n.kt)("p",null,"The 2 main design themes for Tez are:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Empowering end users by:"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Expressive dataflow definition APIs"),(0,n.kt)("li",{parentName:"ul"},"Flexible Input-Processor-Output runtime model"),(0,n.kt)("li",{parentName:"ul"},"Data type agnostic"),(0,n.kt)("li",{parentName:"ul"},"Simplifying deployment"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Execution Performance"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Performance gains over Map Reduce"),(0,n.kt)("li",{parentName:"ul"},"Optimal resource management"),(0,n.kt)("li",{parentName:"ul"},"Plan reconfiguration at runtime"),(0,n.kt)("li",{parentName:"ul"},"Dynamic physical data flow decisions")))),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"http://tez.apache.org"},"http://tez.apache.org")),(0,n.kt)("h2",{id:"apache-spark"},"Apache Spark"),(0,n.kt)("p",null,"Apache Sparkis an ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Open-source_software"},"open-source")," distributed general-purpose ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Cluster_computing"},"cluster-computing"),(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Software_framework"},"framework"),". Spark provides an ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Application_programming_interface"},"interface")," for programming entire clusters with implicit ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Data_parallelism"},"data parallelism")," and ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Fault_tolerance"},"fault tolerance")),(0,n.kt)("h3",{id:"features"},"Features"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Scatter/gather paradigm (similar to MapReduce)"),(0,n.kt)("li",{parentName:"ul"},"More general data model (RDDs, DataSets)"),(0,n.kt)("li",{parentName:"ul"},"More general programming model (transform/action)"),(0,n.kt)("li",{parentName:"ul"},"Storage agnostic"),(0,n.kt)("li",{parentName:"ul"},"Faster version of MapReduce(does all the mapreduce in-memory)")),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Apache_Spark"},"https://en.wikipedia.org/wiki/Apache_Spark")),(0,n.kt)("h2",{id:"apache-superset"},"Apache Superset"),(0,n.kt)("p",null,"Modern, enterprise-ready business intelligence web application"),(0,n.kt)("h3",{id:"features-1"},"Features"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"A rich set of data visualizations"),(0,n.kt)("li",{parentName:"ul"},"An easy-to-use interface for exploring and visualizing data"),(0,n.kt)("li",{parentName:"ul"},"Create and share dashboards"),(0,n.kt)("li",{parentName:"ul"},"Enterprise-ready authentication with integration with major authentication providers (database, OpenID, LDAP, OAuth & REMOTE_USER through Flask AppBuilder)"),(0,n.kt)("li",{parentName:"ul"},"An extensible, high-granularity security/permission model allowing intricate rules on who can access individual features and the dataset"),(0,n.kt)("li",{parentName:"ul"},"A simple semantic layer, allowing users to control how data sources are displayed in the UI by defining which fields should show up in which drop-down and which aggregation and function metrics are made available to the user"),(0,n.kt)("li",{parentName:"ul"},"Integration with most SQL-speaking RDBMS through SQLAlchemy"),(0,n.kt)("li",{parentName:"ul"},"Deep integration with Druid.io")),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://superset.incubator.apache.org/index.html"},"https://superset.incubator.apache.org/index.html")),(0,n.kt)("h2",{id:"apache-beam"},"Apache Beam"),(0,n.kt)("p",null,"An advanced unified programming model"),(0,n.kt)("p",null,"Implement batch and streaming data processing jobs that run on any execution engine."),(0,n.kt)("h2",{id:"apache-storm"},"Apache Storm"),(0,n.kt)("p",null,"Apache Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language."),(0,n.kt)("p",null,"Storm has many use cases: realtime analytics, online machine learning, continuous computation, distributed RPC, ETL, and more. Storm is fast: a benchmark clocked it at overa million tuples processed per second per node. It is scalable, fault-tolerant, guarantees your data will be processed, and is easy to set up and operate."),(0,n.kt)("p",null,"Storm integrates with the queueing and database technologies you already use. A Storm topology consumes streams of data and processes those streams in arbitrarily complex ways, repartitioning the streams between each stage of the computation however needed."),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"http://storm.apache.org"},"http://storm.apache.org")),(0,n.kt)("h2",{id:"apache-flink--stateful-computations-over-data-streams"},"Apache Flink- Stateful Computations over Data Streams"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:a(93028).Z,width:"1523",height:"500"})),(0,n.kt)("p",null,"Apache Flink is a framework and distributed processing engine for stateful computations over",(0,n.kt)("em",{parentName:"p"},"unbounded and bounded"),"data streams. Flink has been designed to run in",(0,n.kt)("em",{parentName:"p"},"all common cluster environments"),", perform computations at",(0,n.kt)("em",{parentName:"p"},"in-memory speed"),"and at",(0,n.kt)("em",{parentName:"p"},"any scale"),"."),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://flink.apache.org/flink-architecture.html"},"https://flink.apache.org/flink-architecture.html")),(0,n.kt)("h2",{id:"apache-openwhisk-incubating"},"Apache OpenWhisk (Incubating)"),(0,n.kt)("p",null,"Apache OpenWhisk (Incubating) is an open source, distributed ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Serverless_computing"},"Serverless")," platform that executes functions (fx) in response to events at any scale. OpenWhisk manages the infrastructure, servers and scaling using Docker containers so you can focus on building amazing and efficient applications."),(0,n.kt)("p",null,"The OpenWhisk platform supports a programming model in which developers write functional logic (called ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/incubator-openwhisk/blob/master/docs/actions#openwhisk-actions"},"Actions"),"), in any supported programming language, that can be dynamically scheduled and run in response to associated events (via ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/incubator-openwhisk/blob/master/docs/triggers_rules#creating-triggers-and-rules"},"Triggers"),") from external sources (",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/incubator-openwhisk/blob/master/docs/feeds#implementing-feeds"},"Feeds"),") or from HTTP requests. The project includes a REST API-based Command Line Interface (CLI) along with other tooling to support packaging, catalog services and many popular container deployment options."),(0,n.kt)("h2",{id:"architecture"},"Architecture"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"image",src:a(166536).Z,width:"738",height:"596"})),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://openwhisk.apache.org"},"https://openwhisk.apache.org")))}h.isMDXComponent=!0},93028:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/Technologies-Apache-Others-image1-13920b1f23cfa5c2bbfdfba441aca5df.jpg"},166536:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/Technologies-Apache-Others-image2-fd3f9722c8dc25fff4e78406939b7c96.jpg"}}]);