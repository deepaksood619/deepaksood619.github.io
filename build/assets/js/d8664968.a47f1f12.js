"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[90110],{603905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var s=a(667294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);t&&(s=s.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,s)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,s,r=function(e,t){if(null==e)return{};var a,s,r={},n=Object.keys(e);for(s=0;s<n.length;s++)a=n[s],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(s=0;s<n.length;s++)a=n[s],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var u=s.createContext({}),l=function(e){var t=s.useContext(u),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=l(e.components);return s.createElement(u.Provider,{value:t},e.children)},p="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return s.createElement(s.Fragment,{},t)}},m=s.forwardRef((function(e,t){var a=e.components,r=e.mdxType,n=e.originalType,u=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=l(a),m=r,h=p["".concat(u,".").concat(m)]||p[m]||c[m]||n;return a?s.createElement(h,o(o({ref:t},d),{},{components:a})):s.createElement(h,o({ref:t},d))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=a.length,o=new Array(n);o[0]=m;var i={};for(var u in t)hasOwnProperty.call(t,u)&&(i[u]=t[u]);i.originalType=e,i[p]="string"==typeof e?e:r,o[1]=i;for(var l=2;l<n;l++)o[l]=a[l];return s.createElement.apply(null,o)}return s.createElement.apply(null,a)}m.displayName="MDXCreateElement"},717107:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>o,default:()=>c,frontMatter:()=>n,metadata:()=>i,toc:()=>l});var s=a(487462),r=(a(667294),a(603905));const n={},o="Redis Queues",i={unversionedId:"databases/nosql-databases/redis/redis-queues",id:"databases/nosql-databases/redis/redis-queues",title:"Redis Queues",description:"Conceptually, a Stream in Redis is a list where you can append entries. Each entry has a unique ID and a value. The ID is auto-generated by default, and it includes a timestamp. The value is a hash. You can query ranges or use blocking commands to read entries as they come. Typical of Redis, you can combine different ingredients to get the result you need. As Niklaus Wirth once said, programs are algorithms plus data structures, and Redis already gives you a bit of both.",source:"@site/docs/databases/nosql-databases/redis/redis-queues.md",sourceDirName:"databases/nosql-databases/redis",slug:"/databases/nosql-databases/redis/redis-queues",permalink:"/databases/nosql-databases/redis/redis-queues",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/databases/nosql-databases/redis/redis-queues.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"redis-py",permalink:"/databases/nosql-databases/redis/redis-py"},next:{title:"Redis Streams / PUBSUB",permalink:"/databases/nosql-databases/redis/redis-streams-pubsub"}},u={},l=[{value:"Message queues",id:"message-queues",level:2},{value:"Reliable queues",id:"reliable-queues",level:2},{value:"Queueing Solutions",id:"queueing-solutions",level:2},{value:"RQ",id:"rq",level:2},{value:"# Application",id:"-application",level:2},{value:"Scheduling jobs",id:"scheduling-jobs",level:2},{value:"Some interesting job attributes include",id:"some-interesting-job-attributes-include",level:2},{value:"get job",id:"get-job",level:3},{value:"Worker",id:"worker",level:3},{value:"Test app - https://github.com/edkrueger/rq-flask-template",id:"test-app---httpsgithubcomedkruegerrq-flask-template",level:2},{value:"Tools - RQ",id:"tools---rq",level:2},{value:"Delayed Tasks",id:"delayed-tasks",level:2},{value:"requiements.txt",id:"requiementstxt",level:3},{value:"tasks.py",id:"taskspy",level:3},{value:"tasks_runner.py",id:"tasks_runnerpy",level:3}],d={toc:l},p="wrapper";function c(e){let{components:t,...a}=e;return(0,r.kt)(p,(0,s.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"redis-queues"},"Redis Queues"),(0,r.kt)("p",null,"Conceptually, a Stream in Redis is a list where you can append entries. Each entry has a unique ID and a value. The ID is auto-generated by default, and it includes a timestamp. The value is a hash. You can query ranges or use blocking commands to read entries as they come. Typical of Redis, you can combine different ingredients to get the result you need. As Niklaus Wirth once said, programs are algorithms plus data structures, and Redis already gives you a bit of both.\nRedis streams are ideal for building history preserving message brokers, message queues, unified logs, and chat systems. Unlike Pub/Sub messages which are fire and forget, Redis streams preserve messages in perpetuity. Redis streams implement consumer groups, a feature that allows a group of clients to cooperate when consuming elements from a stream. For example, consumers in a group can lookup items by ID, have to acknowledge the processing of an item, or claim ownership of a pending message.\n",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/redis/Redis_Streams"},"https://aws.amazon.com/redis/Redis_Streams")),(0,r.kt)("h2",{id:"message-queues"},"Message queues"),(0,r.kt)("p",null,'A message queue is conceptually a list. A producer pushes an element from one side, a consumer reads from the other. Multiple producers and consumers can interact with the same queue. In Redis, a rudimentary message queue can be easily implemented with the commands LPUSH (which means "push from the left") and RPOP (which means "pop from the right"). In the best-case scenario -the happy path - the consumer pops an item, works on it, and once it\'s done, the customer is ready to consume and process the next item. A slight improvement would be to use a blocking command for reading. So instead of RPOP you could use BRPOP. If the list is empty, the consumer blocks and waits for an element to arrive. If the timeout elapses, the consumer can retry. So far, so good for this simplistic implementation. The problem, though, doesn\'t lie in the happy path. The issue is what happens when a process crashes while processing an item.'),(0,r.kt)("h2",{id:"reliable-queues"},"Reliable queues"),(0,r.kt)("p",null,"A queue is reliable if it can recover from a failure scenario. If a consumer crashes and the item it was processing is lost, the system is unreliable. A command was added to a previous version of Redis that is tailor-made for this exact situation. The command is BRPOPLPUSH. It not only pops an item, as discussed in the previous implementation, but it also pushes the item to another list. With the commands LPUSH and BRPOPLPUSH, you can design a reliable message queue\n",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/redis/Redis_Streams_MQ"},"https://aws.amazon.com/redis/Redis_Streams_MQ")),(0,r.kt)("h2",{id:"queueing-solutions"},"Queueing Solutions"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Celery has an optional redis broker.",(0,r.kt)("a",{parentName:"p",href:"http://celeryproject.org"},"http://celeryproject.org"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"resque is an extremely popular redis task queue using redis.",(0,r.kt)("a",{parentName:"p",href:"https://github.com/defunkt/resque"},"https://github.com/defunkt/resque"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},'RQ is a simple and small redis based queue that aims to "take the good stuff from celery and resque" and be much simpler to work with.',(0,r.kt)("a",{parentName:"p",href:"http://python-rq.org"},"http://python-rq.org")))),(0,r.kt)("h2",{id:"rq"},"RQ"),(0,r.kt)("p",null,"RQ (Redis Queue) is a simple Python library for queueing jobs and processing them in the background with workers. It is backed by Redis and it is designed to have a low barrier to entry. It should be integrated in your web stack easily.\npip install rq"),(0,r.kt)("h2",{id:"-application"},"# Application"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from rq.job import Job\njob = redis_queue.enqueue(some_long_function, data)\n\njob = queue.enqueue(count_words_at_url, '<http://nvie.com>')\n")),(0,r.kt)("h2",{id:"scheduling-jobs"},"Scheduling jobs"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Schedule job to run at 9:15, October 10th\njob = queue.**enqueue_at**(datetime(2019, 10, 8, 9, 15), say_hello)\n\n# Schedule job to run in 10 seconds\njob = queue.**enqueue_in**(timedelta(seconds=10), say_hello)\n\n## Retrying failed jobs\nfrom rq import Retry\n\n# Retry up to 3 times, failed job will be requeued immediately\nqueue.enqueue(say_hello, retry=Retry(max=3))\n\n# Retry up to 3 times, with configurable intervals between retries\nqueue.enqueue(say_hello, retry=Retry(max=3, interval=[10, 30, 60]))\n")),(0,r.kt)("h2",{id:"some-interesting-job-attributes-include"},"Some interesting job attributes include"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"job.get_status()Possible values arequeued, started, deferred, finished, andfailed"),(0,r.kt)("li",{parentName:"ul"},"job.func_name"),(0,r.kt)("li",{parentName:"ul"},"job.argsarguments passed to the underlying job function"),(0,r.kt)("li",{parentName:"ul"},"job.kwargskey word arguments passed to the underlying job function"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"job.result"),"stores the return value of the job being executed, will returnNoneprior to job execution. Results are kept according to theresult_ttlparameter (500 seconds by default)."),(0,r.kt)("li",{parentName:"ul"},"job.enqueued_at (job.enqueued_at.isoformat())"),(0,r.kt)("li",{parentName:"ul"},"job.started_at (job.started_at.isoformat())"),(0,r.kt)("li",{parentName:"ul"},"job.ended_at"),(0,r.kt)("li",{parentName:"ul"},"job.exc_infostores exception information if job doesn't finish successfully."),(0,r.kt)("li",{parentName:"ul"},"job.id")),(0,r.kt)("h3",{id:"get-job"},"get job"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"job = Job.fetch(job_id, connection=redis_conn)")),(0,r.kt)("h3",{id:"worker"},"Worker"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Sets up the redis connection and the redis queue.\nimport os\n\nimport redis\n\nfrom rq import Queue\nredis_conn = redis.Redis(\n\nhost=os.getenv("REDIS_HOST", "127.0.0.1"),\n\nport=os.getenv("REDIS_PORT", "6379"),\n\npassword=os.getenv("REDIS_PASSWORD", ""),\n\n)\nredis_queue = Queue(connection=redis_conn)\nIf you use RQ\'s scheduling features, you need to run RQ workers with the scheduler component enabled\n\nrq worker --with-scheduler\nrq worker --url redis://:a6ad92769ef04b711eea18dccfff85ea@redis:6379\nCommands\n\nkeys *\n\n1) "rq:job:61cd0099-f14e-407c-b1c0-f3ce46e5ab67"\n2) "rq:queue:default"\n3) "rq:queues"\n\ntype rq:job:61cd0099-f14e-407c-b1c0-f3ce46e5ab67\n\nhash\n\nhgetall rq:job:61cd0099-f14e-407c-b1c0-f3ce46e5ab67\ntype rq:queue:default\n\nlist\n\nlrange rq:queue:default 0 -1\ntype rq:queues\n\nset\n\nsmembers rq:queues\n<https://github.com/rq/rq>\n\n<https://pypi.org/project/rq>\n\n<https://python-rq.org>\n\n<https://python-rq.org/docs>\n\n<https://python-rq.org/patterns>\n\n<https://python-rq.org/patterns/django>\n\n<https://python-rq.org/patterns/sentry>\n')),(0,r.kt)("h2",{id:"test-app---httpsgithubcomedkruegerrq-flask-template"},"Test app - ",(0,r.kt)("a",{parentName:"h2",href:"https://github.com/edkrueger/rq-flask-template"},"https://github.com/edkrueger/rq-flask-template")),(0,r.kt)("h2",{id:"tools---rq"},"Tools - RQ"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/rq/rq-scheduler"},"https://github.com/rq/rq-scheduler"))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/rq/rq-scheduler"},"RQ Scheduler")," is a small package that adds job scheduling capabilities to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/nvie/rq"},"RQ"),", a ",(0,r.kt)("a",{parentName:"p",href:"http://redis.io/"},"Redis")," based Python queuing library."),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Parallels/rq-dashboard"},"https://github.com/Parallels/rq-dashboard"))),(0,r.kt)("p",null,"rq-dashboardis a general purpose, lightweight, ",(0,r.kt)("a",{parentName:"p",href:"https://flask.palletsprojects.com/"},"Flask"),"-based web front-end to monitor your ",(0,r.kt)("a",{parentName:"p",href:"http://python-rq.org/"},"RQ")," queues, jobs, and workers in realtime."),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/pranavgupta1234/rqmonitor"},"https://github.com/pranavgupta1234/rqmonitor"))),(0,r.kt)("p",null,"RQ Monitor is Flask based more actionable and dynamic web frontend for monitoring your RQ."),(0,r.kt)("h2",{id:"delayed-tasks"},"Delayed Tasks"),(0,r.kt)("p",null,"There are a few different ways that we could potentially add delays to our queue items. Here are the three most straightforward ones:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"We could include an execution time as part of queue items, and if a worker process sees an item with an execution time later than now, it can wait for a brief period and then re-enqueue the item."),(0,r.kt)("li",{parentName:"ul"},"The worker process could have a local waiting list for any items it has seen that need to be executed in the future, and every time it makes a pass through its while loop, it could check that list for any outstanding items that need to be executed."),(0,r.kt)("li",{parentName:"ul"},"Normally when we talk about times, we usually start talking about ",(0,r.kt)("em",{parentName:"li"},"ZSETs"),". What if, for any item we wanted to execute in the future, we added it to a ",(0,r.kt)("em",{parentName:"li"},"ZSET")," instead of a",(0,r.kt)("em",{parentName:"li"},"LIST"),", with its score being the time when we want it to execute? We then have a process that checks for items that should be executed now, and if there are any, the process removes it from the ",(0,r.kt)("em",{parentName:"li"},"ZSET"),", adding it to the proper ",(0,r.kt)("em",{parentName:"li"},"LIST"),"queue.\nWe can't wait/re-enqueue items as described in the first, because that'll waste the worker process's time. We also can't create a local waiting list as described in the second option, because if the worker process crashes for an unrelated reason, we lose any pending work items it knew about. We'll instead use a secondaryZSETas described in the third option, because it's simple, straightforward, and we can use a lock to ensure that the move is safe.")),(0,r.kt)("h3",{id:"requiementstxt"},"requiements.txt"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"rpqueue==0.33.2")),(0,r.kt)("h3",{id:"taskspy"},"tasks.py"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import requests\n\nimport rpqueue\n\nfrom rpqueue import task\nrpqueue.set_redis_connection_settings('redis', '6379', 0, 'a6ad92769ef04b711eea18dccfff85ea')\n\n@task\ndef call_sms_model(cust_id):\n\n    payload = {'cust_id': cust_id}\n\n    resp = requests.get('http://decision_engine:5000/score', params=payload)\n\n    print(f'request: {cust_id}, resp status code: {resp.status_code}, text: {resp.text}')\n")),(0,r.kt)("h3",{id:"tasks_runnerpy"},"tasks_runner.py"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import rpqueue\n\nfrom tasks import call_sms_model\nrpqueue.set_redis_connection_settings('redis', '6379', 0, 'a6ad92769ef04b711eea18dccfff85ea')\n\nrpqueue.execute_tasks(queues=None, threads_per_process=1, processes=1, wait_per_thread=1, module='tasks')\n\n# python -m rpqueue.run --module=tasks --host=redis --port=6379 --db=0 --password=a6ad92769ef04b711eea18dccfff85ea\n")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-4-task-queues/6-4-2-delayed-tasks"},"https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-4-task-queues/6-4-2-delayed-tasks")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/josiahcarlson/rpqueue"},"https://github.com/josiahcarlson/rpqueue")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://josiahcarlson.github.io/rpqueue"},"https://josiahcarlson.github.io/rpqueue")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/Parallels/rq-dashboard"},"https://github.com/Parallels/rq-dashboard")))}c.isMDXComponent=!0}}]);