"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[57010],{603905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var r=a(667294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=r.createContext({}),c=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(a),d=i,h=u["".concat(s,".").concat(d)]||u[d]||m[d]||n;return a?r.createElement(h,o(o({ref:t},p),{},{components:a})):r.createElement(h,o({ref:t},p))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,o=new Array(n);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:i,o[1]=l;for(var c=2;c<n;c++)o[c]=a[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},616367:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>n,metadata:()=>l,toc:()=>c});var r=a(487462),i=(a(667294),a(603905));const n={},o="CPU | GPU | TPU",l={unversionedId:"computer-science/operating-system/cpu-gpu-tpu",id:"computer-science/operating-system/cpu-gpu-tpu",title:"CPU | GPU | TPU",description:"MAC - Multiplier, Adder, Accumulator",source:"@site/docs/computer-science/operating-system/cpu-gpu-tpu.md",sourceDirName:"computer-science/operating-system",slug:"/computer-science/operating-system/cpu-gpu-tpu",permalink:"/computer-science/operating-system/cpu-gpu-tpu",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/computer-science/operating-system/cpu-gpu-tpu.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Coroutines",permalink:"/computer-science/operating-system/coroutines"},next:{title:"Disk IO",permalink:"/computer-science/operating-system/disk-io"}},s={},c=[{value:"CPU / GPU",id:"cpu--gpu",level:2},{value:"TPU",id:"tpu",level:2},{value:"The Systolic Array",id:"the-systolic-array",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"CPU Time",id:"cpu-time",level:2}],p={toc:c},u="wrapper";function m(e){let{components:t,...n}=e;return(0,i.kt)(u,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"cpu--gpu--tpu"},"CPU | GPU | TPU"),(0,i.kt)("p",null,"MAC - Multiplier, Adder, Accumulator"),(0,i.kt)("p",null,"Tensor - n-dimensional array"),(0,i.kt)("p",null,"Specifically for matrix operations"),(0,i.kt)("h2",{id:"cpu--gpu"},"CPU / GPU"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"A CPU is a scalar machine, which means it processes instructions one step at a time."),(0,i.kt)("li",{parentName:"ul"},"A GPU is composed of hundreds of cores that can handle thousands of threads simultaneously.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Thats because GPUs were designed for 3d game rendering, which often involves parallel operations -The ability of a GPU with 100+ cores to process thousands of threads can accelerate some software by 100x over a CPU alone."),(0,i.kt)("li",{parentName:"ul"},"What's more, the GPU achieves this acceleration while being more power- and cost-efficient than a CPU."),(0,i.kt)("li",{parentName:"ul"},"So when neural networks run on GPUs, they run much faster than on CPUs"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("img",{alt:"image",src:a(765558).Z,width:"817",height:"554"})),(0,i.kt)("li",{parentName:"ul"},"A GPU is a vector machine. You can give it a long list of data\u200a---\u200aa 1D vector\u200a---\u200aand run computations on the entire list at the same time."),(0,i.kt)("li",{parentName:"ul"},"This way, we can perform more computations per second, but we have to perform the same computation on a vector of data in parallel."),(0,i.kt)("li",{parentName:"ul"},"GPUs are general purpose chips. They don't just perform matrix operations, they can really do any kind of computation."),(0,i.kt)("li",{parentName:"ul"},"GPUs are optimized for taking huge batches of data and performing the same operation over and over very quickly")),(0,i.kt)("h2",{id:"tpu"},"TPU"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"TPU hardware is comprised of four independent chips."),(0,i.kt)("li",{parentName:"ul"},"Each chip consists of two compute cores called Tensor Cores."),(0,i.kt)("li",{parentName:"ul"},"A Tensor Core consists of scalar, vector and matrix units (MXU)."),(0,i.kt)("li",{parentName:"ul"},"In addition, 8 GB of on-chip memory (HBM) is associated with each Tensor Core."),(0,i.kt)("li",{parentName:"ul"},"The bulk of the compute horsepower in a Cloud TPU is provided by the MXU."),(0,i.kt)("li",{parentName:"ul"},"Each MXU is capable of performing 16K multiply-accumulate operations in each cycle."),(0,i.kt)("li",{parentName:"ul"},"While the MXU's inputs and outputs are 32-bit floating point values, the MXU performs multiplies at reduced bfloat16 precision."),(0,i.kt)("li",{parentName:"ul"},"Bfloat16 is a 16-bit floating point representation that provides better training and model accuracy than the IEEE half-precision representation. -From a software perspective, each of the 8 cores on a Cloud TPU can execute user computations (XLA ops) independently."),(0,i.kt)("li",{parentName:"ul"},"High-bandwidth interconnects allow the chips to communicate directly with each other.- ",(0,i.kt)("img",{alt:"image",src:a(897835).Z,width:"408",height:"589"}))),(0,i.kt)("h2",{id:"the-systolic-array"},"The Systolic Array"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The way to achieve that matrix performance is through a piece of architecture called a systolic array."),(0,i.kt)("li",{parentName:"ul"},"This is the interesting bit, and it's why a TPU is performant."),(0,i.kt)("li",{parentName:"ul"},"A systolic array is a kind of hardware algorithm, and it describes a pattern of cells on a chip that computes matrix multiplication."),(0,i.kt)("li",{parentName:"ul"},'"Systolic" describes how data moves in waves across the chip, like the beating of a human heart.')),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"image",src:a(62316).Z,width:"648",height:"120"})),(0,i.kt)("h2",{id:"use-cases"},"Use Cases"),(0,i.kt)("p",null,"CPUs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Quick prototyping that requires maximum flexibility"),(0,i.kt)("li",{parentName:"ul"},"Simple models that do not take long to train"),(0,i.kt)("li",{parentName:"ul"},"Small models with small effective batch sizes"),(0,i.kt)("li",{parentName:"ul"},"Models that are dominated by custom TensorFlow operations written in C++"),(0,i.kt)("li",{parentName:"ul"},"Models that are limited by available I/O or the networking bandwidth of the host system")),(0,i.kt)("p",null,"GPUs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Models that are not written in TensorFlow or cannot be written in TensorFlow"),(0,i.kt)("li",{parentName:"ul"},"Models for which source does not exist or is too onerous to change"),(0,i.kt)("li",{parentName:"ul"},"Models with a significant number of custom TensorFlow operations that must run at least partially on CPUs"),(0,i.kt)("li",{parentName:"ul"},"Models with TensorFlow ops that are not available on Cloud TPU (see the list of available TensorFlow ops)"),(0,i.kt)("li",{parentName:"ul"},"Medium-to-large models with larger effective batch sizes")),(0,i.kt)("p",null,"TPUs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Models dominated by matrix computations"),(0,i.kt)("li",{parentName:"ul"},"Models with no custom TensorFlow operations inside the main training loop"),(0,i.kt)("li",{parentName:"ul"},"Models that train for weeks or months"),(0,i.kt)("li",{parentName:"ul"},"Larger and very large models with very large effective batch sizes")),(0,i.kt)("h2",{id:"cpu-time"},"CPU Time"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://dzone.com/articles/nice-cpu-time-ni-time-in-top"},"https://dzone.com/articles/nice-cpu-time-ni-time-in-top")))}m.isMDXComponent=!0},765558:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/CPU-GPU-TPU-image1-6e4e088af215dcc3f6975ef020f80aef.jpg"},897835:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/CPU-GPU-TPU-image2-c2adaef7ae08091ea5a54bf0ca8ab0be.jpg"},62316:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/CPU-GPU-TPU-image3-03ae5c97a61da8b7a77ac11bd79e138c.jpg"}}]);