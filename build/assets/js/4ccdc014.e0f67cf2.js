"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[43506],{603905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>d});var n=r(667294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),p=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=p(r),h=o,d=u["".concat(l,".").concat(h)]||u[h]||m[h]||a;return r?n.createElement(d,s(s({ref:t},c),{},{components:r})):n.createElement(d,s({ref:t},c))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,s=new Array(a);s[0]=h;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:o,s[1]=i;for(var p=2;p<a;p++)s[p]=r[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}h.displayName="MDXCreateElement"},826983:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>p});var n=r(487462),o=(r(667294),r(603905));const a={},s="Gunicorn",i={unversionedId:"devops/others/servers/gunicorn",id:"devops/others/servers/gunicorn",title:"Gunicorn",description:'Gunicorn was inspired by Ruby\'s Unicorn server (hence the name). It modestly claims that it is "simply implemented, light on server resources, and fairly speedy." Unlike Bjoern and CerryPy, Gunicorn is a standalone server. "WORKER_COUNT" was set to be twice the number of available of processors, plus one. This was based on a recommendation from Gunicorn\'s documentation.',source:"@site/docs/devops/others/servers/gunicorn.md",sourceDirName:"devops/others/servers",slug:"/devops/others/servers/gunicorn",permalink:"/devops/others/servers/gunicorn",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/devops/others/servers/gunicorn.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Apache Server",permalink:"/devops/others/servers/apache-server"},next:{title:"NGINX",permalink:"/devops/others/servers/nginx/"}},l={},p=[{value:"Async Workers",id:"async-workers",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Commands",id:"commands",level:2},{value:"Enhancements",id:"enhancements",level:2},{value:"Timeout",id:"timeout",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Setting up workers",id:"setting-up-workers",level:2}],c={toc:p},u="wrapper";function m(e){let{components:t,...r}=e;return(0,o.kt)(u,(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"gunicorn"},"Gunicorn"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"http://gunicorn.org/"},"Gunicorn"),' was inspired by Ruby\'s Unicorn server (hence the name). It modestly claims that it is "simply implemented, light on server resources, and fairly speedy." Unlike Bjoern and CerryPy, Gunicorn is a standalone server. "WORKER_COUNT" was set to be ',(0,o.kt)("strong",{parentName:"p"},"twice the number of available of processors, plus one"),". This was based on a recommendation from Gunicorn's documentation."),(0,o.kt)("h2",{id:"async-workers"},"Async Workers"),(0,o.kt)("p",null,"You may also want to install ",(0,o.kt)("a",{parentName:"p",href:"http://eventlet.net/"},"Eventlet")," or ",(0,o.kt)("a",{parentName:"p",href:"http://www.gevent.org/"},"Gevent")," if you expect that your application code may need to pause for extended periods of time during request processing. Check out the ",(0,o.kt)("a",{parentName:"p",href:"http://docs.gunicorn.org/en/stable/design.html"},"design docs")," for more information on when you'll want to consider one of the alternate worker types."),(0,o.kt)("p",null,"$ pip install greenlet # Required for both\n$ pip install eventlet # For eventlet workers\n$ pip install gunicorn ","[eventlet]"," # Or, using extra\n$ pip install gevent # For gevent workers\n$ pip install gunicorn ","[gevent]"," # Or, using extra"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://medium.com/@genchilu/brief-introduction-about-the-types-of-worker-in-gunicorn-and-respective-suitable-scenario-67b0c0e7bd62"},"https://medium.com/@genchilu/brief-introduction-about-the-types-of-worker-in-gunicorn-and-respective-suitable-scenario-67b0c0e7bd62")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"http://docs.gunicorn.org/en/stable/design.html"},"http://docs.gunicorn.org/en/stable/design.html")),(0,o.kt)("h2",{id:"configuration"},"Configuration"),(0,o.kt)("p",null,"in order of least to most authoritative:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Framework Settings")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Configuration File")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Command Line"))),(0,o.kt)("h2",{id:"commands"},"Commands"),(0,o.kt)("p",null,"pip install gunicorn ","[gevent]"),(0,o.kt)("p",null,"gunicorn <app_file>:app -b 0.0.0.0:5000 --workers 3 -k gevent --timeout 300 --worker-connections 1000 --max-requests 1000000 --limit-request-line 8190 --access-logfile /var/log/gunicorn/access.log"),(0,o.kt)("p",null,"gunicorn app:app -b 0.0.0.0:5000 --workers 3 -k gevent --timeout 300 --worker-connections 1000 --max-requests 1000000 --limit-request-line 8190 --access-logfile '-'"),(0,o.kt)("p",null,"gunicorn app:app -b 0.0.0.0:5000 --workers 16 -k gevent --timeout 300 --worker-connections 1000 --graceful-timeout 30 --keep-alive 2 --max-requests 1000000 --max-requests-jitter 100 --limit-request-line 0 --access-logfile '-' --error-logfile '-' --log-level 'info' --access-logformat '%(h)s %(l)s %(u)s %(t)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\"'"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://docs.gunicorn.org/en/stable/settings.html"},"https://docs.gunicorn.org/en/stable/settings.html")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/benoitc/gunicorn/blob/master/examples/example_config.py"},"https://github.com/benoitc/gunicorn/blob/master/examples/example_config.py")),(0,o.kt)("h2",{id:"enhancements"},"Enhancements"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"use/dev/shminstead of/tmp"),(0,o.kt)("li",{parentName:"ul"},"start at least two workers, and probably also start a number of threads using"),(0,o.kt)("li",{parentName:"ul"},"thegthreadworker backend when running in a container"),(0,o.kt)("li",{parentName:"ul"},"gunicorn --log-file=- ..."),(0,o.kt)("li",{parentName:"ul"},"you don't always need nginx or another proxy in front Gunicorn")),(0,o.kt)("p",null,"Gunicorn should only need 4-12 worker processes to handle hundreds or thousands of requests per second."),(0,o.kt)("p",null,"Gunicorn relies on the operating system to provide all of the load balancing when handling requests. Generally we recommend(2x$num_cores)+1as the number of workers to start off with. While not overly scientific, the formula is based on the assumption that for a given core, one worker will be reading or writing from the socket while the other worker is processing a request."),(0,o.kt)("h2",{id:"timeout"},"Timeout"),(0,o.kt)("p",null,"The gunicorn documentation is not entierly clear to me on this point. For --timeout it says that Workers silent for more than this many seconds are killed and restarted. But it seems that workers are killed after 30sec even though they still produce data?"),(0,o.kt)("p",null,"By silent, we mean silent from the perspective of the arbiter process, which communicates with the workers through a temporary file. If the worker is busy sending data, it does not update that file. From the perspective of the arbiter, the worker is missing heartbeats."),(0,o.kt)("h2",{id:"architecture"},"Architecture"),(0,o.kt)("p",null,"Gunicorn's main process starts one or more worker processes, and restarts them if they die. To ensure the workers are still alive, Gunicorn has a heartbeat system - which works by using a file on the filesystem. Gunicorn therefore recommends that this file be stored in a memory-only part of the filesystem."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Gunicorn starts a single master process that gets forked, and the resulting child processes are the workers."),(0,o.kt)("li",{parentName:"ul"},"The role of the master process is to make sure that the number of workers is the same as the ones defined in the settings. So if any of the workers die, the master process starts another one, by forking itself again."),(0,o.kt)("li",{parentName:"ul"},"The role of the workers is to handle HTTP requests."),(0,o.kt)("li",{parentName:"ul"},"Thepreinpre-forkedmeans that the master process creates the workers before handling any HTTP request."),(0,o.kt)("li",{parentName:"ul"},"The OS kernel handles load balancing between worker processes.")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://pythonspeed.com/articles/gunicorn-in-docker"},"https://pythonspeed.com/articles/gunicorn-in-docker")),(0,o.kt)("h2",{id:"setting-up-workers"},"Setting up workers"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"If the application is ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/I/O_bound"},"I/O bounded"),', the best performance usually comes from using "pseudo-threads" (gevent or asyncio). As we have seen, Gunicorn supports this programming paradigm by setting the appropriateworker classand adjusting the value ofworkersto(2*CPU)+1.')),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"If the application is ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/CPU-bound"},"CPU bounded"),", it doesn't matter how many concurrent requests are handled by the application. The only thing that matters is the number of parallel requests. Due to ",(0,o.kt)("a",{parentName:"p",href:"https://wiki.python.org/moin/GlobalInterpreterLock"},"Python's GIL"),', threads and "pseudo-threads" cannot run in parallel. The only way to achieve parallelism is to increaseworkersto the suggested(2*CPU)+1, understanding that the maximum number of parallel requests is the number of cores.')),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"If there is a concern about the application ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Memory_footprint"},"memory footprint"),", usingthreadsand its correspondinggthread worker classin favor ofworkersyields better performance because the application is loaded once per worker and every thread running on the worker shares some memory, this comes to the expense of some additional CPU consumption.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"If you don't know you are doing, start with the simplest configuration, which is only settingworkersto(2*CPU)+1and don't worry aboutthreads. From that point, it's all trial and error with benchmarking. If the bottleneck is memory, start introducing threads. If the bottleneck is I/O, consider a different python programming paradigm. If the bottleneck is CPU, consider using more cores and adjusting theworkersvalue."))),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7"},"https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7")))}m.isMDXComponent=!0}}]);