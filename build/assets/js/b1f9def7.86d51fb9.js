"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[76582],{603905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>f});var r=t(667294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function p(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=r.createContext({}),l=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},m=function(e){var n=l(e.components);return r.createElement(s.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},u=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,m=p(e,["components","mdxType","originalType","parentName"]),c=l(t),u=a,f=c["".concat(s,".").concat(u)]||c[u]||d[u]||o;return t?r.createElement(f,i(i({ref:n},m),{},{components:t})):r.createElement(f,i({ref:n},m))}));function f(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=u;var p={};for(var s in n)hasOwnProperty.call(n,s)&&(p[s]=n[s]);p.originalType=e,p[c]="string"==typeof e?e:a,i[1]=p;for(var l=2;l<o;l++)i[l]=t[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},773804:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>p,toc:()=>l});var r=t(487462),a=(t(667294),t(603905));const o={},i="Commands",p={unversionedId:"ai/deep-learning/commands",id:"ai/deep-learning/commands",title:"Commands",description:"Libraries",source:"@site/docs/ai/deep-learning/commands.md",sourceDirName:"ai/deep-learning",slug:"/ai/deep-learning/commands",permalink:"/ai/deep-learning/commands",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/ai/deep-learning/commands.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Deep Learning",permalink:"/ai/deep-learning/"},next:{title:"DL Specialization",permalink:"/ai/deep-learning/dl-specialization"}},s={},l=[{value:"Libraries",id:"libraries",level:2},{value:"Python- Numpy Vectors",id:"python--numpy-vectors",level:2}],m={toc:l},c="wrapper";function d(e){let{components:n,...t}=e;return(0,a.kt)(c,(0,r.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"commands"},"Commands"),(0,a.kt)("h2",{id:"libraries"},"Libraries"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://idrgfain.labs.coursera.org/notebooks/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/www.numpy.org"},"numpy")," is the fundamental package for scientific computing with Python."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"http://www.h5py.org/"},"h5py")," is a common package to interact with a dataset that is stored on an H5 file."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"http://matplotlib.org/"},"matplotlib")," is a famous library to plot graphs in Python."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"http://www.pythonware.com/products/pil/"},"PIL")," and ",(0,a.kt)("a",{parentName:"li",href:"https://www.scipy.org/"},"scipy")," are used here to test your model with your own picture at the end.")),(0,a.kt)("h2",{id:"python--numpy-vectors"},"Python- Numpy Vectors"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\n\na = np.random.randn(5)\nprint(a.shape)\n\n(5, )\n\nprint(a.T)\n[ ]\n\nprint(np.dot(a, a.T))\n\n# use (5,1) instead of (5) i.e rank 1 array (nor a row vector nor a column vector)\n\n# don't use rank 1 array\n\na = np.random.randn(5,1) # a.shape = (5,1), column vector\n\na = np.random.randn(1,5) # a.shape = (1,5), row vector\n\nprint(a.T)\n\n[[ ]]\n\nassert (a.shape == (5,1))\n\na = a.reshape((5,1)) # to change from rank 1 array to column vector\n\ndef sigmoid(x):\n    s = 1/(1+np.exp(-x))\n\ndef sigmoid_derivative(x):\n    s = 1/(1+np.exp(-x))\n    ds = s*(1-s)\n\ndef image2vector(image):\n    v = image.reshape(image.shape [0]*image.shape [1]*image.shape [2], 1)\n\ndef normalizeRows(x):\n    x_norm = np.linalg.norm(x, ord = 2, axis=1, keepdims=True)\n    x = x/x_norm\n\ndef softmax(x):\n    x_exp = np.exp(x)\n    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n    s = x_exp / x_sum\n\ndef L1(yhat, y):\n    loss = np.sum(abs(y-yhat))\n\ndef L2(yhat, y):\n    loss = np.sum(np.dot((y-yhat),(y-yhat)))\n\nA trick when you want to flatten a matrix X of shape (a, b, c, d) to a matrix X_flatten of shape (b\u2217\u2217c\u2217\u2217d, a) is to use:\n\nX_flatten = X.reshape(X.shape [0], -1).T\n")))}d.isMDXComponent=!0}}]);