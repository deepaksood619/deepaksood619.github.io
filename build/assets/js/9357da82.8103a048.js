"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[81061],{603905:(e,a,t)=>{t.d(a,{Zo:()=>c,kt:()=>g});var i=t(667294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function n(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);a&&(i=i.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,i)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?n(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):n(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,i,r=function(e,a){if(null==e)return{};var t,i,r={},n=Object.keys(e);for(i=0;i<n.length;i++)t=n[i],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(i=0;i<n.length;i++)t=n[i],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=i.createContext({}),l=function(e){var a=i.useContext(p),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},c=function(e){var a=l(e.components);return i.createElement(p.Provider,{value:a},e.children)},h="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return i.createElement(i.Fragment,{},a)}},u=i.forwardRef((function(e,a){var t=e.components,r=e.mdxType,n=e.originalType,p=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),h=l(t),u=r,g=h["".concat(p,".").concat(u)]||h[u]||d[u]||n;return t?i.createElement(g,o(o({ref:a},c),{},{components:t})):i.createElement(g,o({ref:a},c))}));function g(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var n=t.length,o=new Array(n);o[0]=u;var s={};for(var p in a)hasOwnProperty.call(a,p)&&(s[p]=a[p]);s.originalType=e,s[h]="string"==typeof e?e:r,o[1]=s;for(var l=2;l<n;l++)o[l]=t[l];return i.createElement.apply(null,o)}return i.createElement.apply(null,t)}u.displayName="MDXCreateElement"},481667:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>p,contentTitle:()=>o,default:()=>d,frontMatter:()=>n,metadata:()=>s,toc:()=>l});var i=t(487462),r=(t(667294),t(603905));const n={},o="Apache HBase",s={unversionedId:"technologies/apache/apache-hbase",id:"technologies/apache/apache-hbase",title:"Apache HBase",description:"HBaseis an open-source, non-relational, distributed database modeled after Google'sBigtable and written in Java). It is developed as part of Apache Software Foundation's Apache Hadoop project and runs on top of HDFS (Hadoop Distributed File System), providing Bigtable-like capabilities for Hadoop. That is, it provides a fault-tolerant way of storing large quantities of sparse data (small amounts of information caught within a large collection of empty or unimportant data, such as finding the 50 largest items in a group of 2 billion records, or finding the non-zero items representing less than 0.1% of a huge collection).",source:"@site/docs/technologies/apache/apache-hbase.md",sourceDirName:"technologies/apache",slug:"/technologies/apache/apache-hbase",permalink:"/technologies/apache/apache-hbase",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/technologies/apache/apache-hbase.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Others",permalink:"/technologies/apache/apache-hadoop/others"},next:{title:"Apache Hive",permalink:"/technologies/apache/apache-hive"}},p={},l=[{value:"References",id:"references",level:2}],c={toc:l},h="wrapper";function d(e){let{components:a,...n}=e;return(0,r.kt)(h,(0,i.Z)({},c,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"apache-hbase"},"Apache HBase"),(0,r.kt)("p",null,"HBaseis an ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Open-source"},"open-source"),", ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Non-relational_database"},"non-relational"),", ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distributed_database"},"distributed database")," modeled after ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Google"},"Google's"),(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Bigtable"},"Bigtable")," and written in ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Java_(programming_language)"},"Java"),". It is developed as part of ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Apache_Software_Foundation"},"Apache Software Foundation"),"'s ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Hadoop"},"Apache Hadoop")," project and runs on top of ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Hadoop_Distributed_File_System"},"HDFS (Hadoop Distributed File System)"),", providing Bigtable-like capabilities for Hadoop. That is, it provides a ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Fault-tolerant"},"fault-tolerant")," way of storing large quantities of ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Sparse_file"},"sparse")," data (small amounts of information caught within a large collection of empty or unimportant data, such as finding the 50 largest items in a group of 2 billion records, or finding the non-zero items representing less than 0.1% of a huge collection)."),(0,r.kt)("p",null,"HBase features compression, in-memory operation, and ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Bloom_filter"},"Bloom filters")," on a per-column basis as outlined in the original Bigtable paper.Tables in HBase can serve as the input and output for ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Mapreduce"},"MapReduce")," jobs run in Hadoop, and may be accessed through the Java API but also through ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/REST"},"REST"),", ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Avro_(serialization_system)"},"Avro")," or ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Thrift_(protocol)"},"Thrift")," gateway APIs. HBase is a column-oriented key-value data store and has been idolized widely because of its lineage with Hadoop and HDFS. HBase runs on top of HDFS and is well-suited for faster read and write operations on large datasets with high throughput and low input/output latency."),(0,r.kt)("p",null,"HBase is not a direct replacement for a classic ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/SQL"},"SQL"),(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Database"},"database"),", however ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Apache_Phoenix"},"Apache Phoenix")," project provides a SQL layer for HBase as well as ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/JDBC"},"JDBC")," driver that can be integrated with various ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Analytics"},"analytics")," and ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Business_intelligence"},"business intelligence")," applications. The ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Apache_Trafodion"},"Apache Trafodion")," project provides a SQL query engine with ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/ODBC"},"ODBC")," and ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/JDBC"},"JDBC")," drivers and ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/ACID#Distributed_transactions"},"distributed ACID transaction protection")," across multiple statements, tables and rows that uses HBase as a storage engine."),(0,r.kt)("p",null,"Unlike relational and traditional databases, HBase does not support SQL scripting; instead the equivalent is written in Java, employing similarity with a MapReduce application."),(0,r.kt)("p",null,"In the parlance of Eric Brewer's ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/CAP_Theorem"},"CAP Theorem"),", HBase is a CP type system."),(0,r.kt)("p",null,"Use Apache HBase\u2122 when you need random, realtime read/write access to your Big Data. This project's goal is the hosting of very large tables -- billions of rows X millions of columns -- atop clusters of commodity hardware. Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google's ",(0,r.kt)("a",{parentName:"p",href:"http://research.google.com/archive/bigtable.html"},"Bigtable: A Distributed Storage System for Structured Data")," by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS."),(0,r.kt)("p",null,"Features"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Linear and modular scalability."),(0,r.kt)("li",{parentName:"ul"},"Strictly consistent reads and writes."),(0,r.kt)("li",{parentName:"ul"},"Automatic and configurable sharding of tables"),(0,r.kt)("li",{parentName:"ul"},"Automatic failover support between RegionServers."),(0,r.kt)("li",{parentName:"ul"},"Convenient base classes for backing Hadoop MapReduce jobs with Apache HBase tables."),(0,r.kt)("li",{parentName:"ul"},"Easy to use Java API for client access."),(0,r.kt)("li",{parentName:"ul"},"Block cache and Bloom Filters for real-time queries."),(0,r.kt)("li",{parentName:"ul"},"Query predicate push down via server side Filters"),(0,r.kt)("li",{parentName:"ul"},"Thrift gateway and a REST-ful Web service that supports XML, Protobuf, and binary data encoding options"),(0,r.kt)("li",{parentName:"ul"},"Extensible jruby-based (JIRB) shell"),(0,r.kt)("li",{parentName:"ul"},"Support for exporting metrics via the Hadoop metrics subsystem to files or Ganglia; or via JMX")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"image",src:t(941586).Z,width:"1315",height:"986"})),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"image",src:t(984045).Z,width:"1315",height:"986"})),(0,r.kt)("h2",{id:"references"},"References"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Apache_HBase"},"https://en.wikipedia.org/wiki/Apache_HBase")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://hbase.apache.org"},"https://hbase.apache.org")))}d.isMDXComponent=!0},941586:(e,a,t)=>{t.d(a,{Z:()=>i});const i=t.p+"assets/images/Technologies-Apache-Apache-HBase-image1-8ac402031f0bc1c190ee269385ca3e1c.jpg"},984045:(e,a,t)=>{t.d(a,{Z:()=>i});const i=t.p+"assets/images/Technologies-Apache-Apache-HBase-image2-e5824822ab123471c4fb59e36c189af0.jpg"}}]);