"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[10245],{603905:(e,t,r)=>{r.d(t,{Zo:()=>l,kt:()=>d});var a=r(667294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var c=a.createContext({}),m=function(e){var t=a.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},l=function(e){var t=m(e.components);return a.createElement(c.Provider,{value:t},e.children)},p="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),p=m(r),u=n,d=p["".concat(c,".").concat(u)]||p[u]||h[u]||i;return r?a.createElement(d,o(o({ref:t},l),{},{components:r})):a.createElement(d,o({ref:t},l))}));function d(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=u;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[p]="string"==typeof e?e:n,o[1]=s;for(var m=2;m<i;m++)o[m]=r[m];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}u.displayName="MDXCreateElement"},9257:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>m});var a=r(487462),n=(r(667294),r(603905));const i={},o="Others",s={unversionedId:"mathematics/linear-algebra/others",id:"mathematics/linear-algebra/others",title:"Others",description:"Concepts",source:"@site/docs/mathematics/linear-algebra/others.md",sourceDirName:"mathematics/linear-algebra",slug:"/mathematics/linear-algebra/others",permalink:"/mathematics/linear-algebra/others",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/mathematics/linear-algebra/others.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Matrix Transformations",permalink:"/mathematics/linear-algebra/matrix-transformations"},next:{title:"Vectors and Spaces",permalink:"/mathematics/linear-algebra/vectors-and-spaces"}},c={},m=[{value:"Concepts",id:"concepts",level:2},{value:"Norm",id:"norm",level:2},{value:"Vector Norm",id:"vector-norm",level:2}],l={toc:m},p="wrapper";function h(e){let{components:t,...r}=e;return(0,n.kt)(p,(0,a.Z)({},l,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"others"},"Others"),(0,n.kt)("h2",{id:"concepts"},"Concepts"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Matrix factorization"),(0,n.kt)("li",{parentName:"ul"},"Singular value decomposition"),(0,n.kt)("li",{parentName:"ul"},"Moore-Penrose Pseudoinverse"),(0,n.kt)("li",{parentName:"ul"},"Hadamard product"),(0,n.kt)("li",{parentName:"ul"},"Entropy"),(0,n.kt)("li",{parentName:"ul"},"Kullback-Leibler Divergence"),(0,n.kt)("li",{parentName:"ul"},"Gradient Descent\n",(0,n.kt)("a",{parentName:"li",href:"https://www.datacamp.com/community/tutorials/demystifying-mathematics-concepts-deep-learning"},"https://www.datacamp.com/community/tutorials/demystifying-mathematics-concepts-deep-learning"))),(0,n.kt)("h2",{id:"norm"},"Norm"),(0,n.kt)("p",null,"In ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Mathematics"},"mathematics"),", anormis a ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Function_(mathematics)"},"function")," from a real or complex ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Vector_space"},"vector space")," to the nonnegative real numbers that behaves in certain ways like the distance from the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Origin_(mathematics)"},"origin"),": it ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Equivariant_map"},"commutes")," with scaling, obeys a form of the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Triangle_inequality"},"triangle inequality"),", and is zero only at the origin. In particular, the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Euclidean_distance"},"Euclidean distance")," of a vector from the origin is a norm, called the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm"},"Euclidean norm"),", or ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm"},"2-norm"),", which may also be defined as the square root of the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Inner_product"},"inner product")," of a vector with itself.\nApseudonormorseminormsatisfies the first two properties of a norm, but may be zero for other vectors than the origin.A vector space with a specified norm is called a ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Normed_vector_space"},"normed vector space"),". In a similar manner, a vector space with a seminorm is called aseminormed vector space.\n",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Norm_(mathematics)"},"https://en.wikipedia.org/wiki/Norm_(mathematics)")),(0,n.kt)("h2",{id:"vector-norm"},"Vector Norm"),(0,n.kt)("p",null,"Calculating the size or length of a vector is often required either directly or as part of a broader vector or vector-matrix operation.\nThe length of the vector is referred to as the vector norm or the vector's magnitude.\nThe length of a vector is a nonnegative number that describes the extent of the vector in space, and is sometimes referred to as the vector's magnitude or the norm.- The L1 norm that is calculated as the sum of the absolute values of the vector."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"The L2 norm that is calculated as the square root of the sum of the squared vector values."),(0,n.kt)("li",{parentName:"ul"},"The max norm that is calculated as the maximum vector values.\n",(0,n.kt)("a",{parentName:"li",href:"https://machinelearningmastery.com/vector-norms-machine-learning"},"https://machinelearningmastery.com/vector-norms-machine-learning"))))}h.isMDXComponent=!0}}]);