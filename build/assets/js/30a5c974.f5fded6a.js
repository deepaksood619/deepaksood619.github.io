"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[54671],{603905:(e,t,o)=>{o.d(t,{Zo:()=>l,kt:()=>u});var a=o(667294);function s(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function i(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,a)}return o}function r(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?i(Object(o),!0).forEach((function(t){s(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function n(e,t){if(null==e)return{};var o,a,s=function(e,t){if(null==e)return{};var o,a,s={},i=Object.keys(e);for(a=0;a<i.length;a++)o=i[a],t.indexOf(o)>=0||(s[o]=e[o]);return s}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)o=i[a],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(s[o]=e[o])}return s}var c=a.createContext({}),p=function(e){var t=a.useContext(c),o=t;return e&&(o="function"==typeof e?e(t):r(r({},t),e)),o},l=function(e){var t=p(e.components);return a.createElement(c.Provider,{value:t},e.children)},h="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var o=e.components,s=e.mdxType,i=e.originalType,c=e.parentName,l=n(e,["components","mdxType","originalType","parentName"]),h=p(o),d=s,u=h["".concat(c,".").concat(d)]||h[d]||m[d]||i;return o?a.createElement(u,r(r({ref:t},l),{},{components:o})):a.createElement(u,r({ref:t},l))}));function u(e,t){var o=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var i=o.length,r=new Array(i);r[0]=d;var n={};for(var c in t)hasOwnProperty.call(t,c)&&(n[c]=t[c]);n.originalType=e,n[h]="string"==typeof e?e:s,r[1]=n;for(var p=2;p<i;p++)r[p]=o[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,o)}d.displayName="MDXCreateElement"},156901:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>n,toc:()=>p});var a=o(487462),s=(o(667294),o(603905));const i={},r="Consensus Protocols",n={unversionedId:"computer-science/distributed-system/consensus-protocols",id:"computer-science/distributed-system/consensus-protocols",title:"Consensus Protocols",description:"There are a number of ways we can go about replicating the log data. Broadly speaking, we can group the techniques into two different categories:",source:"@site/docs/computer-science/distributed-system/consensus-protocols.md",sourceDirName:"computer-science/distributed-system",slug:"/computer-science/distributed-system/consensus-protocols",permalink:"/computer-science/distributed-system/consensus-protocols",draft:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/main/docs/computer-science/distributed-system/consensus-protocols.md",tags:[],version:"current",lastUpdatedAt:1677955187,formattedLastUpdatedAt:"Mar 4, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Clocks",permalink:"/computer-science/distributed-system/clocks"},next:{title:"Consistency",permalink:"/computer-science/distributed-system/consistency"}},c={},p=[{value:"Gossip/Multicast Protocols",id:"gossipmulticast-protocols",level:2},{value:"Consensus Protocols",id:"consensus-protocols-1",level:2},{value:"Paxos - Consensus over distributed hosts",id:"paxos---consensus-over-distributed-hosts",level:2},{value:"Raft - Consensus Algorithm",id:"raft---consensus-algorithm",level:2},{value:"SWIM",id:"swim",level:2},{value:"Two-Phase Commit Protocol",id:"two-phase-commit-protocol",level:2},{value:"3 Phase Commit",id:"3-phase-commit",level:2},{value:"State Replication",id:"state-replication",level:2},{value:"SAGA (Asynchronous Distributed Transactions)",id:"saga-asynchronous-distributed-transactions",level:2},{value:"Context",id:"context",level:2},{value:"Solution",id:"solution",level:2},{value:"Types of SAGA Implementation",id:"types-of-saga-implementation",level:2},{value:"Gossip / Gossiping",id:"gossip--gossiping",level:2},{value:"FLP Impossibility",id:"flp-impossibility",level:2}],l={toc:p},h="wrapper";function m(e){let{components:t,...i}=e;return(0,s.kt)(h,(0,a.Z)({},l,i,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"consensus-protocols"},"Consensus Protocols"),(0,s.kt)("p",null,"There are a number of ways we can go about replicating the log data. Broadly speaking, we can group the techniques into two different categories:"),(0,s.kt)("h2",{id:"gossipmulticast-protocols"},"Gossip/Multicast Protocols"),(0,s.kt)("p",null,"These tend to be eventually consistent and/or stochastic."),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Epidemic broadcast trees"),(0,s.kt)("li",{parentName:"ul"},"Bimodal multicast"),(0,s.kt)("li",{parentName:"ul"},"SWIM"),(0,s.kt)("li",{parentName:"ul"},"HyParView"),(0,s.kt)("li",{parentName:"ul"},"NeEM")),(0,s.kt)("h2",{id:"consensus-protocols-1"},"Consensus Protocols"),(0,s.kt)("p",null,"These tend to favor strong consistency over availability."),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"2PC/3PC"),(0,s.kt)("li",{parentName:"ul"},"Paxos"),(0,s.kt)("li",{parentName:"ul"},"Raft"),(0,s.kt)("li",{parentName:"ul"},"Zab (Zookeeper atomic broadcast)"),(0,s.kt)("li",{parentName:"ul"},"Chain replication")),(0,s.kt)("h2",{id:"paxos---consensus-over-distributed-hosts"},"Paxos - Consensus over distributed hosts"),(0,s.kt)("p",null,"Ex - doing a leader election among a distributed host."),(0,s.kt)("p",null,"Multi-paxos - models the log as a series of consensus problems, one for each slot in the log\n",(0,s.kt)("a",{parentName:"p",href:"https://lamport.azurewebsites.net/pubs/paxos-simple.pdf"},"Paxos")," is the original distributed consensus algorithm, with modified versions used by ",(0,s.kt)("a",{parentName:"p",href:"https://static.googleusercontent.com/media/research.google.com/en/archive/chubby-osdi06.pdf"},"Chubby")," and many others. (Zookeeper's ",(0,s.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos"},"ZAB")," is similar to Paxos as well.)\n",(0,s.kt)("a",{parentName:"p",href:"https://lamport.azurewebsites.net/tla/paxos-algorithm.html"},"https://lamport.azurewebsites.net/tla/paxos-algorithm.html")),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=JEpsBg0AO6o"},"Paxos lecture (Raft user study)")),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://engineering.fb.com/2022/03/07/core-data/augmenting-flexible-paxos-logdevice"},"https://engineering.fb.com/2022/03/07/core-data/augmenting-flexible-paxos-logdevice")),(0,s.kt)("h2",{id:"raft---consensus-algorithm"},"Raft - Consensus Algorithm"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://raft.github.io/raft.pdf"},"RAFT")," is a much simpler consensus algorithm.\nUsed by -"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Consul"),(0,s.kt)("li",{parentName:"ul"},"Used by etcd (distributed key value store)\n",(0,s.kt)("a",{parentName:"li",href:"https://raft.github.io"},"https://raft.github.io"))),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"http://thesecretlivesofdata.com/raft"},"http://thesecretlivesofdata.com/raft")),(0,s.kt)("h2",{id:"swim"},"SWIM"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/SWIM.pdf"},"SWIM")," is a distributed gossip protocol for group membership (e.g. for determining members of a caching ring, etc)"),(0,s.kt)("h2",{id:"two-phase-commit-protocol"},"Two-Phase Commit Protocol"),(0,s.kt)("p",null,"In ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Transaction_processing"},"transaction processing"),", ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Database"},"databases"),", and ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Computer_networking"},"computer networking"),", thetwo-phase commit protocol(2PC) is a type of ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Atomic_commit"},"atomic commitment protocol"),"(ACP). It is a ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distributed_algorithm"},"distributed algorithm")," that coordinates all the processes that participate in a ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distributed_transaction"},"distributed atomic transaction")," on whether to ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Commit_(data_management)"},"commit")," orabort(roll back) the transaction (it is a specialized type of ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Consensus_(computer_science)"},"consensus")," protocol). The protocol achieves its goal even in many cases of temporary system failure (involving either process, network node, communication, etc. failures), and is thus widely used.However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome. To accommodate recovery from failure (automatic in most cases) the protocol's participants use ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Server_log"},"logging")," of the protocol's states. Log records, which are typically slow to generate but survive failures, are used by the protocol's ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Recovery_procedure"},"recovery procedures"),'. Many protocol variants exist that primarily differ in logging strategies and recovery mechanisms. Though usually intended to be used infrequently, recovery procedures compose a substantial portion of the protocol, due to many possible failure scenarios to be considered and supported by the protocol.\nIn a "normal execution" of any single ',(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distributed_transaction"},"distributed transaction"),"(i.e., when no failure occurs, which is typically the most frequent situation), the protocol consists of two phases:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},(0,s.kt)("strong",{parentName:"p"},"Thecommit-request phase(orvoting phase / prepare phase)"),', in which acoordinatorprocess attempts to prepare all the transaction\'s participating processes (namedparticipants, cohorts, orworkers) to take the necessary steps for either committing or aborting the transaction and tovote, either "Yes": commit (if the transaction participant\'s local portion execution has ended properly), or "No": abort (if a problem has been detected with the local portion), and')),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},(0,s.kt)("strong",{parentName:"p"},"Thecommit phase"),', in which, based onvotingof the participants, the coordinator decides whether to commit (only ifallhave voted "Yes") or abort the transaction (otherwise), and notifies the result to all the participants. The participants then follow with the needed actions (commit or abort) with their local transactional resources (also calledrecoverable resources; e.g., database data) and their respective portions in the transaction\'s other output (if applicable).\n',(0,s.kt)("img",{alt:"image",src:o(447687).Z,width:"1101",height:"962"}),"\n",(0,s.kt)("img",{alt:"image",src:o(784546).Z,width:"1120",height:"690"})))),(0,s.kt)("p",null,"Two-phase commit is a blocking protocol. The coordinator blocks waiting for votes from its cohorts, and cohorts block waiting for a commit/rollback message from the coordinator. Unfortunately, this means 2PC can, in some circumstances, result in a deadlock, e.g. the coordinator dies while cohorts wait or a cohort dies while the coordinator waits. Another problematic scenario is when a coordinator and cohort simultaneously fail. Even if another coordinatortakes its place, it won't be able to determine whether to commit or rollback.\n",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Two-phase_commit_protocol"},"https://en.wikipedia.org/wiki/Two-phase_commit_protocol")),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://bravenewgeek.com/understanding-consensus/"},(0,s.kt)("strong",{parentName:"a"},"https://bravenewgeek.com/understanding-consensus/"))),(0,s.kt)("h2",{id:"3-phase-commit"},"3 Phase Commit"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"image",src:o(480226).Z,width:"1100",height:"951"}),"\n",(0,s.kt)("img",{alt:"image",src:o(824719).Z,width:"1130",height:"944"})),(0,s.kt)("p",null,'Three-phase commit (3PC) is designed to solve the problems identified in two-phase by implementing a non-blocking protocol with an added "prepare" phase. Like 2PC, it relies on a coordinator which relays messages to its cohorts.\nUnlike 2PC, cohorts do not executea transaction during the voting phase. Rather, they simply indicate if they are prepared to perform the transaction. If cohorts timeout during this phase or there is one or more "no" vote, the transaction is aborted. If the vote is unanimously "yes," the coordinator moves on to the "prepare" phase, sending a message to its cohorts to acknowledge the transaction will be committed. Again, if an ack times out, the transactionis aborted. Once all cohorts have acknowledged the commit, we are guaranteed to be in a state where ',(0,s.kt)("em",{parentName:"p"},"all"),"cohorts have agreed to commit. At this point, if the commit message from the coordinator is not received in the third phase, the cohort will go ahead and commit anyway. This solves the deadlocking problems described earlier. However, 3PC is still susceptible to network partitions. If a partition occurs, the coordinator will timeout and progress will not be made.\n",(0,s.kt)("a",{parentName:"p",href:"https://bravenewgeek.com/understanding-consensus"},"https://bravenewgeek.com/understanding-consensus")),(0,s.kt)("h2",{id:"state-replication"},"State Replication"),(0,s.kt)("p",null,"Protocols like ",(0,s.kt)("a",{parentName:"p",href:"https://ramcloud.stanford.edu/raft.pdf"},"Raft"),", ",(0,s.kt)("a",{parentName:"p",href:"http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf"},"Paxos"),", and ",(0,s.kt)("a",{parentName:"p",href:"http://web.stanford.edu/class/cs347/reading/zab.pdf"},"Zab")," are popular and widely used solutions to the problem of distributed consensus. These implement state replication or primary-backup using leaders, quorums, and replicas of operation logs or incremental delta states."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"image",src:o(146573).Z,width:"1098",height:"704"})),(0,s.kt)("p",null,"These protocols workby electing a leader (coordinator). Like multi-phase commit, all changes must go through thatleader, who then broadcasts the changes to the group. Changes occur by appending a log entry, and each node has its own log replica. Where multi-phase commit falls down in the face of network partitions, these protocols are able to continue working by relying on a quorum (majority). The leader commits the change once the quorum has acknowledged it.\nThe use of quorums provide partition tolerance by fencing minority partitions while the majority continues to operate.This is the pessimistic approach to solving split-brain, so it comes with an inherent availability trade-off. This problem is mitigated by the fact that each node hosts a replicated state machine which can be rebuilt or reconciled once the partition is healed.\nGoogle relies on Paxos for its high-replication datastore in App Engine as well as its ",(0,s.kt)("a",{parentName:"p",href:"http://static.googleusercontent.com/media/research.google.com/en/us/archive/chubby-osdi06.pdf"},"Chubby lock service"),". The distributed key-value store ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/coreos/etcd"},"etcd")," uses Raft to manage highly available replicated logs. Zab, which differentiates itself from the former by implementing a primary-backup protocol, was designed for the ",(0,s.kt)("a",{parentName:"p",href:"http://zookeeper.apache.org/"},"ZooKeeper")," coordination service. In general, there are several different implementations of these protocols, such as the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/goraft/raft"},"Go implementation")," of Raft.\n",(0,s.kt)("a",{parentName:"p",href:"https://bravenewgeek.com/understanding-consensus"},"https://bravenewgeek.com/understanding-consensus")),(0,s.kt)("h2",{id:"saga-asynchronous-distributed-transactions"},"SAGA (Asynchronous Distributed Transactions)"),(0,s.kt)("h2",{id:"context"},"Context"),(0,s.kt)("p",null,"You have applied the ",(0,s.kt)("a",{parentName:"p",href:"https://microservices.io/patterns/data/database-per-service.html"},"Database per Service")," pattern. Each service has its own database. Some business transactions, however, span multiple service so you need a mechanism to implement transactions that span services. For example, let's imagine that you are building an e-commerce store where customers have a credit limit. The application must ensure that a new order will not exceed the customer's credit limit. Since Orders and Customers are in different databases owned by different services the application cannot simply use a local ACID transaction."),(0,s.kt)("h2",{id:"solution"},"Solution"),(0,s.kt)("p",null,"Implement each business transaction that spans multiple services is a saga. A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions."),(0,s.kt)("h2",{id:"types-of-saga-implementation"},"Types of SAGA Implementation"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Choreography - Event based")),(0,s.kt)("p",null,"Each local transaction publishes domain events that trigger local transactions in other services\n",(0,s.kt)("img",{alt:"image",src:o(740930).Z,width:"1098",height:"622"}),"\n2. Orchestration - Command based"),(0,s.kt)("p",null,"An orchestrator (object) tells the participants what local transactions to execute\n",(0,s.kt)("img",{alt:"image",src:o(797043).Z,width:"1098",height:"603"}),"\nYoutube - ",(0,s.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=WnZ7IcaN_JA"},"SAGA | Microservices Architecture Patterns | Tech Primers")),(0,s.kt)("p",null,"Youtube - ",(0,s.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=S4FnmSeRpAY"},"Do you know Distributed transactions?")),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://microservices.io/patterns/data/saga.html"},"https://microservices.io/patterns/data/saga.html")),(0,s.kt)("h2",{id:"gossip--gossiping"},"Gossip / Gossiping"),(0,s.kt)("p",null,"Agossip protocolis a procedure or process of computer peer-to-peer communication that is based on the way that ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Epidemic"},"epidemics")," spread. Some ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distributed_computing"},"distributed systems")," use peer-to-peer gossip to ensure that data is routed to all members of an ad-hoc network. Some ad-hoc networks have no central registry and the only way to spread common data is to rely to each member to pass it along to their neighbors."),(0,s.kt)("p",null,"The termepidemic protocolis sometimes used as a synonym for a gossip protocol, because gossip spreads information in a manner similar to the spread of a ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Virus"},"virus")," in a biological community.\n",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Gossip_protocol"},"https://en.wikipedia.org/wiki/Gossip_protocol")),(0,s.kt)("h2",{id:"flp-impossibility"},"FLP Impossibility"),(0,s.kt)("p",null,"States that reaching a multi-party consensus in a asynchronous system is not possible and, in order for consensus to be reachable, we need",(0,s.kt)("strong",{parentName:"p"},"Failure Detectors"),".\nIn order for processes to agree, several invariants have to be persevered:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},'value that\'s being agreed on has to be "proposed" by one of the participants'),(0,s.kt)("li",{parentName:"ul"},"all active (non-crashed) participants have to decide on the value"),(0,s.kt)("li",{parentName:"ul"},"value they eventually decide on has to be the same for all processes\nIn a ",(0,s.kt)("a",{parentName:"li",href:"https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf"},"paper")," by Fisher, Lynch and Paterson, famously known asFLP Impossibility Problem(derived from the first letters of authors' last names), authors discuss a weak form of consensus in which processes start with an initial value and have to achieve an agreement on a new value. This new value has to be the same for all non-faulty processes.\nPaper concludes that in anasynchronous system, no consensus protocol can be totally correct in presence of even a single fault. If we do not consider an upper time bound for process to complete the algorithm steps and if process failures can't be reliably detected, FLP paper shows that there's no deterministic algorithm to reach a consensus.\nHowever, FLP proof does not mean we have to pack our things and go home, as reaching consensus is not possible. It only means that it can't always be reached in bounded time. In practice, systems exhibit partial synchronicity, which puts partially synchronous system between the cases of asynchronous and synchronous ones. Nancy Lynch, one of the FLP proof authors, has later authored ",(0,s.kt)("a",{parentName:"li",href:"http://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf"},"Consensus in the Presence of Partial Synchrony")," paper, where several partially synchronous models are discussed, one of them holding timing assumptions that are not known in advance and the other one, where timing assumptions are known, but start holding up at an unknown time.\n",(0,s.kt)("a",{parentName:"li",href:"https://medium.com/databasss/on-ways-to-agree-part-1-links-and-flp-impossibility-f6bd8a6a0980"},"https://medium.com/databasss/on-ways-to-agree-part-1-links-and-flp-impossibility-f6bd8a6a0980"))))}m.isMDXComponent=!0},447687:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image1-85288d52b87d5f651b6c919e598f4ec8.jpg"},784546:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image2-2cab3fb5d47b85a8bb33891da465e494.jpg"},480226:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image3-dbdace4ddc249f4eb80ad46ee9a18031.jpg"},824719:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image4-fdfe10903653595e56e49681a49a6be1.jpg"},146573:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image5-f692d2115d7bd4737d8dee677ee9058e.jpg"},740930:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image6-d643fdead345a2a59037acb3c18d6549.jpg"},797043:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/Consensus-Protocols-image7-3b99e4372b1e86800dcf8ce374708334.jpg"}}]);