# Intro

LLM makes good programmers great, and not make bad programmers good

Moving from information to knowledge age

LMM - Large Multimodel Model

## LLM

- A large language model (LLM) is a type of artificial intelligence program that can recognize and generate text, among other tasks.
- LLM are very large models that are pre-trained on vast amounts of data.
- Built on transformer architecture, it is a set of neural network that consist of an encoder and a decoder with self-attention capabilities.
- It can perform completely different tasks such as answering questions, summarizing documents, translating languages and completing sentences.
- Open AI's GPT-3 model has 175 billion parameters. Also it can take inputs up to 10K tokens in each prompt.
- In simpler terms, an LLM is a computer program that has been fed enough examples to be able to recognize and interpret human language or other types of complex data.
- Quality of the samples impacts how well LLMs will learn natural language, so an LLM's programmers may use a more curated data set.

## Types

### Base LLM

- Predicts next word, based on text training data
- Prompt - What is the capital of France?
- Ans - What is France's largest city?
- Ans - What is France's population?

### Instruction Tuned LLM

- Tries to follow instructions
- Fine-tune on instructions and good attempts at following those instructions.
- RLHF: Reinforcement Learning with Human Feedback - [Human Feedback in AI: The Essential Ingredient for Success | Label Studio](https://labelstud.io/blog/human-feedback-in-ai/) [Create a High-Quality Dataset for RLHF | Label Studio](https://labelstud.io/blog/create-a-high-quality-rlhf-dataset/)
- Helpful, Honest, Harmless
- Prompt - What is the capital of France?
- Ans - The capital of France is Paris.

## GPT-3 / GPT-4

Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. Given an initial text as prompt, it will produce text that continues the prompt.

The architecture is a standard [transformer network](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))(with a few engineering tweaks) with the unprecedented size of 2048-token-long context and 175 billion [parameters](https://en.wikipedia.org/wiki/Parameter_(machine_learning))(requiring 800 GB of storage). The training method is "generative pretraining", meaning that it is trained to predict what the next token is. The model demonstrated strong [few-shot learning](https://en.wikipedia.org/wiki/Few-shot_learning) on many text-based tasks.

## Past Present & Future

- ["The Past, Present, and Future of GenAI" - Yariv Adan, Google - KEYNOTE at PMF23 - YouTube](https://www.youtube.com/watch?v=-JYbMh4xEos)
- [Generative AI: Past, Present, and Future – A Practitioner's Perspective | PPT](https://www.slideshare.net/slideshow/genaipdf/260536464)
- [The AI Revolution Is Underhyped \| Eric Schmidt \| TED - YouTube](https://www.youtube.com/watch?v=id4YRO7G0wE)
- [How People Are Really Using Gen AI in 2025](https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025)

![Major Gen AI Use Case 2025](../../media/Screenshot%202025-05-18%20at%201.08.37%20PM.jpg)

## Misconceptions

1. LLMs Actually Understand Language Like Humans Do
2. More Parameters Always Mean Better Performance
3. LLMs Are Just Autocomplete on Steroids
4. LLMs Are Just Autocomplete on Steroids
5. Fine-Tuning Always Makes Models Better
6. LLMs Are Deterministic: Same Input, Same Output
7. Bigger Context Windows Are Always Better
8. LLMs Can Replace Traditional Machine Learning for All Language Tasks
9. Prompt Engineering Is Just Trial and Error
10. LLMs Will Soon Replace All Software Developers

[10 Common Misconceptions About Large Language Models - MachineLearningMastery.com](https://machinelearningmastery.com/10-common-misconceptions-about-large-language-models/)

## Datasets

[MMLU Dataset | Papers With Code](https://paperswithcode.com/dataset/mmlu) - Massive Multitask Language Understanding

## Links

- [How to create a private ChatGPT with your own data | by Mick Vleeshouwer | Mar, 2023 | Medium](https://medium.com/@imicknl/how-to-create-a-private-chatgpt-with-your-own-data-15754e6378a1)
- [I Built a Hedge Fund Run by AI Agents - YouTube](https://www.youtube.com/watch?v=vnzt4lwzbXU)
- [State of GPT | BRK216HFS - YouTube](https://www.youtube.com/watch?v=bZQun8Y4L2A)
- [EMERGENCY EPISODE: Ex-Google Officer Finally Speaks Out On The Dangers Of AI! - Mo Gawdat | E252 - YouTube](https://www.youtube.com/watch?v=bk-nQ7HF6k4)
- [WARNING: ChatGPT Could Be The Start Of The End! Sam Harris - YouTube](https://www.youtube.com/watch?v=GmlrEgLGozw)
- [Getting Started with LLMs: A Quick Guide to Resources and Opportunities](https://www.linkedin.com/pulse/getting-started-llms-guide-resources-opportunities-wendy-ran-wei/)
- [DoctorGPT: Offline & Passes Medical Exams! - YouTube](https://www.youtube.com/watch?v=J9nJh33GM-w)
- [The AI-Powered Tools Supercharging Your Imagination | Bilawal Sidhu | TED - YouTube](https://www.youtube.com/watch?v=eZsVDMsBTCQ)
- [The True Cost of Compute - YouTube](https://www.youtube.com/watch?v=MNFeJNUu074)
- [Welcome to State of AI Report 2023](https://www.stateof.ai/)
- [State of AI Report 2023 - ONLINE - Google Slides](https://docs.google.com/presentation/d/156WpBF_rGvf4Ecg19oM1fyR51g4FAmHV3Zs0WLukrLQ/edit)
- [[#29] AI Evolution: From AlexNet to Generative AI - Redefining the Paradigm of Software Development](https://bizit.substack.com/p/29-ai-evolution-from-alexnet-to-generative)
- [Google "We Have No Moat, And Neither Does OpenAI"](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)
- [AGI-Proof Jobs: Navigating the Impending Obsolescence of Human Labor in the Age of AGI - YouTube](https://www.youtube.com/watch?v=Ahh92qtRwos&ab_channel=DavidShapiro)
- [A DeepMind AI rivals the world's smartest high schoolers at geometry](https://www.understandingai.org/p/a-deepmind-ai-rivals-the-worlds-smartest)
- [New Theory Suggests Chatbots Can Understand Text | Quanta Magazine](https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/)
- [The case for-and against-rapid AI-driven growth](https://www.understandingai.org/p/the-case-forand-againstrapid-ai-driven)
- [What I learned from looking at 900 most popular open source AI tools](https://huyenchip.com/2024/03/14/ai-oss.html)
- [Exploring GaiaNet: The Future of Decentralized AI | The Perfect Blend of Web 3.0 and AI - YouTube](https://www.youtube.com/watch?v=C5tCaeOkpps)
- [Generative AI | PPT](https://www.slideshare.net/slideshow/generative-ai-259922340/259922340#2)
- [Foundational Models and Compute Trends - by Bugra Akyildiz](https://mlops.substack.com/p/foundational-models-and-compute-trends)
- [What if LLM is the ultimate data janitor](https://mlops.substack.com/p/what-if-llm-is-the-ultimate-data)
- [How to build an infrastructure from scratch to train a 70B Model?](https://mlops.substack.com/p/how-to-build-an-infrastructure-from)
- [On the Factory Floor: ML Engineering for Industrial-Scale Ads Recommendation Models from Google](https://mlops.substack.com/p/on-the-factory-floor-ml-engineering)
- [Financial Statement Analysis with Large Language Models](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311)
- [Scaling Meta’s Infra with GenAI: Journey to faster and smarter Incident Response - YouTube](https://www.youtube.com/watch?v=rpe7eAR90Ko)
- [AWS re:Invent 2023 - Navigating the future of AI: Deploying generative models on Amazon EKS (CON312) - YouTube](https://www.youtube.com/watch?v=I22pIUSgseA)
- [GenAI Training In Production: Software, Hardware & Network Considerations - YouTube](https://www.youtube.com/watch?v=1lhrGRqqPWU)
- [How I Use "AI"](https://nicholas.carlini.com/writing/2024/how-i-use-ai.html)
- [How might LLMs store facts | Chapter 7, Deep Learning - YouTube](https://www.youtube.com/watch?v=9-Jl0dxWQs8)
- [Introduction to Generative AI - YouTube](https://www.youtube.com/watch?v=cZaNf2rA30k)
- [Introduction to Large Language Models - YouTube](https://www.youtube.com/watch?v=RBzXsQHjptQ)
- [Welcome to State of AI Report 2024](https://www.stateof.ai/2024-report-launch)
- [How Much Trust Do You Have with LLM-Based Solutions? • Matthew Salmon • GOTO 2024 - YouTube](https://www.youtube.com/watch?v=uMhmvba7Z3I)
- [Building LLMs from the Ground Up: A 3-hour Coding Workshop - YouTube](https://www.youtube.com/watch?v=quh7z1q7-uc)
- [3Blue1Brown - Large Language Models explained briefly](https://www.3blue1brown.com/lessons/mini-llm)
- [Generative AI Fine Tuning LLM Models Crash Course - YouTube](https://youtu.be/t-0s_2uZZU0)
- [A Visual Guide to LLM Agents - by Maarten Grootendorst](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents)
- [\[2205.11916\] Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)
- [BERT Demystified: Like I’m Explaining It to My Younger Self](https://youtu.be/NUf5q4cWhdQ)
- [I got fooled by AI-for-science hype—here's what it taught me](https://www.understandingai.org/p/i-got-fooled-by-ai-for-science-hypeheres)
- [Why Finishing with AI Feels Harder Than Starting- My Confessions](https://www.thetoolnerd.com/p/why-finishing-with-ai-feels-harder)
- [Artificial Intelligence (AI) : 20 Must Know Terminology (Basics to Advanced)](https://www.thetoolnerd.com/p/artificial-intelligence-ai-20-must-know-terminology-thetoolnerd)
- [I think this is one of the best moments to be an AI/ML Engineer! \| Alex Razvant](https://www.linkedin.com/posts/arazvant_i-think-this-is-one-of-the-best-moments-to-activity-7363125145726517250-QJ3N?)
- [LLMs + Coding Agents = Security Nightmare](https://garymarcus.substack.com/p/llms-coding-agents-security-nightmare)
- [Networked Saas is the new AI business model replacing per-seat pricing](https://www.signalfire.com/blog/networked-saas-business-model-is-replacing-per-seat-pricing)
- [Showing Delivery Date at 10x Scale with 1/10th Latency \| by Dhruvik Shah \| Flipkart Tech Blog](https://blog.flipkart.tech/showing-delivery-sla-at-10x-scale-with-1-10th-latency-28b17b198cc8)
- [Language Models as Fact Checkers? \| Research - AI at Meta](https://ai.meta.com/research/publications/language-models-as-fact-checkers/)
- [How LLMs Handle Infinite Context With Finite Memory \| Towards Data Science](https://towardsdatascience.com/llms-can-now-process-infinite-context-windows/)
