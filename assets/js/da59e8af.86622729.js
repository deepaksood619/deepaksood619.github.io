"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[67466],{283483:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"data-warehouses/concepts/data-engineering-challenges","title":"Data Engineering Challenges","description":"1. Elimination of Data Silos - Unified Lakehouse Architecture","source":"@site/docs/data-warehouses/concepts/data-engineering-challenges.md","sourceDirName":"data-warehouses/concepts","slug":"/data-warehouses/concepts/data-engineering-challenges","permalink":"/data-warehouses/concepts/data-engineering-challenges","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/data-warehouses/concepts/data-engineering-challenges.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1750702471000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Change Data Capture (CDC)","permalink":"/data-warehouses/concepts/change-data-capture-cdc"},"next":{"title":"Data Engineering","permalink":"/data-warehouses/concepts/data-engineering"}}');var t=a(474848),s=a(28453);const r={},l="Data Engineering Challenges",o={},d=[{value:"1. Elimination of Data Silos - Unified Lakehouse Architecture",id:"1-elimination-of-data-silos---unified-lakehouse-architecture",level:3},{value:"2. Universal Real-Time Data Pipeline",id:"2-universal-real-time-data-pipeline",level:3},{value:"3. Common Query Abstraction Layer",id:"3-common-query-abstraction-layer",level:3},{value:"4. Robust Metadata and Centralised Data Catalog",id:"4-robust-metadata-and-centralised-data-catalog",level:3},{value:"5. Observability and Monitoring of Pipelines",id:"5-observability-and-monitoring-of-pipelines",level:3},{value:"6. Standardised Data Quality Framework",id:"6-standardised-data-quality-framework",level:3},{value:"7. CI/CD for Data Pipelines",id:"7-cicd-for-data-pipelines",level:3},{value:"8. Cost Optimisation &amp; Resource Governance",id:"8-cost-optimisation--resource-governance",level:3}];function c(e){const n={h1:"h1",h3:"h3",header:"header",li:"li",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"data-engineering-challenges",children:"Data Engineering Challenges"})}),"\n",(0,t.jsx)(n.h3,{id:"1-elimination-of-data-silos---unified-lakehouse-architecture",children:"1. Elimination of Data Silos - Unified Lakehouse Architecture"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Challenge:"})," Multiple data sources leading to fragmented analytics, duplication, and inconsistency."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Design and implement a centralised Lakehouse architecture to unify batch and streaming data, enabling a single source of truth for structured and semi-structured data."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-universal-real-time-data-pipeline",children:"2. Universal Real-Time Data Pipeline"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Challenge:"})," Inability to handle seamless real-time ingestion and sync between varied data systems."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Build a real-time data pipeline framework that supports data migration across heterogeneous sources and sinks such as:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sources:"})," MySQL, PostgreSQL, MariaDB, MongoDB, Kafka"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Destinations:"})," Redshift, Databricks, Iceberg-based tables, BigQuery, etc."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Should support change data capture (CDC), schema evolution, and backfill."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-common-query-abstraction-layer",children:"3. Common Query Abstraction Layer"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Challenge:"})," Reporting systems break or require rework when data warehouses are switched."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Introduce a semantic or federated query layer which enables Standard SQL-based querying across different storage engines, ensuring reporting tools continue to function without rewriting queries"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"4-robust-metadata-and-centralised-data-catalog",children:"4. Robust Metadata and Centralised Data Catalog"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Challenge:"})," Lack of visibility into data flow and transformations across the pipeline."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Build or integrate a searchable data catalog that includes table descriptions, column definitions, data freshness, owners, and usage metrics. Implement a metadata governance tool to track data lineage, schema changes, ownership, and business glossary."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"5-observability-and-monitoring-of-pipelines",children:"5. Observability and Monitoring of Pipelines"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Introduce monitoring and alerting for pipeline health, data quality issues, latency, and SLA breaches"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"6-standardised-data-quality-framework",children:"6. Standardised Data Quality Framework"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Establish a rule-based or ML-powered data quality layer for anomaly detection, null checks, duplicate checks, and type mismatches \u2014 embedded in the pipeline."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"7-cicd-for-data-pipelines",children:"7. CI/CD for Data Pipelines"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Adopt modern DevOps practices for data engineering including pipeline-as-code, version control, automated testing"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"8-cost-optimisation--resource-governance",children:"8. Cost Optimisation & Resource Governance"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Requirement:"})," Optimise compute/storage costs across platforms/pipelines"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>l});var i=a(296540);const t={},s=i.createContext(t);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);