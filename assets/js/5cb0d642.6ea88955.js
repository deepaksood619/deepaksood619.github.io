"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[55453],{575167:(e,a,r)=>{r.r(a),r.d(a,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"technologies/kafka/kafka-brokers","title":"Kafka Brokers","description":"In Kafka,\xa0brokers\xa0are the servers that store data and handle all data streaming requests. When you run Kafka, each instance of the Kafka server process is a\xa0broker. These brokers can be deployed on physical machines, cloud instances, or even Raspberry Pis. Each broker stores\xa0partitions\xa0of\xa0topics, allowing Kafka to distribute storage and processing across multiple servers for scalability and reliability.","source":"@site/docs/technologies/kafka/kafka-brokers.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/kafka-brokers","permalink":"/technologies/kafka/kafka-brokers","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/kafka-brokers.md","tags":[],"version":"current","lastUpdatedBy":"Deeapak Sood","lastUpdatedAt":1765826756000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka Architecture","permalink":"/technologies/kafka/kafka-architecture"},"next":{"title":"Kafka Commands","permalink":"/technologies/kafka/kafka-commands"}}');var t=r(474848),n=r(28453);const o={},i="Kafka Brokers",c={},l=[];function d(e){const a={a:"a",h1:"h1",header:"header",p:"p",strong:"strong",...(0,n.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"kafka-brokers",children:"Kafka Brokers"})}),"\n",(0,t.jsxs)(a.p,{children:["In Kafka,\xa0",(0,t.jsx)(a.strong,{children:"brokers"}),"\xa0are the servers that store data and handle all data streaming requests. When you run Kafka, each instance of the Kafka server process is a\xa0",(0,t.jsx)(a.strong,{children:"broker"}),". These brokers can be deployed on physical machines, cloud instances, or even Raspberry Pis. Each broker stores\xa0",(0,t.jsx)(a.strong,{children:"partitions"}),"\xa0of\xa0",(0,t.jsx)(a.strong,{children:"topics"}),", allowing Kafka to distribute storage and processing across multiple servers for scalability and reliability."]}),"\n",(0,t.jsxs)(a.p,{children:["A group of brokers forms a\xa0",(0,t.jsx)(a.strong,{children:"Kafka cluster"}),". In this cluster, each broker is responsible for handling\xa0",(0,t.jsx)(a.strong,{children:"read"}),"\xa0and\xa0",(0,t.jsx)(a.strong,{children:"write"}),"\xa0requests from clients. When data is written to a topic, it's actually written to a specific\xa0",(0,t.jsx)(a.strong,{children:"partition"}),"\xa0on one of the brokers. Similarly, when consumers read from a topic, they pull data directly from the partition on the broker where it's stored. This distribution across multiple brokers is what enables Kafka to scale massively while maintaining high throughput."]}),"\n",(0,t.jsxs)(a.p,{children:["Historically, Kafka used\xa0",(0,t.jsx)(a.strong,{children:"Apache ZooKeeper"}),"\xa0for managing metadata and coordinating the brokers. However, starting with\xa0",(0,t.jsx)(a.strong,{children:"Kafka 4.0"}),", this changed. ZooKeeper was replaced by\xa0",(0,t.jsx)(a.strong,{children:"KRaft"}),", a built-in metadata management system based on the\xa0",(0,t.jsx)(a.strong,{children:"Raft consensus protocol"}),". This means brokers now handle their own metadata synchronization, simplifying the architecture and improving efficiency."]}),"\n",(0,t.jsxs)(a.p,{children:["If you're using\xa0",(0,t.jsxs)(a.a,{href:"https://www.confluent.io/confluent-cloud/?session_ref=https%3A%2F%2Fdeveloper.confluent.io%2Fcertification%2F%3Futm_medium%3Dsem%26utm_source%3Dgoogle%26utm_campaign%3Dch.sem_br.nonbrand_tp.prs_tgt.dsa_mt.dsa_rgn.apac_sbrgn.india_lng.eng_dv.all_con.confluent-developer%26utm_term%3D%26creative%3D%26device%3Dc%26placement%3D%26gad_source%3D1%26gad_campaignid%3D19560855030%26gbraid%3D0AAAAADRv2c1DOIOBAozJI6eYpioovMyoo%26gclid%3DCj0KCQiA9OnJBhD-ARIsAPV51xMQxq7e-jC0tkvQIDYfH3lARfj6MxXPSd6vORc94KGXIYCsASdOvvcaApazEALw_wcB",children:["a\xa0",(0,t.jsx)(a.strong,{children:"cloud-native service"}),"\xa0like\xa0",(0,t.jsx)(a.strong,{children:"Confluent Cloud"})]}),", the details of brokers are mostly abstracted away\u2014you focus on topics and streams, while the service manages the brokers for you. But when running Kafka on your own, understanding brokers and how they manage partitions is crucial for optimizing performance and ensuring reliability."]}),"\n",(0,t.jsxs)(a.p,{children:["In summary,\xa0",(0,t.jsx)(a.strong,{children:"brokers"}),"\xa0are the backbone of Kafka's distributed storage and processing, managing partitions, handling client requests, and now, as of Kafka 4.0, coordinating metadata directly through KRaft."]}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.a,{href:"https://developer.confluent.io/courses/apache-kafka/brokers/",children:"Kafka Brokers: The Backbone of a Distributed Cluster"})})]})}function h(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,a,r)=>{r.d(a,{R:()=>o,x:()=>i});var s=r(296540);const t={},n=s.createContext(t);function o(e){const a=s.useContext(n);return s.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(n.Provider,{value:a},e.children)}}}]);