"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[75691],{413256:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"cloud/aws/cli-commands","title":"CLI Commands","description":"AWS cli (brew install awscli)","source":"@site/docs/cloud/aws/cli-commands.md","sourceDirName":"cloud/aws","slug":"/cloud/aws/cli-commands","permalink":"/cloud/aws/cli-commands","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/cloud/aws/cli-commands.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1761587427000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"AWS Services","permalink":"/cloud/aws/aws-services"},"next":{"title":"Compute","permalink":"/cloud/aws/compute/"}}');var t=n(474848),o=n(28453);const i={},r="CLI Commands",c={},l=[{value:"AWS cli (brew install awscli)",id:"aws-cli-brew-install-awscli",level:2},{value:"Download / Upload folder / bucket from s3",id:"download--upload-folder--bucket-from-s3",level:2},{value:"RDS + Route53",id:"rds--route53",level:2},{value:"Cleanups",id:"cleanups",level:2},{value:"Tools",id:"tools",level:2},{value:"awslog",id:"awslog",level:3}];function d(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"cli-commands",children:"CLI Commands"})}),"\n",(0,t.jsx)(s.h2,{id:"aws-cli-brew-install-awscli",children:"AWS cli (brew install awscli)"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'pip install awscli\n\nGraphical installer - https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html\n\n# Linux\ncurl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"\n\nunzip awscliv2.zip\n\nsudo ./aws/install\n\nhttps://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html\n\naws configure list-profiles\naws configure list\n\naws configure\nregion - ap-south-1\noutput - json\n\n# adding new profile\naws configure --profile zen\naws ec2 describe-instances --profile {{profile_name}}\n# query to filter based on Hypervisor\n--query "Reservations[].Instances[?Hypervisor==\'xen\' && State.Name==\'running\'].[InstanceId,InstanceType,Placement.AvailabilityZone]"\n\naws s3 ls --profile zen\n\n# set default profile\nexport AWS_DEFAULT_PROFILE=personal\n\n# get current user\naws sts get-caller-identity\n\naws sts get-access-key-info --access-key-id AKIAU2R6AAK3KKWSWRFU\n\naws organizations describe-account --account-id 331916247734\n\naws s3 ls s3://migration-data/year=2020/month=05/day=09/1334d4026463437b\n\naws s3 mb s3://bigbet90 --region us-west-2\n\naws s3 presign s3://bigbet90/index.html --expires-in 90 # in seconds max 36 hours\n\naws s3 cp aws.jpg s3://bigbet90 --region us-west-2 --endpoint-url https://bigbet90.s3-accelerate.amazonaws.com\n'})}),"\n",(0,t.jsx)(s.h2,{id:"download--upload-folder--bucket-from-s3",children:"Download / Upload folder / bucket from s3"}),"\n",(0,t.jsxs)(s.p,{children:["The aws S3 sync command uses the CopyObject APIs to copy objects between Amazon S3 buckets. The sync command lists the source and target buckets to identify objects that are in the source bucket but that aren't in the target bucket. The command also identifies objects in the source bucket that have different LastModified dates than the objects that are in the target bucket. ",(0,t.jsx)(s.strong,{children:"The sync command on a versioned bucket copies only the current version of the object\u2014previous versions aren't copied."})," By default, this preserves object metadata, but the access control lists (ACLs) are set to FULL_CONTROL for your AWS account, which removes any additional ACLs. If the operation fails, you can run the sync command again without duplicating previously copied objects."]}),"\n",(0,t.jsx)(s.p,{children:"You can use the command like so:"}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.code,{children:"aws s3 sync s3://DOC-EXAMPLE-BUCKET-SOURCE s3://DOC-EXAMPLE-BUCKET-TARGET"})}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws s3 sync\n\naws s3 sync . s3://bigbet90\n\naws s3 sync s3://source-bucket/source-path ./local_folder\n\naws s3 sync test s3://storage-dev/test\n\naws s3api get-object --bucket DOC-EXAMPLE-BUCKET1--key dir/my_images.tar.bz2 my_images.tar.bz2\n\n## download file\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=XXX aws s3 cp s3://2022-03-07-12-44-11-7946.jpg 2022-03-07-12-44-11-7946.jpg\n\n# Upload a file to s3\nAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=XXX aws s3 cp s3://<folder_name>/sms_data_oct_20_to_feb_21_new.csv sms_data_oct_20_to_feb_21_new.csv\n\naws iam delete-policy --policy-arn arn:aws:iam::331916247734:policy/ssh_update_policy\n\n# personal sync\naws s3 sync . s3://deep-personal-bucket/photos --storage-class DEEP_ARCHIVE --cli-read-timeout 0 --cli-connect-timeout 0\n\naws s3 cp abc.zip s3://deep-personal-bucket/photos/abc.zip --storage-class DEEP_ARCHIVE\n"})}),"\n",(0,t.jsx)(s.h2,{id:"rds--route53",children:"RDS + Route53"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws rds create-db-instance --db-instance-identifier <db_name> --db-cluster-identifier db_name --engine aurora-mysql --db-instance-class db.r5.2xlarge --availability-zone ap-south-1b\n\naws rds delete-db-instance --db-instance-identifier <db_name>\n\naws rds modify-db-parameter-group --db-parameter-group-name [aurora-data-analytics-group](https://ap-south-1.console.aws.amazon.com/rds/home?region=ap-south-1#parameter-groups-detail:ids=aurora-data-analytics-group;type=DbParameterGroup;editing=false) --parameters \"ParameterName='max_execution_time',ParameterValue=3200000,ApplyMethod=immediate\"\n\naws rds modify-db-parameter-group --db-parameter-group-name aurora-prod-db-write-group --parameters \"ParameterName='max_execution_time',ParameterValue=1500000,ApplyMethod=immediate\"\n\naws rds create-db-instance-read-replica \\\n--source-db-instance-identifier django-master \\\n--db-instance-identifier django-daily \\\n--availability-zone ap-south-1a \\\n--db-instance-class db.m5.8xlarge \\\n--no-multi-az \\\n--storage-type gp3 \\\n--enable-performance-insights \\\n--performance-insights-kms-key-id 8044ba2e-b763-4649-b41f-ed4867e76f67 \\ --performance-insights-retention-period 7 \\\n--enable-cloudwatch-logs-exports slowquery \\\n--no-deletion-protection \\\n--allocated-storage 450 \\\n--no-auto-minor-version-upgrade \\\n--region ap-south-1\n\naws rds delete-db-instance \\ --db-instance-identifier django-daily \\ --skip-final-snapshot \\ --delete-automated-backups\n\naws route53 change-resource-record-sets \\ --hosted-zone-id ABCD \\ --change-batch file://prod_rds_create.json\n"})}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-json",children:'{\n   "Changes": [\n       {\n       "Action": "CREATE",\n        "ResourceRecordSet": {\n       "Name": "a.example.com",\n       "Type": "CNAME",\n       "SetIdentifier": "daily-db",\n       "Weight": 64,\n       "TTL": 300,\n       "ResourceRecords": [{  "Value": "daily-db.abc.ap-south-1.rds.amazonaws.com"} ]\n        }\n       },\n    {\n       "Action": "CREATE",\n       "ResourceRecordSet": {\n           "Name": "b.example.com",\n           "Type": "CNAME",\n           "SetIdentifier": "daily-db",\n           "Weight": 64,\n           "TTL": 300,\n           "ResourceRecords": [{  "Value":"daily-db.abc.ap-south-1.rds.amazonaws.com"} ]\n    } }\n]\n}\n'})}),"\n",(0,t.jsx)(s.h2,{id:"cleanups",children:"Cleanups"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws ec2 describe-volumes --filter Name=status,Values=available\n"})}),"\n",(0,t.jsx)(s.h2,{id:"tools",children:"Tools"}),"\n",(0,t.jsx)(s.h3,{id:"awslog",children:"awslog"}),"\n",(0,t.jsxs)(s.p,{children:["awslogsis a simple command line tool for querying groups, streams and events from ",(0,t.jsx)(s.a,{href:"http://aws.amazon.com/cloudwatch/",children:"Amazon CloudWatch"})," logs."]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.a,{href:"https://github.com/jorgebastida/awslogs",children:"https://github.com/jorgebastida/awslogs"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Set credentials at your env vars;"}),"\n",(0,t.jsxs)(s.li,{children:["Logs in production: ",(0,t.jsx)(s.code,{children:"awslogs get production-zf-backend ALL --aws-region sa-east-1"}),";"]}),"\n",(0,t.jsxs)(s.li,{children:["Logs in staging: ",(0,t.jsx)(s.code,{children:"awslogs get staging-zf-backend ALL --aws-region us-east-1"}),"."]}),"\n"]})]})}function u(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,s,n)=>{n.d(s,{R:()=>i,x:()=>r});var a=n(296540);const t={},o=a.createContext(t);function i(e){const s=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(o.Provider,{value:s},e.children)}}}]);