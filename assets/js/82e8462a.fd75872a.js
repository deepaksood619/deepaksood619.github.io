"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[39087],{986725:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>r,default:()=>o,frontMatter:()=>t,metadata:()=>d,toc:()=>l});var s=n(785893),a=n(511151);const t={},r="Andrew NG",d={id:"ai/ml-fundamentals/andrew-ng",title:"Andrew NG",description:"Model and cost function",source:"@site/docs/ai/ml-fundamentals/andrew-ng.md",sourceDirName:"ai/ml-fundamentals",slug:"/ai/ml-fundamentals/andrew-ng",permalink:"/ai/ml-fundamentals/andrew-ng",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/ml-fundamentals/andrew-ng.md",tags:[],version:"current",lastUpdatedAt:1707138374,formattedLastUpdatedAt:"Feb 5, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"ML Fundamentals",permalink:"/ai/ml-fundamentals/"},next:{title:"Intro",permalink:"/ai/ml-fundamentals/intro"}},c={},l=[{value:"Model and cost function",id:"model-and-cost-function",level:2},{value:"2. Cost function",id:"2-cost-function",level:2},{value:"Gradient Descent for Linear regression with one variable",id:"gradient-descent-for-linear-regression-with-one-variable",level:2},{value:"Derivative term",id:"derivative-term",level:2},{value:"Alpha",id:"alpha",level:2},{value:"Gradient Descent for Linear Regression",id:"gradient-descent-for-linear-regression",level:2}];function h(e){const i={em:"em",h1:"h1",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"andrew-ng",children:"Andrew NG"}),"\n",(0,s.jsx)(i.h2,{id:"model-and-cost-function",children:"Model and cost function"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsx)(i.li,{children:"Model representation - Linear regression using Training set"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"m - number of training examples"}),"\n",(0,s.jsx)(i.p,{children:"x's - input variables / features"}),"\n",(0,s.jsx)(i.p,{children:'y\'s - output variable / "target" variable'}),"\n",(0,s.jsx)(i.p,{children:"(x,y) - one training example"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(770399).Z+"",width:"963",height:"546"})}),"\n",(0,s.jsx)(i.h2,{id:"2-cost-function",children:"2. Cost function"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(96621).Z+"",width:"972",height:"550"})}),"\n",(0,s.jsx)(i.p,{children:"Cost function intuition -"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(903005).Z+"",width:"972",height:"550"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(938823).Z+"",width:"970",height:"547"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(21233).Z+"",width:"970",height:"547"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(120721).Z+"",width:"970",height:"547"})}),"\n",(0,s.jsx)(i.p,{children:"Octave"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:(0,s.jsx)(i.strong,{children:"Singular Value Decomposition (SVD)"})}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Every nxm matrix can be written as a product of three smaller matrices."}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(105780).Z+"",width:"1100",height:"500"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["SVD appreas in lots of places","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Statistics (PCA)"}),"\n",(0,s.jsx)(i.li,{children:"Chemical physics"}),"\n",(0,s.jsx)(i.li,{children:"Image processing"}),"\n",(0,s.jsx)(i.li,{children:"Genomics"}),"\n",(0,s.jsx)(i.li,{children:"Robotics"}),"\n",(0,s.jsx)(i.li,{children:"Quantum physics (entanglement)"}),"\n",(0,s.jsx)(i.li,{children:"Data embeddings / vector embeddings"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"gradient-descent-for-linear-regression-with-one-variable",children:"Gradient Descent for Linear regression with one variable"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(519751).Z+"",width:"974",height:"554"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(426672).Z+"",width:"974",height:"554"})}),"\n",(0,s.jsx)(i.p,{children:"Gradient descent intuition"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(283393).Z+"",width:"975",height:"552"})}),"\n",(0,s.jsx)(i.h2,{id:"derivative-term",children:"Derivative term"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(182914).Z+"",width:"975",height:"552"})}),"\n",(0,s.jsx)(i.h2,{id:"alpha",children:"Alpha"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(757489).Z+"",width:"973",height:"563"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(970824).Z+"",width:"973",height:"563"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(762252).Z+"",width:"975",height:"556"})}),"\n",(0,s.jsx)(i.h2,{id:"gradient-descent-for-linear-regression",children:"Gradient Descent for Linear Regression"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(855710).Z+"",width:"972",height:"563"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(372305).Z+"",width:"981",height:"560"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(755229).Z+"",width:"972",height:"563"})}),"\n",(0,s.jsx)(i.p,{children:"Gradient descent is a convex function (Global minimum)"}),"\n",(0,s.jsx)(i.p,{children:"Also called (Batch gradient descent) becauses look at all training sample."}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(961828).Z+"",width:"981",height:"558"})}),"\n",(0,s.jsx)(i.p,{children:"Linear Algebra Review"}),"\n",(0,s.jsx)(i.p,{children:"Matrix - Rectangular array of numbers."}),"\n",(0,s.jsx)(i.p,{children:"Dimension of matrix : number of rows * number of columns"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(161356).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"Vector - is a matrix with one column (n*1 matrix)"}),"\n",(0,s.jsx)(i.p,{children:"Uppercase for matrices"}),"\n",(0,s.jsx)(i.p,{children:"Lower case for others variables, vectors, etc."}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(567301).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"Addition and Scalar Multiplication"}),"\n",(0,s.jsxs)(i.p,{children:["Scalar multiplication is 3",(0,s.jsx)(i.em,{children:"matrix (n"}),"matrix)."]}),"\n",(0,s.jsx)(i.p,{children:"Scalar division is \u2153 * matrix"}),"\n",(0,s.jsx)(i.p,{children:"Matrix Vector Multiplication"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(817076).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"Calculating hypothesis using matrix-vector multiplication in octave its easy"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(335249).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"Matrix - Matrix multiplication"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(358582).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"If we have 3 hypothesis with 4 houses then,"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(335043).Z+"",width:"987",height:"600"})}),"\n",(0,s.jsx)(i.p,{children:"Multiplication Properties"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["Multiplication is not commutative ( A",(0,s.jsx)(i.em,{children:"B not equal to B"}),"A)"]}),"\n",(0,s.jsxs)(i.li,{children:["Multiplication is Associative ( a*(b",(0,s.jsx)(i.em,{children:"c) = (a"}),"b)*c)"]}),"\n",(0,s.jsx)(i.li,{children:"Identity matrix (A.I = I.A = A)"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Matrix Inverse and Transpose"}),"\n",(0,s.jsx)(i.p,{children:"Matrix Inverse:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"0 does not have an inverse."}),"\n",(0,s.jsx)(i.li,{children:"3 inverse is 3-1"}),"\n",(0,s.jsx)(i.li,{children:"Matrix inverse ( A * A-1 = Identity)"}),"\n",(0,s.jsx)(i.li,{children:"Matrix that don't have an inverse are singular or degenerate matrix"}),"\n",(0,s.jsx)(i.li,{children:"Ex- 0 matrix doesn't have inverse."}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Matrix Transpose:"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:n(880172).Z+"",width:"987",height:"600"})})]})}function o(e={}){const{wrapper:i}={...(0,a.a)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},770399:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image1-0327069b7dc0e6423be6472a07059538.jpg"},283393:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image10-3f947c2a2c2ba23c02cecdaf7da364a4.jpg"},182914:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image11-346eded7f5f6af1318d412973a6fbf8d.jpg"},757489:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image12-c813cc1d17e60f77ea986d2fcd88ff18.jpg"},970824:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image13-41da0a558c959119fb7033ca2bf5f12c.jpg"},762252:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image14-a202c1539d575e2d3bc8039866d6c8a1.jpg"},855710:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image15-ac55230f6d1db7476ec32f6428c23592.jpg"},372305:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image16-8d47f8118752ccb6cde949f3585de04f.jpg"},755229:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image17-fbd9a244d7fd58d46750f701b1f0b2b3.jpg"},961828:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image18-a6a9d61acd8c81703d3f30c83c9466c4.jpg"},161356:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image19-edc073f0c9151860ed3d900c5c6f31df.jpg"},96621:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image2-faa0242a70497153a26d9a65382ebd4b.jpg"},567301:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image20-1302b1057dc15b4a4f50231508be0b71.jpg"},817076:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image21-93ebde25718493ced6633afbd1a62b0a.jpg"},335249:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image22-e0ddaf69fbe150277c2e18b0aeb16601.jpg"},358582:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image23-7fd7a89756d83a7790f00dbef6ef7fa2.jpg"},335043:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image24-be53f51bb56a6f296ee5066ba24c46d6.jpg"},880172:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image25-8411aa1574753494b550ba1e3b5061dd.jpg"},903005:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image3-0c6a1bd05bc7dfa6c92fe32052194f15.jpg"},938823:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image4-291e184e3eb3e799f78f09f2be5c12ad.jpg"},21233:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image5-a5fca8387a7c5998b8b7d40d171f6c2e.jpg"},120721:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image6-66127eebbb5c90ecaa0db396e1416a8d.jpg"},105780:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image7-bd029bd7dcaf444eae19e55cdf3a546d.jpg"},519751:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image8-6f326e3b587a5b2663c28092e0b14425.jpg"},426672:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/Andrew-NG-image9-93444b82b119afee2c6b5d2287e7209b.jpg"},511151:(e,i,n)=>{n.d(i,{Z:()=>d,a:()=>r});var s=n(667294);const a={},t=s.createContext(a);function r(e){const i=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function d(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(t.Provider,{value:i},e.children)}}}]);