"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[58909],{220797:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>c,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"devops/terraform/confluent-provider","title":"Confluent Provider","description":"Simplify Apache Kafka Terraform deployment with the Confluent Terraform Provider. Manage Environments, Kafka Clusters, Kafka Topics, Kafka ACLs, Service Accounts, and more in Confluent.","source":"@site/docs/devops/terraform/confluent-provider.md","sourceDirName":"devops/terraform","slug":"/devops/terraform/confluent-provider","permalink":"/devops/terraform/confluent-provider","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/devops/terraform/confluent-provider.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1771485259000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Commands","permalink":"/devops/terraform/commands"},"next":{"title":"Documentation","permalink":"/devops/terraform/documentation"}}');var i=a(474848),t=a(28453);const c={},o="Confluent Provider",s={},l=[{value:"Commands",id:"commands",level:2},{value:"Resource Importer",id:"resource-importer",level:2},{value:"Examples",id:"examples",level:2},{value:"Notes",id:"notes",level:3},{value:"basic-kafka-acls",id:"basic-kafka-acls",level:2},{value:"confluent_kafka_cluster",id:"confluent_kafka_cluster",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"confluent-provider",children:"Confluent Provider"})}),"\n",(0,i.jsx)(n.p,{children:"Simplify Apache Kafka Terraform deployment with the Confluent Terraform Provider. Manage Environments, Kafka Clusters, Kafka Topics, Kafka ACLs, Service Accounts, and more in Confluent."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs",children:"Terraform Registry - Confluent Provider"})}),"\n",(0,i.jsx)(n.h2,{id:"commands",children:"Commands"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'git clone https://github.com/confluentinc/terraform-provider-confluent.git\n\ncd terraform-provider-confluent/examples/configurations\n\n// Using the example configuration //1 as an example\ncd basic-kafka-acls\n\nterraform init\n\nexport TF_VAR_confluent_cloud_api_key="<cloud_api_key>"\nexport TF_VAR_confluent_cloud_api_secret="<cloud_api_secret>"\n\nterraform plan\n\nterraform apply\n\nterraform output resource-ids\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/guides/sample-project",children:"Terraform Registry - Confluent Provider - Sample Project"})}),"\n",(0,i.jsx)(n.h2,{id:"resource-importer",children:"Resource Importer"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Resource Importer for Confluent Terraform Provider"}),"\xa0enables importing your existing Confluent Cloud resources to Terraform Configuration (",(0,i.jsx)(n.code,{children:"main.tf"}),") and Terraform State (",(0,i.jsx)(n.code,{children:"terraform.tfstate"}),") files to a local directory named\xa0",(0,i.jsx)(n.code,{children:"imported_confluent_infrastructure"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'git clone https://github.com/confluentinc/terraform-provider-confluent.git\n\ncd terraform-provider-confluent/examples/configurations\n\n# Using the example configuration #1 as an example\ncd cloud-importer\n\nterraform init\n\nexport TF_VAR_confluent_cloud_api_key="<cloud_api_key>"\nexport TF_VAR_confluent_cloud_api_secret="<cloud_api_secret>"\n\nterraform validate\n\nterraform apply\n\n# Using the example configuration #1 as an example\ncd imported_confluent_infrastructure\n\nterraform init\n\nterraform refresh\n\nterraform plan\n\nterraform plan -parallelism=100\n# default parallelism=10\n# If the import process is taking longer than expected, you can improve the speed by increasing the parallelism flag. For example, you can set it to 100 like this: terraform plan -parallelism=100. Increasing parallelism can help speed up the import process, especially when dealing with a large number of resources.\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",metastring:"title=main.tf",children:'terraform {\n  required_providers {\n    confluent = {\n      source  = "confluentinc/confluent"\n      version = "2.59.0"\n    }\n  }\n}\n\nprovider "confluent" {\n  cloud_api_key    = var.confluent_cloud_api_key\n  cloud_api_secret = var.confluent_cloud_api_secret\n}\n\nresource "confluent_tf_importer" "example" {}\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",metastring:'title="variables.tf"',children:'variable "confluent_cloud_api_key" {\n  description = "Confluent Cloud API Key (also referred as Cloud API ID)"\n  type        = string\n}\n\nvariable "confluent_cloud_api_secret" {\n  description = "Confluent Cloud API Secret"\n  type        = string\n  sensitive   = true\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note -"})," Running Resource Importer for Confluent Terraform Provider is a read-only operation. It will not edit Confluent Cloud infrastructure."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/guides/resource-importer",children:"Resource Importer for Confluent Terraform Provider - Terraform Registry"})}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"advanced-bidirectional-cluster-link-rbac"}),"\n",(0,i.jsx)(n.li,{children:"authentication-using-oauth"}),"\n",(0,i.jsx)(n.li,{children:"azure-key-vault"}),"\n",(0,i.jsx)(n.li,{children:"basic-kafka-acls-with-alias"}),"\n",(0,i.jsx)(n.li,{children:"basic-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"cloud-importer"}),"\n",(0,i.jsx)(n.li,{children:"cluster-link-over-aws-private-link-networks"}),"\n",(0,i.jsx)(n.li,{children:"cluster-link-using-oauth"}),"\n",(0,i.jsx)(n.li,{children:"connect-artifact"}),"\n",(0,i.jsx)(n.li,{children:"connectors"}),"\n",(0,i.jsx)(n.li,{children:"create-default-topic-and-return-kafka-api-keys-to-consume-and-produce"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-private-service-connect-gcp-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-private-service-connect-gcp-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-privatelink-aws-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-privatelink-aws-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-privatelink-azure-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-privatelink-azure-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-public-aws-byok-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-public-azure-byok-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-public-gcp-byok-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-public-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-public-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-transit-gateway-attachment-aws-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-transit-gateway-attachment-aws-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vnet-peering-azure-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vnet-peering-azure-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vpc-peering-aws-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vpc-peering-aws-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vpc-peering-gcp-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vpc-peering-gcp-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dedicated-vpc-peering-v2-aws-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"destination-initiated-cluster-link-rbac"}),"\n",(0,i.jsx)(n.li,{children:"dns-forwarder"}),"\n",(0,i.jsx)(n.li,{children:"enterprise-pni-aws-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"enterprise-privatelinkattachment-aws-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"enterprise-privatelinkattachment-azure-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"field-level-encryption-schema"}),"\n",(0,i.jsx)(n.li,{children:"flink-carry-over-offset-between-statements"}),"\n",(0,i.jsx)(n.li,{children:"flink-connection"}),"\n",(0,i.jsx)(n.li,{children:"flink-quickstart-2"}),"\n",(0,i.jsx)(n.li,{children:"flink-quickstart"}),"\n",(0,i.jsx)(n.li,{children:"flink_artifact"}),"\n",(0,i.jsx)(n.li,{children:"freight-aws-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"hashicorp-vault"}),"\n",(0,i.jsx)(n.li,{children:"kafka-importer"}),"\n",(0,i.jsx)(n.li,{children:"kafka-ops-env-admin-product-team"}),"\n",(0,i.jsx)(n.li,{children:"kafka-ops-kafka-admin-product-team"}),"\n",(0,i.jsx)(n.li,{children:"ksql-acls"}),"\n",(0,i.jsx)(n.li,{children:"ksql-rbac"}),"\n",(0,i.jsx)(n.li,{children:"manage-topics-via-json"}),"\n",(0,i.jsx)(n.li,{children:"managing-single-kafka-cluster"}),"\n",(0,i.jsx)(n.li,{children:"managing-single-schema-registry-cluster"}),"\n",(0,i.jsx)(n.li,{children:"multiple-event-types-avro-schema"}),"\n",(0,i.jsx)(n.li,{children:"multiple-event-types-proto-schema"}),"\n",(0,i.jsx)(n.li,{children:"network-access-point-gcp-private-service-connect"}),"\n",(0,i.jsx)(n.li,{children:"private-flink-quickstart"}),"\n",(0,i.jsx)(n.li,{children:"private-link-schema-registry"}),"\n",(0,i.jsx)(n.li,{children:"provider-integration-aws"}),"\n",(0,i.jsx)(n.li,{children:"regular-bidirectional-cluster-link-rbac"}),"\n",(0,i.jsx)(n.li,{children:"schema-linking"}),"\n",(0,i.jsx)(n.li,{children:"schema-registry-importer"}),"\n",(0,i.jsx)(n.li,{children:"single-event-types-avro-schema"}),"\n",(0,i.jsx)(n.li,{children:"single-event-types-proto-schema-with-alias"}),"\n",(0,i.jsx)(n.li,{children:"single-event-types-proto-schema"}),"\n",(0,i.jsx)(n.li,{children:"source-initiated-cluster-link-rbac"}),"\n",(0,i.jsx)(n.li,{children:"standard-kafka-acls"}),"\n",(0,i.jsx)(n.li,{children:"standard-kafka-rbac"}),"\n",(0,i.jsx)(n.li,{children:"stream-catalog"}),"\n",(0,i.jsx)(n.li,{children:"tableflow"}),"\n",(0,i.jsx)(n.li,{children:"topic-as-a-service"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"notes",children:"Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Basic"}),"\xa0Kafka cluster with authorization using RBAC configuration is not supported, because both\xa0",(0,i.jsx)(n.code,{children:"DeveloperRead"}),"\xa0and\xa0",(0,i.jsx)(n.code,{children:"DeveloperWrite"}),"\xa0roles are not available for\xa0",(0,i.jsx)(n.em,{children:"Basic"}),"\xa0Kafka clusters."]}),"\n",(0,i.jsx)(n.li,{children:"When considering whether to use RBAC or ACLs for access control, it is suggested you use RBAC as the default because of its ease of use and manageability at scale, but for edge cases where you need to have more granular access control, or wish to explicitly deny access, ACLs may make more sense. For example, you could use RBAC to allow access for a group of users, but an ACL to deny access for a particular member of that group."}),"\n",(0,i.jsxs)(n.li,{children:["When using a private networking option, you must execute\xa0",(0,i.jsx)(n.code,{children:"terraform"}),"\xa0on a system with connectivity to the Kafka REST API. Check the\xa0",(0,i.jsx)(n.a,{href:"https://docs.confluent.io/cloud/current/api.html//tag/Topic-(v3)",children:"Kafka REST API docs"}),"\xa0to learn more about it."]}),"\n",(0,i.jsxs)(n.li,{children:["If you're interested in a more granular setup with TF configuration split between a Kafka Ops team and a Product team, see\xa0",(0,i.jsx)(n.a,{href:"https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/kafka-ops-env-admin-product-team",children:"kafka-ops-env-admin-product-team"}),"\xa0and\xa0",(0,i.jsx)(n.a,{href:"https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/kafka-ops-kafka-admin-product-team",children:"kafka-ops-kafka-admin-product-team"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"basic-kafka-acls",children:"basic-kafka-acls"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",metastring:"title=main.tf",children:'terraform {\n  required_providers {\n    confluent = {\n      source  = "confluentinc/confluent"\n      version = "2.59.0"\n    }\n  }\n}\n\nprovider "confluent" {\n  cloud_api_key    = var.confluent_cloud_api_key\n  cloud_api_secret = var.confluent_cloud_api_secret\n}\n\nresource "confluent_environment" "staging" {\n  display_name = "Staging"\n\n  stream_governance {\n    package = "ESSENTIALS"\n  }\n}\n\ndata "confluent_schema_registry_cluster" "essentials" {\n  environment {\n    id = confluent_environment.staging.id\n  }\n\n  depends_on = [\n    confluent_kafka_cluster.basic\n  ]\n}\n\n// Update the config to use a cloud provider and region of your choice.\n// https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_cluster\nresource "confluent_kafka_cluster" "basic" {\n  display_name = "inventory"\n  availability = "SINGLE_ZONE"\n  cloud        = "AWS"\n  region       = "us-east-2"\n  basic {}\n  environment {\n    id = confluent_environment.staging.id\n  }\n}\n\n// \'app-manager\' service account is required in this configuration to create \'orders\' topic and grant ACLs\n// to \'app-producer\' and \'app-consumer\' service accounts.\nresource "confluent_service_account" "app-manager" {\n  display_name = "app-manager"\n  description  = "Service account to manage \'inventory\' Kafka cluster"\n}\n\nresource "confluent_role_binding" "app-manager-kafka-cluster-admin" {\n  principal   = "User:${confluent_service_account.app-manager.id}"\n  role_name   = "CloudClusterAdmin"\n  crn_pattern = confluent_kafka_cluster.basic.rbac_crn\n}\n\nresource "confluent_api_key" "app-manager-kafka-api-key" {\n  display_name = "app-manager-kafka-api-key"\n  description  = "Kafka API Key that is owned by \'app-manager\' service account"\n  owner {\n    id          = confluent_service_account.app-manager.id\n    api_version = confluent_service_account.app-manager.api_version\n    kind        = confluent_service_account.app-manager.kind\n  }\n\n  managed_resource {\n    id          = confluent_kafka_cluster.basic.id\n    api_version = confluent_kafka_cluster.basic.api_version\n    kind        = confluent_kafka_cluster.basic.kind\n\n    environment {\n      id = confluent_environment.staging.id\n    }\n  }\n\n  // The goal is to ensure that confluent_role_binding.app-manager-kafka-cluster-admin is created before\n  // confluent_api_key.app-manager-kafka-api-key is used to create instances of\n  // confluent_kafka_topic, confluent_kafka_acl resources.\n\n  // \'depends_on\' meta-argument is specified in confluent_api_key.app-manager-kafka-api-key to avoid having\n  // multiple copies of this definition in the configuration which would happen if we specify it in\n  // confluent_kafka_topic, confluent_kafka_acl resources instead.\n  depends_on = [\n    confluent_role_binding.app-manager-kafka-cluster-admin\n  ]\n}\n\nresource "confluent_kafka_topic" "orders" {\n  kafka_cluster {\n    id = confluent_kafka_cluster.basic.id\n  }\n  topic_name    = "orders"\n  rest_endpoint = confluent_kafka_cluster.basic.rest_endpoint\n  credentials {\n    key    = confluent_api_key.app-manager-kafka-api-key.id\n    secret = confluent_api_key.app-manager-kafka-api-key.secret\n  }\n}\n\nresource "confluent_service_account" "app-consumer" {\n  display_name = "app-consumer"\n  description  = "Service account to consume from \'orders\' topic of \'inventory\' Kafka cluster"\n}\n\nresource "confluent_api_key" "app-consumer-kafka-api-key" {\n  display_name = "app-consumer-kafka-api-key"\n  description  = "Kafka API Key that is owned by \'app-consumer\' service account"\n  owner {\n    id          = confluent_service_account.app-consumer.id\n    api_version = confluent_service_account.app-consumer.api_version\n    kind        = confluent_service_account.app-consumer.kind\n  }\n\n  managed_resource {\n    id          = confluent_kafka_cluster.basic.id\n    api_version = confluent_kafka_cluster.basic.api_version\n    kind        = confluent_kafka_cluster.basic.kind\n\n    environment {\n      id = confluent_environment.staging.id\n    }\n  }\n}\n\nresource "confluent_kafka_acl" "app-producer-write-on-topic" {\n  kafka_cluster {\n    id = confluent_kafka_cluster.basic.id\n  }\n  resource_type = "TOPIC"\n  resource_name = confluent_kafka_topic.orders.topic_name\n  pattern_type  = "LITERAL"\n  principal     = "User:${confluent_service_account.app-producer.id}"\n  host          = "*"\n  operation     = "WRITE"\n  permission    = "ALLOW"\n  rest_endpoint = confluent_kafka_cluster.basic.rest_endpoint\n  credentials {\n    key    = confluent_api_key.app-manager-kafka-api-key.id\n    secret = confluent_api_key.app-manager-kafka-api-key.secret\n  }\n}\n\nresource "confluent_service_account" "app-producer" {\n  display_name = "app-producer"\n  description  = "Service account to produce to \'orders\' topic of \'inventory\' Kafka cluster"\n}\n\nresource "confluent_api_key" "app-producer-kafka-api-key" {\n  display_name = "app-producer-kafka-api-key"\n  description  = "Kafka API Key that is owned by \'app-producer\' service account"\n  owner {\n    id          = confluent_service_account.app-producer.id\n    api_version = confluent_service_account.app-producer.api_version\n    kind        = confluent_service_account.app-producer.kind\n  }\n\n  managed_resource {\n    id          = confluent_kafka_cluster.basic.id\n    api_version = confluent_kafka_cluster.basic.api_version\n    kind        = confluent_kafka_cluster.basic.kind\n\n    environment {\n      id = confluent_environment.staging.id\n    }\n  }\n}\n\n// Note that in order to consume from a topic, the principal of the consumer (\'app-consumer\' service account)\n// needs to be authorized to perform \'READ\' operation on both Topic and Group resources:\n// confluent_kafka_acl.app-consumer-read-on-topic, confluent_kafka_acl.app-consumer-read-on-group.\n// https://docs.confluent.io/platform/current/kafka/authorization.html//using-acls\nresource "confluent_kafka_acl" "app-consumer-read-on-topic" {\n  kafka_cluster {\n    id = confluent_kafka_cluster.basic.id\n  }\n  resource_type = "TOPIC"\n  resource_name = confluent_kafka_topic.orders.topic_name\n  pattern_type  = "LITERAL"\n  principal     = "User:${confluent_service_account.app-consumer.id}"\n  host          = "*"\n  operation     = "READ"\n  permission    = "ALLOW"\n  rest_endpoint = confluent_kafka_cluster.basic.rest_endpoint\n  credentials {\n    key    = confluent_api_key.app-manager-kafka-api-key.id\n    secret = confluent_api_key.app-manager-kafka-api-key.secret\n  }\n}\n\nresource "confluent_kafka_acl" "app-consumer-read-on-group" {\n  kafka_cluster {\n    id = confluent_kafka_cluster.basic.id\n  }\n  resource_type = "GROUP"\n  // The existing values of resource_name, pattern_type attributes are set up to match Confluent CLI\'s default consumer group ID ("confluent_cli_consumer_<uuid>").\n  // https://docs.confluent.io/confluent-cli/current/command-reference/kafka/topic/confluent_kafka_topic_consume.html\n  // Update the values of resource_name, pattern_type attributes to match your target consumer group ID.\n  // https://docs.confluent.io/platform/current/kafka/authorization.html//prefixed-acls\n  resource_name = "confluent_cli_consumer_"\n  pattern_type  = "PREFIXED"\n  principal     = "User:${confluent_service_account.app-consumer.id}"\n  host          = "*"\n  operation     = "READ"\n  permission    = "ALLOW"\n  rest_endpoint = confluent_kafka_cluster.basic.rest_endpoint\n  credentials {\n    key    = confluent_api_key.app-manager-kafka-api-key.id\n    secret = confluent_api_key.app-manager-kafka-api-key.secret\n  }\n}\n\n'})}),"\n",(0,i.jsx)(n.h2,{id:"confluent_kafka_cluster",children:"confluent_kafka_cluster"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_cluster#dedicated-2",children:(0,i.jsx)(n.code,{children:"dedicated"})}),"\xa0- (Optional Configuration Block) The configuration of the Dedicated Kafka cluster. It supports the following:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_cluster#zones-1",children:(0,i.jsx)(n.code,{children:"zones"})}),"\xa0- (Required List of String) The list of zones the cluster is in."]}),"\n",(0,i.jsxs)(n.li,{children:["On AWS, zones are AWS\xa0",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/ram/latest/userguide/working-with-az-ids.html",children:"AZ IDs"}),", for example,\xa0",(0,i.jsx)(n.code,{children:"use1-az3"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["On GCP, zones are GCP\xa0",(0,i.jsx)(n.a,{href:"https://cloud.google.com/compute/docs/regions-zones",children:"zones"}),", for example,\xa0",(0,i.jsx)(n.code,{children:"us-central1-c"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["On Azure, zones are Confluent-chosen names (for example,\xa0",(0,i.jsx)(n.code,{children:"1"}),",\xa0",(0,i.jsx)(n.code,{children:"2"}),",\xa0",(0,i.jsx)(n.code,{children:"3"}),") since Azure does not have universal zone identifiers."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_cluster",children:"Terraform Registry - confluent_kafka_cluster"})})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>c,x:()=>o});var r=a(296540);const i={},t=r.createContext(i);function c(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);