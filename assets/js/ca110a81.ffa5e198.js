"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[68641],{483915:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>o});const a=JSON.parse('{"id":"ai/nlp/intro","title":"NLP","description":"- 14. Natural Language Processing: Pretraining","source":"@site/docs/ai/nlp/intro.md","sourceDirName":"ai/nlp","slug":"/ai/nlp/intro","permalink":"/ai/nlp/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/nlp/intro.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1759002907000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chatbot SAAS","permalink":"/ai/nlp/chatbot-saas"},"next":{"title":"NLP Concepts","permalink":"/ai/nlp/nlp-concepts"}}');var t=i(474848),r=i(28453);const s={},l="NLP",h={},o=[{value:"NLP (Natural Language Processing)",id:"nlp-natural-language-processing",level:2},{value:"Why Natural Language is hard for computer to parse",id:"why-natural-language-is-hard-for-computer-to-parse",level:2},{value:"Spacy",id:"spacy",level:2},{value:"Gensim (Topic Modeling for Humans)",id:"gensim-topic-modeling-for-humans",level:2},{value:"Topic Modeling",id:"topic-modeling",level:3},{value:"Text Similarity Methods",id:"text-similarity-methods",level:2},{value:"FlashText",id:"flashtext",level:2},{value:"ML Kit Natural Language APIs",id:"ml-kit-natural-language-apis",level:2},{value:"Haystack",id:"haystack",level:2},{value:"Models",id:"models",level:2},{value:"References",id:"references",level:2},{value:"Links",id:"links",level:2}];function c(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"nlp",children:"NLP"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/index.html",children:"14. Natural Language Processing: Pretraining"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html",children:"14.1. Word Embedding (word2vec)"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/approx-training.html",children:"14.2. Approximate Training"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/word-embedding-dataset.html",children:"14.3. The Dataset for Pretraining Word Embedding"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec-pretraining.html",children:"14.4. Pretraining word2vec"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/glove.html",children:"14.5. Word Embedding with Global Vectors (GloVe)"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/subword-embedding.html",children:"14.6. Subword Embedding"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/similarity-analogy.html",children:"14.7. Finding Synonyms and Analogies"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html",children:"14.8. Bidirectional Encoder Representations from Transformers (BERT)"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html",children:"14.9. The Dataset for Pretraining BERT"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html",children:"14.10. Pretraining BERT"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/index.html",children:"15. Natural Language Processing: Applications"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html",children:"15.1. Sentiment Analysis and the Dataset"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-rnn.html",children:"15.2. Sentiment Analysis: Using Recurrent Neural Networks"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html",children:"15.3. Sentiment Analysis: Using Convolutional Neural Networks"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html",children:"15.4. Natural Language Inference and the Dataset"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-attention.html",children:"15.5. Natural Language Inference: Using Attention"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html",children:"15.6. Fine-Tuning BERT for Sequence-Level and Token-Level Applications"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-bert.html",children:"15.7. Natural Language Inference: Fine-Tuning BERT"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"nlp-natural-language-processing",children:"NLP (Natural Language Processing)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Lexical Processing"}),"\n",(0,t.jsx)(n.li,{children:"Semantic Analysis"}),"\n",(0,t.jsx)(n.li,{children:"Syntactic Analysis"}),"\n",(0,t.jsx)(n.li,{children:"Neural Network (NN)"}),"\n",(0,t.jsx)(n.li,{children:"Recurring NN"}),"\n",(0,t.jsx)(n.li,{children:"Chatbot Project"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"why-natural-language-is-hard-for-computer-to-parse",children:"Why Natural Language is hard for computer to parse"}),"\n",(0,t.jsx)(n.p,{children:"May is fun but June bores me."}),"\n",(0,t.jsx)(n.p,{children:"Does it refer to months or to people?"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.toptal.com/machine-learning/google-nlp-tutorial",children:"https://www.toptal.com/machine-learning/google-nlp-tutorial"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=B2q5cRJvqI8",children:"Natural Language Processing with TensorFlow 2 - Beginner's Course"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.freecodecamp.org/news/google-bert-nlp-machine-learning-tutorial",children:"https://www.freecodecamp.org/news/google-bert-nlp-machine-learning-tutorial"})}),"\n",(0,t.jsx)(n.h2,{id:"spacy",children:"Spacy"}),"\n",(0,t.jsx)(n.p,{children:"Industrial-Strength Natural Language Processing"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://spacy.io/usage/models",children:"https://spacy.io/usage/models"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://spacy.io/",children:"spaCy \xb7 Industrial-strength Natural Language Processing in Python"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/explosion/spaCy",children:"GitHub - explosion/spaCy: \ud83d\udcab Industrial-strength Natural Language Processing (NLP) in Python"})}),"\n",(0,t.jsx)(n.h2,{id:"gensim-topic-modeling-for-humans",children:"Gensim (Topic Modeling for Humans)"}),"\n",(0,t.jsx)(n.p,{children:"Gensim is a Python library for topic modeling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing(NLP) andinformation retrieval(IR) community."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/parulsethi/gensim",children:"https://github.com/parulsethi/gensim"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://radimrehurek.com/gensim",children:"https://radimrehurek.com/gensim"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.toptal.com/python/topic-modeling-python",children:"https://www.toptal.com/python/topic-modeling-python"})}),"\n",(0,t.jsx)(n.h3,{id:"topic-modeling",children:"Topic Modeling"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Topic_modeling",children:"Topic modeling"})," is a related problem, where a program is given a list of ",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Natural_language",children:"human language"})," documents and is tasked with finding out which documents cover similar topics."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=pEkxRQFNAs4",children:"Extract Topics From Video/Audio With LLMs (Topic Modeling w/ LangChain) - YouTube"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Topic%20Modeling%20With%20Language%20Models.ipynb",children:"langchain-tutorials/data_generation/Topic Modeling With Language Models.ipynb at main \xb7 gkamradt/langchain-tutorials \xb7 GitHub"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"text-similarity-methods",children:"Text Similarity Methods"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Normalized, metric, similarity and distance"}),"\n",(0,t.jsx)(n.li,{children:"(Normalized) similarity and distance"}),"\n",(0,t.jsx)(n.li,{children:"Metric distances"}),"\n",(0,t.jsx)(n.li,{children:"Shingles (n-gram) based similarity and distance"}),"\n",(0,t.jsx)(n.li,{children:"Levenshtein"}),"\n",(0,t.jsx)(n.li,{children:"Normalized Levenshtein"}),"\n",(0,t.jsx)(n.li,{children:"Weighted Levenshtein"}),"\n",(0,t.jsx)(n.li,{children:"Damerau-Levenshtein"}),"\n",(0,t.jsx)(n.li,{children:"Optimal String Alignment"}),"\n",(0,t.jsx)(n.li,{children:"Jaro-Winkler"}),"\n",(0,t.jsx)(n.li,{children:"Longest Common Subsequence"}),"\n",(0,t.jsx)(n.li,{children:"Metric Longest Common Subsequence"}),"\n",(0,t.jsx)(n.li,{children:"N-Gram"}),"\n",(0,t.jsx)(n.li,{children:"Shingle(n-gram) based algorithms"}),"\n",(0,t.jsx)(n.li,{children:"Q-Gram"}),"\n",(0,t.jsx)(n.li,{children:"Cosine similarity"}),"\n",(0,t.jsx)(n.li,{children:"Jaccard index"}),"\n",(0,t.jsx)(n.li,{children:"Sorensen-Dice coefficient"}),"\n",(0,t.jsx)(n.li,{children:"Overlap coefficient (i.e., Szymkiewicz-Simpson)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/luozhouyang/python-string-similarity#python-string-similarity",children:"https://github.com/luozhouyang/python-string-similarity#python-string-similarity"})}),"\n",(0,t.jsx)(n.h2,{id:"flashtext",children:"FlashText"}),"\n",(0,t.jsx)(n.p,{children:"Replace keywords in sentences or extract keywords from sentences"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://pypi.org/project/flashtext",children:"https://pypi.org/project/flashtext"})}),"\n",(0,t.jsx)(n.h2,{id:"ml-kit-natural-language-apis",children:"ML Kit Natural Language APIs"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Language ID"}),"\n",(0,t.jsx)(n.li,{children:"On-device translation"}),"\n",(0,t.jsx)(n.li,{children:"Smart reply"}),"\n",(0,t.jsx)(n.li,{children:"Entity extraction"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://developers.google.com/ml-kit",children:"https://developers.google.com/ml-kit"})}),"\n",(0,t.jsx)(n.h2,{id:"haystack",children:"Haystack"}),"\n",(0,t.jsx)(n.p,{children:"Haystack is the open source Python framework by deepset for building custom apps with large language models (LLMs). It lets you quickly try out the latest models in natural language processing (NLP) while being flexible and easy to use. Our inspiring community of users and builders has helped shape Haystack into what it is today: a complete framework for building production-ready NLP apps."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/deepset-ai/haystack",children:"GitHub - deepset-ai/haystack"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://haystack.deepset.ai/overview/intro",children:"What is Haystack? | Haystack"})}),"\n",(0,t.jsx)(n.h2,{id:"models",children:"Models"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"BERT: Bidirectional Encoder Representations from Transformers"}),"\n",(0,t.jsxs)(n.li,{children:["RoBERTa: A Robustly Optimized BERT Pretraining Approach","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://medium.com/@marketing_novita.ai/introducing-roberta-base-model-a-comprehensive-overview-330338afa082",children:"Introducing RoBERTa Base Model: A Comprehensive Overview | by Novita AI | Medium"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/en/model_doc/roberta",children:"RoBERTa"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.p,{children:["The Association for Computational Linguistics is the international organization that represents the field of NLP. The ACL website (",(0,t.jsx)(n.a,{href:"http://www.aclweb.org",children:"http://www.aclweb.org"}),") hosts many useful resources, including: information about international and regional conferences and workshops; the ",(0,t.jsx)(n.em,{children:"ACL Wiki"})," with links to hundreds of useful resources; and the ",(0,t.jsx)(n.em,{children:"ACL Anthology"}),", which contains most of the NLP research literature from the past 50+ years, fully indexed and freely downloadable."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.freecodecamp.org/news/natural-language-processing-with-spacy-python-full-course",children:"https://www.freecodecamp.org/news/natural-language-processing-with-spacy-python-full-course"})}),"\n",(0,t.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=LIRwZDEMn2o",children:"NLP - EXPLAINED! - YouTube"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=AGWieLbom_g",children:"Convolution in NLP - YouTube"})})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>l});var a=i(296540);const t={},r=a.createContext(t);function s(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);