"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[63354],{267001:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"python/advanced/web-scraping","title":"Web Scraping","description":"Web Scraping is a technique in which a computer program extracts data from human-readable output coming from websites.","source":"@site/docs/python/advanced/web-scraping.md","sourceDirName":"python/advanced","slug":"/python/advanced/web-scraping","permalink":"/python/advanced/web-scraping","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/python/advanced/web-scraping.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1732812944000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Super","permalink":"/python/advanced/super"},"next":{"title":"Django","permalink":"/python/django/"}}');var r=s(474848),i=s(28453);const o={},a="Web Scraping",l={},c=[{value:"Download full website",id:"download-full-website",level:3},{value:"lxml.etree",id:"lxmletree",level:3},{value:"beautifulsoup",id:"beautifulsoup",level:3},{value:"Selenium (for javascript)",id:"selenium-for-javascript",level:3},{value:"Headless browser",id:"headless-browser",level:3},{value:"Links",id:"links",level:2},{value:"AI Tools",id:"ai-tools",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"web-scraping",children:"Web Scraping"})}),"\n",(0,r.jsx)(n.p,{children:"Web Scraping is a technique in which a computer program extracts data from human-readable output coming from websites."}),"\n",(0,r.jsx)(n.h3,{id:"download-full-website",children:"Download full website"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"wget --mirror --convert-links --adjust-extension --page-requisites --no-parent http://example.org"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.toolsbug.com/website-copier-online.php",children:"Website Copier | Download Sites | Website Ripper - Tools Bug"})}),"\n",(0,r.jsx)(n.h3,{id:"lxmletree",children:"lxml.etree"}),"\n",(0,r.jsx)(n.p,{children:"theXPath - language for XML queries"}),"\n",(0,r.jsx)(n.h3,{id:"beautifulsoup",children:"beautifulsoup"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"super short learning curve"}),"\n",(0,r.jsxs)(n.li,{children:["two function api","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"parse"}),"\n",(0,r.jsx)(n.li,{children:"search (find_all)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from bs4 import BeautifulSoup\n\nsoup = BeautifulSoup(response.text, \'html.parser\')\n\nmydivs = soup.find_all("div", {"class": "stylelistrow"})\nprint(i, soup.body.div.div)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"selenium-for-javascript",children:"Selenium (for javascript)"}),"\n",(0,r.jsx)(n.h3,{id:"headless-browser",children:"Headless browser"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://chromium.googlesource.com/chromium/src/+/lkgr/headless/README",children:"Headless Chromium"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/assaf/zombie",children:"Zombie"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"http://slimerjs.org/",children:"slimerjs"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/GoogleChrome/puppeteer",children:"puppeteer"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.toptal.com/python/web-scraping-with-python",children:"https://www.toptal.com/python/web-scraping-with-python"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python",children:"https://www.freecodecamp.org/news/how-to-scrape-websites-with-python"})}),"\n",(0,r.jsx)(n.h2,{id:"ai-tools",children:"AI Tools"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.browse.ai/",children:"Scrape and Monitor Data from Any Website with No Code"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/laramies/theHarvester",children:"GitHub - laramies/theHarvester: E-mails, subdomains and names Harvester - OSINT"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>a});var t=s(296540);const r={},i=t.createContext(r);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);