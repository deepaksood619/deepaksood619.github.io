"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[92402],{27840:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"technologies/flink/queries","title":"Queries","description":"Source Tables","source":"@site/docs/technologies/flink/queries.md","sourceDirName":"technologies/flink","slug":"/technologies/flink/queries","permalink":"/technologies/flink/queries","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/flink/queries.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1770866685000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"PyFlink","permalink":"/technologies/flink/pyflink"},"next":{"title":"WaterMarks","permalink":"/technologies/flink/watermarks"}}');var s=t(474848),r=t(28453);const a={},o="Queries",l={},c=[{value:"Source Tables",id:"source-tables",level:2},{value:"Examples",id:"examples",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"queries",children:"Queries"})}),"\n",(0,s.jsx)(n.h2,{id:"source-tables",children:"Source Tables"}),"\n",(0,s.jsx)(n.p,{children:"As with all SQL engines, Flink queries operate on top of tables. It differs from a traditional database because Flink does not manage data at rest locally; instead, its queries operate continuously over external tables."}),"\n",(0,s.jsxs)(n.p,{children:["Flink data processing pipelines begin with source tables. Source tables produce rows operated over during the query\u2019s execution; they are the tables referenced in the\xa0",(0,s.jsx)(n.code,{children:"FROM"}),"\xa0clause of a query. These could be Kafka topics, databases, filesystems, or any other system that Flink knows how to consume."]}),"\n",(0,s.jsxs)(n.p,{children:["Tables can be defined through the SQL client or using environment config file. The SQL client support\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/overview/",children:"SQL DDL commands"}),"\xa0similar to traditional SQL. Standard SQL DDL is used to\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/",children:"create"}),",\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/alter/",children:"alter"}),",\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/drop/",children:"drop"}),"\xa0tables."]}),"\n",(0,s.jsxs)(n.p,{children:["Flink has a support for different\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/overview/",children:"connectors"}),"\xa0and\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/formats/overview/",children:"formats"}),"\xa0that can be used with tables. Following is an example to define a source table backed by a\xa0",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/table/formats/csv/",children:"CSV file"}),"\xa0with\xa0",(0,s.jsx)(n.code,{children:"emp_id"}),",\xa0",(0,s.jsx)(n.code,{children:"name"}),",\xa0",(0,s.jsx)(n.code,{children:"dept_id"}),"\xa0as columns in a\xa0",(0,s.jsx)(n.code,{children:"CREATE"}),"\xa0table statement."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SHOW FUNCTIONS;\n\nCREATE TABLE employee_information (\n    emp_id INT,\n    name VARCHAR,\n    dept_id INT\n) WITH (\n    'connector' = 'filesystem',\n    'path' = '/path/to/something.csv',\n    'format' = 'csv'\n);\n\nSELECT * from employee_information WHERE dept_id = 1;\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Create table supported options"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"changelog.mode"}),"\n",(0,s.jsx)(n.li,{children:"connector"}),"\n",(0,s.jsx)(n.li,{children:"error-handling.log.target"}),"\n",(0,s.jsx)(n.li,{children:"error-handling.mode"}),"\n",(0,s.jsx)(n.li,{children:"kafka.cleanup-policy"}),"\n",(0,s.jsx)(n.li,{children:"kafka.compaction.time"}),"\n",(0,s.jsx)(n.li,{children:"kafka.consumer.isolation-level"}),"\n",(0,s.jsx)(n.li,{children:"kafka.max-message-size"}),"\n",(0,s.jsx)(n.li,{children:"kafka.message-timestamp-type"}),"\n",(0,s.jsx)(n.li,{children:"kafka.producer.compression.type"}),"\n",(0,s.jsx)(n.li,{children:"kafka.retention.size"}),"\n",(0,s.jsx)(n.li,{children:"kafka.retention.time"}),"\n",(0,s.jsx)(n.li,{children:"key.fields-prefix"}),"\n",(0,s.jsx)(n.li,{children:"key.format"}),"\n",(0,s.jsx)(n.li,{children:"key.raw.charset"}),"\n",(0,s.jsx)(n.li,{children:"key.raw.endianness"}),"\n",(0,s.jsx)(n.li,{children:"scan.bounded.mode"}),"\n",(0,s.jsx)(n.li,{children:"scan.bounded.specific-offsets"}),"\n",(0,s.jsx)(n.li,{children:"scan.bounded.timestamp-millis"}),"\n",(0,s.jsx)(n.li,{children:"scan.startup.mode"}),"\n",(0,s.jsx)(n.li,{children:"scan.startup.specific-offsets"}),"\n",(0,s.jsx)(n.li,{children:"scan.startup.timestamp-millis"}),"\n",(0,s.jsx)(n.li,{children:"value.fields-include"}),"\n",(0,s.jsx)(n.li,{children:"value.format"}),"\n",(0,s.jsx)(n.li,{children:"value.raw.charset"}),"\n",(0,s.jsx)(n.li,{children:"value.raw.endianness"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://docs.confluent.io/cloud/current/flink/reference/statements/create-table.html",children:"SQL CREATE TABLE Statement in Confluent Cloud for Apache Flink | Confluent Documentation"})}),"\n",(0,s.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Create a table for raw ratings\nCREATE TABLE ratings (\n\tmovie_id INT,\n\trating DOUBLE,\n\tevent_time TIMESTAMP (3) ,\n\tWATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n) WITH (\n\t'connector' = 'kafka'\n\t'topic' = 'raw-ratings',\n\t'properties.bootstrap.servers' = 'localhost:9092',\n\t'format' = 'json'\n);\n\nCREATE TABLE avg_ratings AS\nSELECT\n\tmovie_id,\n\tAVG (rating) AS avg_rating,\n\twindow_start,\n\twindow_time\nFROM\n\tTUMBLE(DATA = TABLE ratings,\n\t\tTIMECOL => DESCRIPTOR (event_time),\n\t\tSIZE => INTERVAL '5' MINUTES)\nGROUP BY movie_id, window_start, window_end,\n\twindow_time;\n\n-- Create a table for movies\nCREATE TABLE movies (\n\tmovie_id INT,\n\ttitle STRING\n) WITH (\n\t'connector' = 'kafka'\n\t'topic' = 'movies',\n\t'properties.bootstrap,servers' = 'localhost:9092',\n\t'format' = 'json'\n);\n\n-- Join the computed ratings with movie data\nCREATE TABLE rated_movies AS\nSELECT r. movie_id,\n\tm. title,\n\tr.avg_rating,\n\tr. window_start\nFROM avg_ratings r\nJOIN movies m ON r.movie_id = m.movie_id;\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(296540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);