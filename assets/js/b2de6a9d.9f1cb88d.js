"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[21166],{610203:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference","title":"14. Intro to Bayesian Inference","description":"The power of Bayesian statistics","source":"@site/docs/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference.md","sourceDirName":"mathematics/probability/intro-to-probability","slug":"/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference","permalink":"/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1707138374000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"13. Conditional expectation and variance revisited","permalink":"/mathematics/probability/intro-to-probability/13.-conditional-expectation-and-variance-revisited"},"next":{"title":"2. Conditioning and Independence","permalink":"/mathematics/probability/intro-to-probability/2.-conditioning-and-independence"}}');var a=n(474848),s=n(28453);const o={},r="14. Intro to Bayesian Inference",c={},l=[{value:"The power of Bayesian statistics",id:"the-power-of-bayesian-statistics",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"14-intro-to-bayesian-inference",children:"14. Intro to Bayesian Inference"})}),"\n",(0,a.jsx)(t.h2,{id:"the-power-of-bayesian-statistics",children:"The power of Bayesian statistics"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Outcome characterization - This is the distribution of things that happened"}),"\n",(0,a.jsx)(t.li,{children:"Latent factor analysis - These are the things affect your outcome"}),"\n",(0,a.jsx)(t.li,{children:"Decision making - Given all the potential outcomes here's the most optimal choice we should make today"}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://www.youtube.com/watch?v=pJH_2y9J9-I",children:"https://www.youtube.com/watch?v=pJH_2y9J9-I"})}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"We apply the Bayes rule to find the posterior distribution of an unknown random variable given one or multiple observations of related random variables."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"We discuss the most common methods for coming up with a point estimate of the unknown random variable (Maximum a Posteriori probability estimate, Least Mean Squares estimate, and Linear Least Mean Squares estimate)."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"We consider the question of performance analysis, namely, the calculation of the probability of error in hypothesis testing problems or the calculation of the mean squared error in estimation problems."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"To illustrate the methodology, we pay special attention to a few canonical problems such as linear normal models and the problem of estimating the unknown bias of a coin."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(488686).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(768953).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(782076).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(899975).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(932234).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(524309).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(103640).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(761251).A+"",width:"999",height:"562"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:n(387494).A+"",width:"999",height:"562"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://www.youtube.com/watch?v=HZGCoVF3YvM",children:"Bayes theorem, and making probability intuitive"}),"- Bayes' theorem describe the probability of an event occurring, based upon prior knowledge of other variables related to that event"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In effect, it is a conditional probability, with the probability of an event conditioned on the information/knowledge you have"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Since the information/knowledge that different individuals can have about an event can vary, Bayes' thorem allows for differences in probability estimates for the same event across individuals"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In Bayesian Inference, you update the probability of an event happening as you receive new evidence or information"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"The probability that you assign to an event before you receive the new information represent your priors"}),"\n",(0,a.jsx)(t.li,{children:"The probability that you assign to that same event after receiving and processing new information represent your posterior estimate"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},488686:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image1-f7ff7e1f72df900d0818829c079a8403.jpg"},768953:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image2-5d94754401f53b9e2d16ea019ff27c9c.jpg"},782076:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image3-e8d61714c6b03cf443ad93431848672a.jpg"},899975:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image4-5f732b3444e4095aa5664d4782d0669b.jpg"},932234:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image5-c6eff2d0bd6692edfdac991aef87329f.jpg"},524309:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image6-12803bf849de9a835523b68b30bb0371.jpg"},103640:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image7-0f08c1f0da482c0df7519250e4e6c423.jpg"},761251:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image8-5c55945d87c624c7fd9ba8d5f4d38595.jpg"},387494:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image9-9fc5c69d83037f6ea28e6f816db3e439.jpg"},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var i=n(296540);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);