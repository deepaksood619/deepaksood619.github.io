"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[5755],{679027:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"technologies/apache-airflow/others","title":"Others","description":"Cadence","source":"@site/docs/technologies/apache-airflow/others.md","sourceDirName":"technologies/apache-airflow","slug":"/technologies/apache-airflow/others","permalink":"/technologies/apache-airflow/others","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/apache-airflow/others.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1769598990000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Airflow","permalink":"/technologies/apache-airflow/intro"},"next":{"title":"Parallelism","permalink":"/technologies/apache-airflow/parallelism"}}');var r=i(474848),s=i(28453);const a={},o="Others",l={},c=[{value:"Cadence",id:"cadence",level:2},{value:"Dynein",id:"dynein",level:2},{value:"Immediate Jobs",id:"immediate-jobs",level:3},{value:"Delayed Jobs",id:"delayed-jobs",level:3},{value:"Quartz",id:"quartz",level:2},{value:"Dkron",id:"dkron",level:2},{value:"Airflow + Genie on AWS Platform",id:"airflow--genie-on-aws-platform",level:2},{value:"Prefect",id:"prefect",level:2},{value:"Netflix Conductor (Archived)",id:"netflix-conductor-archived",level:2},{value:"Temporal",id:"temporal",level:2},{value:"Event-driven Architecture",id:"event-driven-architecture",level:3},{value:"Limitations of Apache Kafka for Workflow Orchestration",id:"limitations-of-apache-kafka-for-workflow-orchestration",level:4},{value:"Links",id:"links",level:3},{value:"Dagster",id:"dagster",level:2},{value:"Mage.ai",id:"mageai",level:2},{value:"Flyte",id:"flyte",level:2},{value:"Flyte vs Airflow",id:"flyte-vs-airflow",level:3},{value:"DVC",id:"dvc",level:2},{value:"Airbyte",id:"airbyte",level:2},{value:"CDC",id:"cdc",level:3},{value:"Airbyte\u2019s replication modes",id:"airbytes-replication-modes",level:4},{value:"Others",id:"others-1",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"others",children:"Others"})}),"\n",(0,r.jsx)(t.h2,{id:"cadence",children:"Cadence"}),"\n",(0,r.jsx)(t.p,{children:"Cadence is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way."}),"\n",(0,r.jsx)(t.p,{children:"Business logic is modeled as workflows and activities. Workflows are the implementation of coordination logic. Its sole purpose is to orchestrate activity executions. Activities are the implementation of a particular task in the business logic. The workflow and activity implementation are hosted and executed in worker processes. These workers long-poll the Cadence server for tasks, execute the tasks by invoking either a workflow or activity implementation, and return the results of the task back to the Cadence server. Furthermore, the workers can be implemented as completely stateless services which in turn allows for unlimited horizontal scaling."}),"\n",(0,r.jsx)(t.p,{children:"The Cadence server brokers and persists tasks and events generated during workflow execution, which provides certain scalability and reliability guarantees for workflow executions. An individual activity execution is not fault tolerant as it can fail for various reasons. But the workflow that defines in which order and how (location, input parameters, timeouts, etc.) activities are executed is guaranteed to continue execution under various failure conditions."}),"\n",(0,r.jsx)(t.p,{children:"Cadence fault-oblivious stateful code platform preserves complete multithreaded application state including thread stacks with local variables across hardware and software failures. It greatly simplifies coding of complex stateful distributed applications."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/uber/cadence",children:"https://github.com/uber/cadence"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://cadenceworkflow.io/",children:"https://cadenceworkflow.io"})}),"\n",(0,r.jsx)(t.h2,{id:"dynein",children:"Dynein"}),"\n",(0,r.jsx)(t.p,{children:"Dynein is Airbnb's Open-source Distributed Delayed Job Queueing System."}),"\n",(0,r.jsx)(t.p,{children:"We can divide Dynein jobs into two categories: immediate jobs and delayed jobs."}),"\n",(0,r.jsx)(t.h3,{id:"immediate-jobs",children:"Immediate Jobs"}),"\n",(0,r.jsx)(t.p,{children:"For immediate jobs, or jobs that are scheduled to run within 15 minutes, Dynein simply works as a wrapper of the SQS API - Jobs submitted to Dynein will be relayed to an SQS queue immediately, and the job will then be consumed by consumers with the SQS dequeue API. We opted to wrap the SQS API rather than have services directly enqueue to SQS because this approach offers us expansive metrics coverage, as well as tight integration with Airbnb's internal rate-limiting and backpressure systems. Additionally, our users can use the same API they use for delayed jobs."}),"\n",(0,r.jsx)(t.h3,{id:"delayed-jobs",children:"Delayed Jobs"}),"\n",(0,r.jsx)(t.p,{children:"Dynein takes a more elaborate approach to delayed jobs. Delayed jobs, to Dynein, means deliver the right message to the right service queue at the right time. When a delayed job is submitted to Dynein, it is immediately put into an SQS queue - we call it inbound queue. This queue works as a write buffer for our scheduler, designed so that we can sustain small spikes in jobs submitted. Not only does the inbound queue protect our system from write spikes, but it also gives us clear indicating metrics that such issues are happening. SQS gives us enough time to figure out what the issue is, fix it, and then process the backlog."}),"\n",(0,r.jsx)(t.p,{children:"Dynein service then picks up the job from the inbound queue with a consistent ingestion rate, and stores a trigger for the job into the scheduler. At the scheduled time, Dynein service selects the jobs from the scheduler, and then enqueues the jobs into SQS. The Dynein service is completely stateless, and runs as a simple Deployment on Kubernetes platform."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/airbnb/dynein",children:"https://github.com/airbnb/dynein"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://medium.com/airbnb-engineering/dynein-building-a-distributed-delayed-job-queueing-system-93ab10f05f99",children:"https://medium.com/airbnb-engineering/dynein-building-a-distributed-delayed-job-queueing-system-93ab10f05f99"})}),"\n",(0,r.jsx)(t.h2,{id:"quartz",children:"Quartz"}),"\n",(0,r.jsxs)(t.p,{children:["Quartz is a ",(0,r.jsx)(t.a,{href:"http://www.quartz-scheduler.org/documentation/2.4.0-SNAPSHOT/introduction.html#features",children:"richly featured"}),", open source job scheduling library that can be integrated within virtually any Java application - from the smallest stand-alone application to the largest e-commerce system. Quartz can be used to create simple or complex schedules for executing tens, hundreds, or even tens-of-thousands of jobs; jobs whose tasks are defined as standard Java components that may execute virtually anything you may program them to do. The Quartz Scheduler includes many enterprise-class features, such as support for JTA transactions and clustering."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"http://www.quartz-scheduler.org",children:"http://www.quartz-scheduler.org"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/quartz-scheduler/quartz",children:"https://github.com/quartz-scheduler/quartz"})}),"\n",(0,r.jsx)(t.h2,{id:"dkron",children:"Dkron"}),"\n",(0,r.jsx)(t.p,{children:"Dkron is a distributed cron service, easy to setup and fault tolerant with focus in:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Easy: Easy to use with a great UI"}),"\n",(0,r.jsx)(t.li,{children:"Reliable: Completely fault tolerant"}),"\n",(0,r.jsx)(t.li,{children:"High scalable: Able to handle high volumes of scheduled jobs and thousands of nodes"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Dkron is written in Go and leverage the power of distributed key-value stores and serf for providing fault tolerance, reliability and scalability while keeping simple and easily installable."}),"\n",(0,r.jsxs)(t.p,{children:["Dkron is inspired by the google whitepaper ",(0,r.jsx)(t.a,{href:"https://queue.acm.org/detail.cfm?id=2745840",children:"Reliable Cron across the Planet"})," and by Airbnb Chronos borrowing the same features from it."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/victorcoder/dkron",children:"https://github.com/victorcoder/dkron"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://dkron.io",children:"https://dkron.io"})}),"\n",(0,r.jsx)(t.h2,{id:"airflow--genie-on-aws-platform",children:"Airflow + Genie on AWS Platform"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"image",src:i(201411).A+"",width:"999",height:"328"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://aws.amazon.com/blogs/big-data/orchestrate-big-data-workflows-with-apache-airflow-genie-and-amazon-emr-part-1",children:"https://aws.amazon.com/blogs/big-data/orchestrate-big-data-workflows-with-apache-airflow-genie-and-amazon-emr-part-1"})}),"\n",(0,r.jsx)(t.h2,{id:"prefect",children:"Prefect"}),"\n",(0,r.jsx)(t.p,{children:"Prefect is a new workflow management system, designed for modern infrastructure and powered by the open-source Prefect Core workflow engine. Users organize Tasks into Flows, and Prefect takes care of the rest."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/prefecthq/prefect",children:"https://github.com/prefecthq/prefect"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://www.prefect.io",children:"https://www.prefect.io"})}),"\n",(0,r.jsx)(t.h2,{id:"netflix-conductor-archived",children:"Netflix Conductor (Archived)"}),"\n",(0,r.jsx)(t.p,{children:"Conductor is a microservices orchestration engine"}),"\n",(0,r.jsx)(t.p,{children:"We built Conductor to help us orchestrate microservices based process flows at Netflix with the following features:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"A distributed server ecosystem, which stores workflow state information efficiently."}),"\n",(0,r.jsx)(t.li,{children:"Allow creation of process / business flows in which each individual task can be implemented by the same / different microservices."}),"\n",(0,r.jsx)(t.li,{children:"A JSON DSL based blueprint defines the execution flow."}),"\n",(0,r.jsx)(t.li,{children:"Provide visibility and traceability into these process flows."}),"\n",(0,r.jsx)(t.li,{children:"Simple interface to connect workers, which execute the tasks in workflows."}),"\n",(0,r.jsx)(t.li,{children:"Full operational control over workflows with the ability to pause, resume, restart, retry and terminate."}),"\n",(0,r.jsx)(t.li,{children:"Allow greater reuse of existing microservices providing an easier path for onboarding."}),"\n",(0,r.jsx)(t.li,{children:"User interface to visualize, replay and search the process flows."}),"\n",(0,r.jsx)(t.li,{children:"Ability to scale to millions of concurrently running process flows."}),"\n",(0,r.jsx)(t.li,{children:"Backed by a queuing service abstracted from the clients."}),"\n",(0,r.jsx)(t.li,{children:"Be able to operate on HTTP or other transports e.g. gRPC."}),"\n",(0,r.jsx)(t.li,{children:"Event handlers to control workflows via external actions."}),"\n",(0,r.jsx)(t.li,{children:"Client implementations in Java, Python and other languages."}),"\n",(0,r.jsx)(t.li,{children:"Various configurable properties with sensible defaults to fine tune workflow and task executions like rate limiting, concurrent execution limits etc."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/Netflix/conductor",children:"https://github.com/Netflix/conductor"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://netflix.github.io/conductor",children:"https://netflix.github.io/conductor"})}),"\n",(0,r.jsx)(t.h2,{id:"temporal",children:"Temporal"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Durable Execution:"})," a new abstraction for developers"]}),"\n",(0,r.jsx)(t.p,{children:"Durable Execution is a development abstraction that preserves complete application state so that upon host or software failure it can seamlessly migrate execution to another machine."}),"\n",(0,r.jsxs)(t.p,{children:["A\xa0",(0,r.jsx)(t.strong,{children:"durable execution engine"}),"\xa0ensures reliable, stateful execution of workflows and processes in distributed systems. It\u2019s designed to manage workflows that are long-running, complex, or require durability across retries and failures. These engines:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Persist the state of workflows to durable storage (e.g., databases)."}),"\n",(0,r.jsx)(t.li,{children:"Automatically handle retries, timeouts, and rollbacks."}),"\n",(0,r.jsx)(t.li,{children:"Manage distributed transactions in a fault-tolerant way."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Temporal is an open source implementation of Durable Execution created by the originators of the abstraction."}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.a,{href:"https://docs.temporal.io/temporal",children:"Temporal Platform"})," provides developers a suite of effective tools for building reliable applications at scale."]}),"\n",(0,r.jsx)(t.p,{children:"The concepts, components, and features of the platform are described in detail across the concept guides."}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/temporal",children:"Temporal"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/workflows",children:"Workflows"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/activities",children:"Activities"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/workers",children:"Workers"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/retry-policies",children:"Retry Policies"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/clusters",children:"Clusters"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/visibility",children:"Visibility"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/namespaces",children:"Namespaces"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/dataconversion",children:"Data conversion"})}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"event-driven-architecture",children:"Event-driven Architecture"}),"\n",(0,r.jsx)(t.p,{children:"Durable execution engines like Temporal and Restate are redefining how developers orchestrate long-running, stateful workflows in distributed systems. Unlike traditional BPM tools focused on human-centric tasks, these engines automate machine-to-machine processes with built-in durability, retries, and fault-tolerant coordination. When integrated with event-driven platforms like Apache Kafka, they enable scalable, resilient architectures\u2014handling complex business logic such as order processing, fraud detection, and multi-step transactions. This blog explores their capabilities, differences from stream processing tools like Apache Flink, Kafka Streams or Spark Structured Streaming, and the emerging role they play in modern enterprise infrastructure."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Feature"}),(0,r.jsx)(t.th,{children:"BPM Engine"}),(0,r.jsx)(t.th,{children:"Durable Execution Engine"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Focus"}),(0,r.jsx)(t.td,{children:"Human workflows, approvals, and form-based processes"}),(0,r.jsx)(t.td,{children:"Optimized for long-running, automated, fault-tolerant service orchestration"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Durability"}),(0,r.jsx)(t.td,{children:"Often limited to task-level state"}),(0,r.jsx)(t.td,{children:"Built-in, state persists across failures"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Development Model"}),(0,r.jsx)(t.td,{children:"Visual workflow modeling"}),(0,r.jsx)(t.td,{children:"Code-first"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Scalability"}),(0,r.jsx)(t.td,{children:"Limited scalability"}),(0,r.jsx)(t.td,{children:"Optimized for distributed, scalable systems"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Example Use Cases"}),(0,r.jsx)(t.td,{children:"Employee Onboarding, Invoice Approval Workflow, Loan Application Processing, Customer Complaint Resolution"}),(0,r.jsx)(t.td,{children:"Order Fulfillment in E-commerce, Insurance Claims Processing, Subscription Billing and Renewal, IoT Sensor Alert Workflow, Financial Transaction Settlement"})]})]})]}),"\n",(0,r.jsx)(t.h4,{id:"limitations-of-apache-kafka-for-workflow-orchestration",children:"Limitations of Apache Kafka for Workflow Orchestration"}),"\n",(0,r.jsxs)(t.p,{children:["While\xa0",(0,r.jsx)(t.strong,{children:"Apache Kafka"}),", combined with stream processing,\xa0can act as a\xa0",(0,r.jsx)(t.strong,{children:"workflow engine"}),", there are\xa0",(0,r.jsx)(t.strong,{children:"limitations"}),":"]}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Manual State Management"}),": Kafka, or more generally data streaming, lacks built-in tools for tracking workflow states or managing retries. Developers must implement these manually using patterns like saga orchestration."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Lack of Workflow Semantics"}),": Kafka Topics are excellent for messaging and as persistence layer for events, but stream processing lack built-in constructs like parallel execution or compensations."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Code Complexity"}),": Building a full-fledged workflow engine on Kafka and stream processing engines like Kafka Streams, Flink, or Spark Structured Streaming adds significant custom development overhead."]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://www.kai-waehner.de/blog/2025/06/05/the-rise-of-the-durable-execution-engine-temporal-restate-in-an-event-driven-architecture-apache-kafka/",children:"\xad\xadThe Rise of the Durable Execution Engine (Temporal, Restate) in an Event-driven Architecture (Apache Kafka) - Kai Waehner"})}),"\n",(0,r.jsx)(t.h3,{id:"links",children:"Links"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://temporal.io/",children:"Open Source Durable Execution | Temporal Technologies"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://github.com/temporalio/temporal",children:"GitHub - temporalio/temporal: Temporal service"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=wIpz4ioK0gI",children:"Getting to know Temporal - YouTube"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/",children:"Documentation | Temporal Documentation"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.temporal.io/web-ui",children:"Temporal Web UI | Temporal Documentation"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://medium.com/safetycultureengineering/building-resilient-microservice-workflows-with-temporal-a-next-gen-workflow-engine-a9637a73572d",children:"Building Resilient Microservice Workflows with Temporal: A Next-Gen Workflow Engine | by Dixon Deng | SafetyCulture Engineering | Medium"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://mikhail.io/2021/03/maru-load-testing-tool-for-temporal-workflows/",children:"Maru: Load Testing Tool for Temporal Workflows | Mikhail Shilkov"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://platformatory.io/blog/Introduction-to-Temporal/",children:"Introduction to Temporal | The Write Ahead Log"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://temporal.io/blog/city-of-systems-temporal-kafka-nexus",children:"The city of systems: Temporal, Kafka, and Nexus | Temporal"})}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"dagster",children:"Dagster"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"/ai/big-data/tools#Dagster",children:"Dagster"})}),"\n",(0,r.jsx)(t.h2,{id:"mageai",children:"Mage.ai"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"https://github.com/mage-ai/mage-ai",children:"GitHub - mage-ai/mage-ai: \ud83e\uddd9 Build, run, and manage data pipelines for integrating and transforming data."})," - 8K stars"]}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.mage.ai/",children:"Give your data team magical powers | Mage"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=3gXsFEC3aYA",children:"The Airflow alternative worth checking out: Mage.ai - YouTube"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://github.com/mage-ai/mage-ai/blob/master/mage_integrations/mage_integrations/destinations/bigquery/README.md",children:"mage-ai/mage_integrations/mage_integrations/destinations/bigquery/README.md at master \xb7 mage-ai/mage-ai \xb7 GitHub"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://github.com/mage-ai/mage-ai/issues/5345",children:"[BUG] Pipelines stuck due to high CPU usage of Mage scheduler \xb7 Issue #5345 \xb7 mage-ai/mage-ai \xb7 GitHub"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.mage.ai/events/multi-tenant-foundation-for-data-mesh-excellence-in-mage-pro",children:"Multi-Tenant Foundation for Data Mesh Excellence in Mage Pro - Magical workflows for data engineering \u2013 Mage AI"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://docs.mage.ai/guides/tips-and-tricks",children:"Mage tips & tricks - Mage AI"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://youtu.be/jQZb3lrAb8w",children:"Mage Tips & Tricks: Dynamic Blocks - YouTube"})}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"flyte",children:"Flyte"}),"\n",(0,r.jsx)(t.p,{children:"Build & deploy data & ML pipelines, hassle-free"}),"\n",(0,r.jsx)(t.p,{children:"The infinitely scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks."}),"\n",(0,r.jsx)(t.p,{children:"Flyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. It is built for scalability and reproducibility, leveraging Kubernetes as its underlying platform. With Flyte, user teams can construct pipelines using the Python SDK, and seamlessly deploy them on both cloud and on-premises environments, enabling distributed processing and efficient resource utilization."}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://flyte.org/",children:"Build production-grade data and ML workflows, hassle-free with Flyte"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://github.com/flyteorg/flyte",children:"GitHub - flyteorg/flyte: Scalable and flexible workflow orchestration platform that seamlessly unifies data, ML and analytics stacks."})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=0cP9pLLeqT4",children:"Flyte School: A Practical Introduction to Machine Learning Orchestration - YouTube"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=Km2ii0F8Yl0",children:"Self-serve Feature Engineering Platform Using Flyte and Feast - Ketan Umare, & Felix Wang, - YouTube"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=7ZDFhZ4hut0",children:"Flyte: Production-Grade Data and Machine Learning Orchestration - Shivay Lamba & Ekansh Gupta - YouTube"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=EQSHqtlTXwM",children:"Flyte School: Flyte Architecture Deep Dive - YouTube"})}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"flyte-vs-airflow",children:"Flyte vs Airflow"}),"\n",(0,r.jsx)(t.p,{children:"Flyte simplifies building data and ML workflows with its user-friendly SDK. It also supports flexible scaling with minimal infrastructure costs and effort. In contrast, Airflow does not offer an infrastructure-oriented setup, which means more effort to manage the platform. Designed for teams who want more productivity, Flyte helps you easily organize and manage your workflows from the start."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://flyte.org/airflow-alternative",children:"Airflow Alternate \u2022 Flyte vs. Airflow"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://eng.lyft.com/orchestrating-data-pipelines-at-lyft-comparing-flyte-and-airflow-72c40d143aad",children:"Orchestrating Data Pipelines at Lyft: comparing Flyte and Airflow | by Constantine Slisenka | Lyft Engineering"})}),"\n",(0,r.jsx)(t.h2,{id:"dvc",children:"DVC"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://dvc.org/",children:"DVC"}),' stands for "data version control". This project invites data scientists and engineers to a Git-inspired world, where all workflow versions are tracked, along with all the data artifacts and models, as well as associated metrics.']}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Data Version Control"})," or ",(0,r.jsx)(t.strong,{children:"DVC"})," is a command line tool and ",(0,r.jsx)(t.a,{href:"https://github.com/iterative/dvc#vs-code-extension",children:"VS Code Extension"})," to help you develop reproducible machine learning projects:"]}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Version"})," your data and models. Store them in your cloud storage but keep their version info in your Git repo."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Iterate"})," fast with lightweight pipelines. When you make changes, only run the steps impacted by those changes."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Track"})," experiments in your local Git repo (no servers needed)."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Compare"})," any data, code, parameters, model, or performance plots."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Share"})," experiments and automatically reproduce anyone's experiment."]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://dvc.org",children:"Data Version Control \xb7 DVC"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/iterative/dvc",children:"GitHub - iterative/dvc: \ud83e\udd89 ML Experiments Management with Git"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://www.analyticsvidhya.com/blog/2021/06/mlops-tracking-ml-experiments-with-data-version-control/",children:"Tracking ML Experiments With Data Version Control"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://opstree.com/blog/2025/04/22/a-simple-guide-to-dvc-what-it-is-and-how-to-get-started/",children:"A Simple Guide to DVC: What It Is and How to Get Started - DEVOPS DONE RIGHT."})}),"\n",(0,r.jsx)(t.h2,{id:"airbyte",children:"Airbyte"}),"\n",(0,r.jsx)(t.p,{children:"The leading data integration platform for ETL / ELT data pipelines from APIs, databases & files to data warehouses, data lakes & data lakehouses. Both self-hosted and Cloud-hosted."}),"\n",(0,r.jsxs)(t.p,{children:["Ultimate vision is to help you move data from any source to any destination. Airbyte already provides the largest ",(0,r.jsx)(t.a,{href:"https://docs.airbyte.com/integrations/",children:"catalog"})," of 300+ connectors for APIs, databases, data warehouses, and data lakes."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/airbytehq/airbyte",children:"GitHub - airbytehq/airbyte: The leading data integration platform for ETL / ELT data pipelines from APIs, databases & files to data warehouses, data lakes & data lakehouses. Both self-hosted and Cloud-hosted."})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://airbyte.com/",children:"Airbyte | Open-Source Data Integration Platform | ELT tool"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://docs.airbyte.com/using-airbyte/getting-started",children:"Getting Started | Airbyte Documentation"})}),"\n",(0,r.jsx)(t.h3,{id:"cdc",children:"CDC"}),"\n",(0,r.jsxs)(t.p,{children:["To support CDC, Airbyte uses ",(0,r.jsx)(t.a,{href:"https://debezium.io/",children:"Debezium"})," internally."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://airbyte.com/tutorials/incremental-change-data-capture-cdc-replication",children:"Airbyte's incremental Change Data Capture (CDC) replication"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://www.reddit.com/r/dataengineering/comments/13me0t9/how_useful_is_airbytes_in_production_pipelines/",children:"How useful is Airbytes in production pipelines? : r/dataengineering"})}),"\n",(0,r.jsx)(t.h4,{id:"airbytes-replication-modes",children:"Airbyte\u2019s replication modes"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"What is Airbyte\u2019s ELT approach to data integration?"}),"\n",(0,r.jsx)(t.li,{children:"Why is ELT preferred over ETL?"}),"\n",(0,r.jsx)(t.li,{children:"What is a cursor?"}),"\n",(0,r.jsx)(t.li,{children:"What is a primary key used for?"}),"\n",(0,r.jsx)(t.li,{children:"What is the difference between full refresh replication and incremental sync replication?"}),"\n",(0,r.jsx)(t.li,{children:"What does it mean to append data rather than overwrite it in the destination?"}),"\n",(0,r.jsx)(t.li,{children:"How is incremental sync with deduped history different from incremental sync with append?"}),"\n",(0,r.jsx)(t.li,{children:"What are the advantages of log-based change data capture (CDC) replication versus standard replication?"}),"\n",(0,r.jsx)(t.li,{children:"Which replication mode should you choose?"}),"\n"]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Full refresh replication"}),(0,r.jsx)(t.th,{children:"Incremental sync replication"})]})}),(0,r.jsx)(t.tbody,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsxs)(t.td,{children:["The ",(0,r.jsx)(t.strong,{children:"entire data set"})," will be retrieved from the source and sent to the destination on each sync run."]}),(0,r.jsxs)(t.td,{children:["Only records that have been ",(0,r.jsx)(t.strong,{children:"inserted or updated"})," in the source system since the previous sync run are sent to the destination."]})]})})]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://airbyte.com/blog/understanding-data-replication-modes",children:"An overview of Airbyte\u2019s replication modes | Airbyte"})}),"\n",(0,r.jsx)(t.h2,{id:"others-1",children:"Others"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/alseambusher/crontab-ui",children:"GitHub - alseambusher/crontab-ui: Easy and safe way to manage your crontab file"})}),"\n",(0,r.jsxs)(t.p,{children:["Amazon Managed Workflows for Apache Airflow (MWAA) ",(0,r.jsx)(t.a,{href:"https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html",children:"What Is Amazon Managed Workflows for Apache Airflow? - Amazon Managed Workflows for Apache Airflow"})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.a,{href:"https://www.youtube.com/watch?v=ZET50M20hkU",children:"Amazon Managed Workflows for Apache Airflow: Getting Started - YouTube"})}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Amazon MWAA Architecture",src:i(196209).A+"",width:"1000",height:"535"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/astronomer/airflow-ai-sdk",children:"GitHub - astronomer/airflow-ai-sdk: An SDK for working with LLMs and AI Agents from Apache Airflow, based on Pydantic AI"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://www.cloverdx.com/",children:"CloverDX Data Integration Platform"})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},196209:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/Pasted image 20240109123958-6922bca91cf6c8b26298ba10ef91d389.jpg"},201411:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/Technologies-Apache-Others-image1-c5b843723a7d5b09f50530e70044dc8d.jpg"},28453:(e,t,i)=>{i.d(t,{R:()=>a,x:()=>o});var n=i(296540);const r={},s=n.createContext(r);function a(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);