"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[47441],{685461:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"computer-science/system-design/case-study/10-appendix","title":"Appendix","description":"Detailed Technical Appendix: Implementation Reference","source":"@site/docs/computer-science/system-design/case-study/10-appendix.md","sourceDirName":"computer-science/system-design/case-study","slug":"/computer-science/system-design/case-study/10-appendix","permalink":"/computer-science/system-design/case-study/10-appendix","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/computer-science/system-design/case-study/10-appendix.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1769708615000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Conclusion","permalink":"/computer-science/system-design/case-study/05-conclusion"},"next":{"title":"Cloud Native","permalink":"/computer-science/system-design/cloud-native"}}');var i=t(474848),r=t(28453);const a={},c="Appendix",d={},o=[{value:"A.1 Comparison of Stream Processing Options",id:"a1-comparison-of-stream-processing-options",level:2},{value:"A.2 Data Lineage and Governance",id:"a2-data-lineage-and-governance",level:2},{value:"A.3 Mocking the External API: Technical Detail",id:"a3-mocking-the-external-api-technical-detail",level:2},{value:"A.4 Flink &quot;Create Connection&quot; Syntax",id:"a4-flink-create-connection-syntax",level:2},{value:"A.5 Handling Scale: The &quot;Thundering Herd&quot;",id:"a5-handling-scale-the-thundering-herd",level:2}];function l(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"appendix",children:"Appendix"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Detailed Technical Appendix: Implementation Reference"})}),"\n",(0,i.jsx)(n.h2,{id:"a1-comparison-of-stream-processing-options",children:"A.1 Comparison of Stream Processing Options"}),"\n",(0,i.jsx)(n.p,{children:"The following table details the technical evaluation performed to select the processing engine for BFB."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Feature"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Apache Flink (Recommended)"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"ksqlDB"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Kafka Streams"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Spark Structured Streaming"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Primary Use Case"})}),(0,i.jsx)(n.td,{children:"Complex stateful processing, Event-driven apps."}),(0,i.jsx)(n.td,{children:"Streaming Database, Simple SQL transformations."}),(0,i.jsx)(n.td,{children:"Microservices, Java/Kotlin apps."}),(0,i.jsx)(n.td,{children:"Micro-batch processing, Analytics."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"External Async I/O"})}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Native Support."})," High throughput via non-blocking I/O."]}),(0,i.jsx)(n.td,{children:"Limited. UDFs are synchronous/blocking (performance bottleneck)."}),(0,i.jsx)(n.td,{children:"Supported but requires complex manual threading code."}),(0,i.jsx)(n.td,{children:"Supported but micro-batch architecture increases minimum latency."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"State Management"})}),(0,i.jsx)(n.td,{children:"RocksDB backend. Handles TBs of state."}),(0,i.jsx)(n.td,{children:"RocksDB backend. Good state handling."}),(0,i.jsx)(n.td,{children:"RocksDB. Tied to the application instance."}),(0,i.jsx)(n.td,{children:"HDFS/S3 checkpoints. Higher latency for state updates."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Join Support"})}),(0,i.jsx)(n.td,{children:"Interval, Temporal, Window, Lookup Joins."}),(0,i.jsx)(n.td,{children:"Stream-Stream, Stream-Table."}),(0,i.jsx)(n.td,{children:"Stream-Stream, Stream-Table."}),(0,i.jsx)(n.td,{children:"Stream-Stream, Stream-Static."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"True Streaming (Event-at-a-time)."})," Sub-second."]}),(0,i.jsx)(n.td,{children:"True Streaming. Sub-second."}),(0,i.jsx)(n.td,{children:"True Streaming. Sub-second."}),(0,i.jsx)(n.td,{children:"Micro-batch (Seconds)."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Deployment Model"})}),(0,i.jsx)(n.td,{children:"Fully Managed in Confluent Cloud (Serverless)."}),(0,i.jsx)(n.td,{children:"Fully Managed (Confluent Cloud)."}),(0,i.jsx)(n.td,{children:"Self-managed library (embedded in app)."}),(0,i.jsx)(n.td,{children:"Managed (Databricks) or Self-managed."})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Justification:"})," Spark was rejected due to its micro-batch architecture, which introduces inherent latency unacceptable for POS. Kafka Streams was rejected due to the complexity of implementing non-blocking Async I/O manually. ksqlDB was rejected because its UDF architecture blocks processing threads during external API calls. Flink remains the only viable option for high-throughput, low-latency asynchronous enrichment."]}),"\n",(0,i.jsx)(n.h2,{id:"a2-data-lineage-and-governance",children:"A.2 Data Lineage and Governance"}),"\n",(0,i.jsxs)(n.p,{children:["Using Confluent ",(0,i.jsx)(n.strong,{children:"Stream Lineage"}),", BFB can visualize the data flow."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Node 1 (Source):"})," ",(0,i.jsx)(n.code,{children:"POS_Connector"})," (Datagen) -> Topic: ",(0,i.jsx)(n.code,{children:"loan_applications"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Node 2 (Process):"})," ",(0,i.jsx)(n.code,{children:"Flink_Router_Job"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["-> Path A: Topic ",(0,i.jsx)(n.code,{children:"internal_checks"})]}),"\n",(0,i.jsxs)(n.li,{children:["-> Path B: Topic ",(0,i.jsx)(n.code,{children:"external_checks"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Node 3 (Process):"})," ",(0,i.jsx)(n.code,{children:"Flink_Enrichment_Job"})," (The Async Bureau Lookup)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Node 4 (Sink):"})," Topic ",(0,i.jsx)(n.code,{children:"loan_decisions"})," -> ",(0,i.jsx)(n.code,{children:"POS_Response_Service"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This visualization is automated in Confluent Cloud, providing immediate operational visibility into throughput and lag at every stage of the BNPL pipeline."}),"\n",(0,i.jsx)(n.h2,{id:"a3-mocking-the-external-api-technical-detail",children:"A.3 Mocking the External API: Technical Detail"}),"\n",(0,i.jsx)(n.p,{children:'To replicate the "Unknown User" challenge without a real Equifax subscription, we use a simple Python simulation script.'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"mock_bureau.py"})})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI\nfrom pydantic import BaseModel\nimport random\nimport asyncio\n\napp = FastAPI()\n\nclass CreditRequest(BaseModel):\n    ssn: str\n\n@app.post("/v1/score")\nasync def get_score(req: CreditRequest):\n    # Simulate Network Latency (The Core Challenge)\n    # Random delay between 200ms and 1.5 seconds\n    delay = random.uniform(0.2, 1.5)\n    await asyncio.sleep(delay)\n    # Logic to make demo deterministic if needed\n    # e.g. SSN ending in 9 always fails\n    if req.ssn.endswith("9"):\n        return {"ssn": req.ssn, "score": 450}\n\n    return {\n        "ssn": req.ssn,\n        "score": random.randint(300, 850)\n    }\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Deployment:"})," This script is containerized (Docker) and deployed to a cloud run service (AWS Lambda / Google Cloud Run) to provide a publicly accessible HTTPS endpoint that Flink can query via the ",(0,i.jsx)(n.code,{children:"KEY_SEARCH_AGG"})," function or REST connector."]}),"\n",(0,i.jsx)(n.h2,{id:"a4-flink-create-connection-syntax",children:'A.4 Flink "Create Connection" Syntax'}),"\n",(0,i.jsxs)(n.p,{children:["In Confluent Cloud, we secure the credentials for this external API using the ",(0,i.jsx)(n.code,{children:"CREATE CONNECTION"})," statement. This abstracts the URL and Auth headers from the SQL logic."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CONNECTION CreditBureauConn WITH (\n  'type' = 'rest',\n  'endpoint' = 'https://api.mock-bureau.com',\n  -- For a real bureau, we would use proper auth\n  -- 'api-key' = '<SECRET_API_KEY>'\n  'auth.type' = 'none'\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:"This ensures that sensitive API keys are stored in the Confluent Secret Store and not hardcoded in the SQL queries, adhering to BFB's security policies."}),"\n",(0,i.jsx)(n.h2,{id:"a5-handling-scale-the-thundering-herd",children:'A.5 Handling Scale: The "Thundering Herd"'}),"\n",(0,i.jsx)(n.p,{children:"If a marketing campaign drives 100,000 users to apply simultaneously, the external Credit Bureau API might rate-limit BFB."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Architecture Mitigation:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flink Backpressure:"})," Flink's Async I/O operator has a ",(0,i.jsx)(n.code,{children:"capacity"})," setting (buffer size). If the external API slows down or the buffer fills, Flink will naturally exert backpressure upstream."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Impact:"})," The Kafka consumer in Flink slows down. The ",(0,i.jsx)(n.code,{children:"loan_applications"})," topic accumulates lag."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Result:"})," No data is lost. The system processes at the maximum rate the Credit Bureau allows. BFB can monitor ",(0,i.jsx)(n.code,{children:"consumer_lag"})," metrics in Confluent Cloud to alert operations if the delay becomes unacceptable, triggering discussions with the Bureau for higher rate limits."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This native handling of backpressure is a key advantage of the EDA approach over synchronous REST services, which would simply time out and crash under the load."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>c});var s=t(296540);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);