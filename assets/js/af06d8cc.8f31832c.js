"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[71586],{775218:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>d,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"languages/sql/databricks-sql","title":"Databricks SQL","description":"SQL language reference | Databricks on AWS","source":"@site/docs/languages/sql/databricks-sql.md","sourceDirName":"languages/sql","slug":"/languages/sql/databricks-sql","permalink":"/languages/sql/databricks-sql","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/languages/sql/databricks-sql.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1699168437000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Databricks SQL Functions","permalink":"/languages/sql/databricks-sql-functions"},"next":{"title":"DCL - Data Control Language","permalink":"/languages/sql/dcl-data-control-language"}}');var l=s(474848),t=s(28453);const r={},i="Databricks SQL",d={},c=[{value:"Query",id:"query",level:2},{value:"set_operator",id:"set_operator",level:3},{value:"ORDER BY",id:"order-by",level:3},{value:"DISTRIBUTE BY",id:"distribute-by",level:3},{value:"SORT BY",id:"sort-by",level:3},{value:"CLUSTER BY",id:"cluster-by",level:3},{value:"WINDOW",id:"window",level:3},{value:"Lateral View - map / explode",id:"lateral-view---map--explode",level:3},{value:"Materialized Views",id:"materialized-views",level:2},{value:"Explain",id:"explain",level:2},{value:"Examples",id:"examples",level:2},{value:"Print all",id:"print-all",level:3},{value:"Others",id:"others",level:2}];function o(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(a.header,{children:(0,l.jsx)(a.h1,{id:"databricks-sql",children:"Databricks SQL"})}),"\n",(0,l.jsx)(a.p,{children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/index.html",children:"SQL language reference | Databricks on AWS"})}),"\n",(0,l.jsx)(a.h2,{id:"query",children:"Query"}),"\n",(0,l.jsx)(a.h3,{id:"set_operator",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-setops.html",children:"set_operator"})}),"\n",(0,l.jsxs)(a.p,{children:["A construct combining subqueries using ",(0,l.jsx)(a.code,{children:"UNION"}),", ",(0,l.jsx)(a.code,{children:"EXCEPT"}),", or ",(0,l.jsx)(a.code,{children:"INTERSECT"})," operators."]}),"\n",(0,l.jsx)(a.h3,{id:"order-by",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-orderby.html",children:"ORDER BY"})}),"\n",(0,l.jsxs)(a.p,{children:["An ordering of the rows of the complete result set of the query. The output rows are ordered across the partitions. This parameter is mutually exclusive with ",(0,l.jsx)(a.code,{children:"SORT BY"}),", ",(0,l.jsx)(a.code,{children:"CLUSTER BY"}),", and ",(0,l.jsx)(a.code,{children:"DISTRIBUTE BY"})," and cannot be specified together."]}),"\n",(0,l.jsx)(a.h3,{id:"distribute-by",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-distributeby.html",children:"DISTRIBUTE BY"})}),"\n",(0,l.jsxs)(a.p,{children:["A set of expressions by which the result rows are repartitioned. This parameter is mutually exclusive with ",(0,l.jsx)(a.code,{children:"ORDER BY"})," and ",(0,l.jsx)(a.code,{children:"CLUSTER BY"})," and cannot be specified together."]}),"\n",(0,l.jsx)(a.h3,{id:"sort-by",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-sortby.html",children:"SORT BY"})}),"\n",(0,l.jsxs)(a.p,{children:["An ordering by which the rows are ordered within each partition. This parameter is mutually exclusive with ",(0,l.jsx)(a.code,{children:"ORDER BY"})," and ",(0,l.jsx)(a.code,{children:"CLUSTER BY"})," and cannot be specified together."]}),"\n",(0,l.jsx)(a.h3,{id:"cluster-by",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-clusterby.html",children:"CLUSTER BY"})}),"\n",(0,l.jsxs)(a.p,{children:["A set of expressions that is used to repartition and sort the rows. Using this clause has the same effect of using ",(0,l.jsx)(a.code,{children:"DISTRIBUTE BY"})," and ",(0,l.jsx)(a.code,{children:"SORT BY"})," together."]}),"\n",(0,l.jsx)(a.h3,{id:"window",children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-qry-select-named-window.html",children:"WINDOW"})}),"\n",(0,l.jsxs)(a.p,{children:["Defines named window specifications that can be shared by multiple ",(0,l.jsx)(a.a,{href:"https://docs.databricks.com/sql/language-manual/sql-ref-window-functions.html",children:"Window functions"})," in the ",(0,l.jsx)(a.code,{children:"select_query"}),"."]}),"\n",(0,l.jsx)(a.h3,{id:"lateral-view---map--explode",children:"Lateral View - map / explode"}),"\n",(0,l.jsx)(a.pre,{children:(0,l.jsx)(a.code,{className:"language-sql",children:"WITH data AS (\n SELECT\n  abc,\n  cde,\n  count(1) AS nodes\n FROM\n  table_name\n WHERE\n  filter_col = 'filter_value'\n GROUP BY\n  ALL\n),\n-- Example of storing table as map in a single cell\ndummy_data AS (\n SELECT\n  array_agg((abc, cde, nodes)) AS column_name\n FROM\n  DATA\n)\n-- Go from map cell to rows and columns\nSELECT\n m['abc'] AS abc,\n m['cde'] AS cde,\n m['nodes'] AS nodes\nFROM\n dummy_data LATERAL VIEW explode(column_name) AS m\n"})}),"\n",(0,l.jsx)(a.p,{children:(0,l.jsx)(a.a,{href:"https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-qry-select-lateral-view.html",children:"LATERAL VIEW clause | Databricks"})}),"\n",(0,l.jsx)(a.h2,{id:"materialized-views",children:"Materialized Views"}),"\n",(0,l.jsx)(a.pre,{children:(0,l.jsx)(a.code,{className:"language-sql",children:"create materialized view schema.dev.test_materialized_view_job_run snapshot as select * from schema.dev.job_run limit 100;\n"})}),"\n",(0,l.jsx)(a.p,{children:"Materialized view only run from DBSQL Warehouse and not from notebook."}),"\n",(0,l.jsx)(a.h2,{id:"explain",children:"Explain"}),"\n",(0,l.jsx)(a.p,{children:"Provides the logical or physical plans for an input statement. By default, this clause provides information about a physical plan only."}),"\n",(0,l.jsx)(a.p,{children:(0,l.jsx)(a.code,{children:"EXPLAIN [ EXTENDED | CODEGEN | COST | FORMATTED ] statement"})}),"\n",(0,l.jsxs)(a.ul,{children:["\n",(0,l.jsxs)(a.li,{children:[(0,l.jsx)(a.strong,{children:"EXTENDED"})," - Generates parsed logical plan, analyzed logical plan, optimized logical plan and physical plan. Parsed Logical plan is a unresolved plan that extracted from the query. Analyzed logical plans transforms which translates unresolvedAttribute and unresolvedRelation into fully typed objects. The optimized logical plan transforms through a set of optimization rules, resulting in the physical plan."]}),"\n",(0,l.jsxs)(a.li,{children:[(0,l.jsx)(a.strong,{children:"CODEGEN"})," - Generates code for the statement, if any and a physical plan."]}),"\n",(0,l.jsxs)(a.li,{children:[(0,l.jsx)(a.strong,{children:"COST"})," - If plan node statistics are available, generates a logical plan and the statistics."]}),"\n",(0,l.jsxs)(a.li,{children:[(0,l.jsx)(a.strong,{children:"FORMATTED"})," - Generates two sections: a physical plan outline and node details."]}),"\n",(0,l.jsxs)(a.li,{children:[(0,l.jsx)(a.strong,{children:"statement"})," - A SQL statement to be explained."]}),"\n"]}),"\n",(0,l.jsx)(a.h2,{id:"examples",children:"Examples"}),"\n",(0,l.jsx)(a.pre,{children:(0,l.jsx)(a.code,{className:"language-sql",children:"CREATE TABLE student_copy AS SELECT * FROM student;\n\nSHOW COLUMNS IN `default`.test ;\n\nDESCRIBE TABLE `default`.test ;\n\nSELECT createdAtDate, subject, count(*) FROM students group by ALL ORDER BY ALL;\n"})}),"\n",(0,l.jsx)(a.h3,{id:"print-all",children:"Print all"}),"\n",(0,l.jsx)(a.pre,{children:(0,l.jsx)(a.code,{className:"language-python",children:"schemas = ['bronze', 'silver', 'gold']\n\nfor each_schema in schemas:\n df = spark.sql(f\"SHOW TABLES IN test.{each_schema}\").collect()\n\n for each in df:\n  print(\"\\n\", each)\n  print(spark.sql(f\"DESCRIBE test.{each_schema}.{each[1]}\").collect())\n"})}),"\n",(0,l.jsx)(a.h2,{id:"others",children:"Others"}),"\n",(0,l.jsx)(a.p,{children:(0,l.jsx)(a.a,{href:"https://medium.com/helmes-people/how-to-view-all-databases-tables-and-columns-in-databricks-9683b12fee10",children:"How to view all databases, tables, and columns in Databricks | by Kristo Raun | Helmes People | Medium"})})]})}function h(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,l.jsx)(a,{...e,children:(0,l.jsx)(o,{...e})}):o(e)}},28453:(e,a,s)=>{s.d(a,{R:()=>r,x:()=>i});var n=s(296540);const l={},t=n.createContext(l);function r(e){const a=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),n.createElement(t.Provider,{value:a},e.children)}}}]);