"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[22535],{197233:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"computer-science/operating-system/cpu-gpu-tpu","title":"CPU | GPU | TPU","description":"MAC - Multiplier, Adder, Accumulator","source":"@site/docs/computer-science/operating-system/cpu-gpu-tpu.md","sourceDirName":"computer-science/operating-system","slug":"/computer-science/operating-system/cpu-gpu-tpu","permalink":"/computer-science/operating-system/cpu-gpu-tpu","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/computer-science/operating-system/cpu-gpu-tpu.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1707138374000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Coroutines","permalink":"/computer-science/operating-system/coroutines"},"next":{"title":"Disk IO","permalink":"/computer-science/operating-system/disk-io"}}');var s=t(474848),a=t(28453);const r={},o="CPU | GPU | TPU",c={},l=[{value:"CPU / GPU",id:"cpu--gpu",level:2},{value:"TPU",id:"tpu",level:2},{value:"The Systolic Array",id:"the-systolic-array",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"CPU Time",id:"cpu-time",level:2},{value:"Links",id:"links",level:2}];function h(e){const i={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"cpu--gpu--tpu",children:"CPU | GPU | TPU"})}),"\n",(0,s.jsx)(i.p,{children:"MAC - Multiplier, Adder, Accumulator"}),"\n",(0,s.jsx)(i.p,{children:"Tensor - n-dimensional array"}),"\n",(0,s.jsx)(i.p,{children:"Specifically for matrix operations"}),"\n",(0,s.jsx)(i.h2,{id:"cpu--gpu",children:"CPU / GPU"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"A CPU is a scalar machine, which means it processes instructions one step at a time."}),"\n",(0,s.jsxs)(i.li,{children:["A GPU is composed of hundreds of cores that can handle thousands of threads simultaneously.","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Thats because GPUs were designed for 3d game rendering, which often involves parallel operations -The ability of a GPU with 100+ cores to process thousands of threads can accelerate some software by 100x over a CPU alone."}),"\n",(0,s.jsx)(i.li,{children:"What's more, the GPU achieves this acceleration while being more power- and cost-efficient than a CPU."}),"\n",(0,s.jsx)(i.li,{children:"So when neural networks run on GPUs, they run much faster than on CPUs"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.li,{children:(0,s.jsx)(i.img,{alt:"image",src:t(733565).A+"",width:"817",height:"554"})}),"\n",(0,s.jsx)(i.li,{children:"A GPU is a vector machine. You can give it a long list of data - a 1D vector - and run computations on the entire list at the same time."}),"\n",(0,s.jsx)(i.li,{children:"This way, we can perform more computations per second, but we have to perform the same computation on a vector of data in parallel."}),"\n",(0,s.jsx)(i.li,{children:"GPUs are general purpose chips. They don't just perform matrix operations, they can really do any kind of computation."}),"\n",(0,s.jsx)(i.li,{children:"GPUs are optimized for taking huge batches of data and performing the same operation over and over very quickly"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"tpu",children:"TPU"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"TPU hardware is comprised of four independent chips."}),"\n",(0,s.jsx)(i.li,{children:"Each chip consists of two compute cores called Tensor Cores."}),"\n",(0,s.jsx)(i.li,{children:"A Tensor Core consists of scalar, vector and matrix units (MXU)."}),"\n",(0,s.jsx)(i.li,{children:"In addition, 8 GB of on-chip memory (HBM) is associated with each Tensor Core."}),"\n",(0,s.jsx)(i.li,{children:"The bulk of the compute horsepower in a Cloud TPU is provided by the MXU."}),"\n",(0,s.jsx)(i.li,{children:"Each MXU is capable of performing 16K multiply-accumulate operations in each cycle."}),"\n",(0,s.jsx)(i.li,{children:"While the MXU's inputs and outputs are 32-bit floating point values, the MXU performs multiplies at reduced bfloat16 precision."}),"\n",(0,s.jsx)(i.li,{children:"Bfloat16 is a 16-bit floating point representation that provides better training and model accuracy than the IEEE half-precision representation. -From a software perspective, each of the 8 cores on a Cloud TPU can execute user computations (XLA ops) independently."}),"\n",(0,s.jsxs)(i.li,{children:["High-bandwidth interconnects allow the chips to communicate directly with each other.- ",(0,s.jsx)(i.img,{alt:"image",src:t(714610).A+"",width:"408",height:"589"})]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"the-systolic-array",children:"The Systolic Array"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"The way to achieve that matrix performance is through a piece of architecture called a systolic array."}),"\n",(0,s.jsx)(i.li,{children:"This is the interesting bit, and it's why a TPU is performant."}),"\n",(0,s.jsx)(i.li,{children:"A systolic array is a kind of hardware algorithm, and it describes a pattern of cells on a chip that computes matrix multiplication."}),"\n",(0,s.jsx)(i.li,{children:'"Systolic" describes how data moves in waves across the chip, like the beating of a human heart.'}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"image",src:t(790991).A+"",width:"648",height:"120"})}),"\n",(0,s.jsx)(i.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsx)(i.p,{children:"CPUs:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Quick prototyping that requires maximum flexibility"}),"\n",(0,s.jsx)(i.li,{children:"Simple models that do not take long to train"}),"\n",(0,s.jsx)(i.li,{children:"Small models with small effective batch sizes"}),"\n",(0,s.jsx)(i.li,{children:"Models that are dominated by custom TensorFlow operations written in C++"}),"\n",(0,s.jsx)(i.li,{children:"Models that are limited by available I/O or the networking bandwidth of the host system"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"GPUs:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Models that are not written in TensorFlow or cannot be written in TensorFlow"}),"\n",(0,s.jsx)(i.li,{children:"Models for which source does not exist or is too onerous to change"}),"\n",(0,s.jsx)(i.li,{children:"Models with a significant number of custom TensorFlow operations that must run at least partially on CPUs"}),"\n",(0,s.jsx)(i.li,{children:"Models with TensorFlow ops that are not available on Cloud TPU (see the list of available TensorFlow ops)"}),"\n",(0,s.jsx)(i.li,{children:"Medium-to-large models with larger effective batch sizes"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"TPUs:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Models dominated by matrix computations"}),"\n",(0,s.jsx)(i.li,{children:"Models with no custom TensorFlow operations inside the main training loop"}),"\n",(0,s.jsx)(i.li,{children:"Models that train for weeks or months"}),"\n",(0,s.jsx)(i.li,{children:"Larger and very large models with very large effective batch sizes"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"cpu-time",children:"CPU Time"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://dzone.com/articles/nice-cpu-time-ni-time-in-top",children:"https://dzone.com/articles/nice-cpu-time-ni-time-in-top"})}),"\n",(0,s.jsx)(i.h2,{id:"links",children:"Links"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://www.youtube.com/watch?v=IPre5287P3I",children:"Chasing Silicon: The Race for GPUs"})})]})}function d(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},733565:(e,i,t)=>{t.d(i,{A:()=>n});const n=t.p+"assets/images/CPU-GPU-TPU-image1-6e4e088af215dcc3f6975ef020f80aef.jpg"},714610:(e,i,t)=>{t.d(i,{A:()=>n});const n=t.p+"assets/images/CPU-GPU-TPU-image2-c2adaef7ae08091ea5a54bf0ca8ab0be.jpg"},790991:(e,i,t)=>{t.d(i,{A:()=>n});const n=t.p+"assets/images/CPU-GPU-TPU-image3-03ae5c97a61da8b7a77ac11bd79e138c.jpg"},28453:(e,i,t)=>{t.d(i,{R:()=>r,x:()=>o});var n=t(296540);const s={},a=n.createContext(s);function r(e){const i=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(a.Provider,{value:i},e.children)}}}]);