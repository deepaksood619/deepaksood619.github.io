"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[69943],{711254:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"ai/llm/langchain","title":"Langchain","description":"Welcome to LangChain - \ud83e\udd9c\ud83d\udd17 LangChain 0.0.180","source":"@site/docs/ai/llm/langchain.md","sourceDirName":"ai/llm","slug":"/ai/llm/langchain","permalink":"/ai/llm/langchain","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/llm/langchain.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1760775012000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Intro","permalink":"/ai/llm/intro"},"next":{"title":"Libraries","permalink":"/ai/llm/libraries"}}');var t=a(474848),r=a(28453);const s={},l="Langchain",o={},h=[{value:"Langchain vs LlamaIndex",id:"langchain-vs-llamaindex",level:4},{value:"LangGraph",id:"langgraph",level:4},{value:"Courses",id:"courses",level:5},{value:"LangSmith",id:"langsmith",level:4},{value:"Links",id:"links",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"langchain",children:"Langchain"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://python.langchain.com/en/latest/index.html",children:"Welcome to LangChain - \ud83e\udd9c\ud83d\udd17 LangChain 0.0.180"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huyenchip.com/2023/04/11/llm-engineering.html",children:"Building LLM applications for production"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.makeuseof.com/langchain-llm-introduction/",children:"Introduction to LangChain LLM: A Beginner\u2019s Guide"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain",children:"How to Build LLM Applications with LangChain | DataCamp"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Langchain Modules",src:a(938157).A+"",width:"999",height:"433"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python -m pip install --upgrade langchain[llm]\npip install chromadb\npip install pypdf\n\npip install chainlit\nchainlit hello\n\nchainlit run document_qa.py\n"})}),"\n",(0,t.jsx)(n.h4,{id:"langchain-vs-llamaindex",children:"Langchain vs LlamaIndex"}),"\n",(0,t.jsx)(n.p,{children:"Both LangChain & LlamaIndex offer distinct approaches to implementing RAG workflows."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"LangChain"})," follows a modular pipeline starting with Document Loaders that handle various file formats, followed by Text Splitters for chunk management, and Embeddings for vector creation."]}),"\n",(0,t.jsx)(n.p,{children:"It then utilizes Vector Stores like SingleStore, FAISS or Chroma for storage, a Retriever for similarity search, and finally, an LLM Chain for response generation. This framework emphasizes composability and flexibility in pipeline construction."}),"\n",(0,t.jsxs)(n.p,{children:["On the other hand, ",(0,t.jsx)(n.strong,{children:"LlamaIndex"})," begins with Data Connectors for multi-source loading, employs a Node Parser for sophisticated document processing, and features diverse Index Construction options including vector, list, and tree structures."]}),"\n",(0,t.jsx)(n.p,{children:"It implements a Storage Context for persistent storage, an advanced Query Engine for retrieval, and Response Synthesis for context integration. LlamaIndex specializes in data indexing and retrieval, offering more sophisticated indexing structures out of the box, while maintaining a focus on ease of use with structured data."}),"\n",(0,t.jsx)(n.p,{children:"The key distinction lies in their approaches: LangChain prioritizes customization and pipeline flexibility, while LlamaIndex emphasizes structured data handling and advanced indexing capabilities, making each framework suitable for different use cases in RAG implementations."}),"\n",(0,t.jsx)(n.p,{children:"No matter what AI framework you pick, I always recommend using a robust data platform like SingleStore that supports not just vector storage but also hybrid search, low latency, fast data ingestion, all data types, AI frameworks integration, and much more."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"image",src:a(107044).A+"",width:"1000",height:"750"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e",children:"A Beginner\u2019s Guide to Building LLM-Powered Applications with LangChain! - DEV Community"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=lOic_3bcxT8",children:"Understanding LlamaIndex in 9 Minutes! - YouTube"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://cloud.llamaindex.ai/",children:"https://cloud.llamaindex.ai/"})}),"\n",(0,t.jsx)(n.h4,{id:"langgraph",children:"LangGraph"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=QblpBsipCwM",children:"Build Agentic Workflows Using LangGraph! - YouTube"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.curotec.com/insights/langchain-vs-langgraph-framework-comparison/",children:"LangChain vs. LangGraph: Which AI Framwork Is Right for You?"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://towardsdatascience.com/ai-agent-workflows-a-complete-guide-on-whether-to-build-with-langgraph-or-langchain-117025509fa0",children:"AI Agent Workflows: A Complete Guide on Whether to Build With LangGraph or LangChain | by Sandi Besen | Towards Data Science"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/neo4j-labs/llm-graph-builder",children:"GitHub - neo4j-labs/llm-graph-builder: Neo4j graph construction from unstructured data using LLMs"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://neo4j.com/labs/genai-ecosystem/llm-graph-builder/",children:"Neo4j LLM Knowledge Graph Builder - Extract Nodes and Relationships from Unstructured Text"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://neo4j.com/blog/graphrag-python-package/",children:"GraphRAG Python Package: Accelerating GenAI With Knowledge Graphs"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_rag.html#retriever-configuration",children:"User Guide: RAG \u2014 neo4j-graphrag-python documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://neo4j.com/labs/genai-ecosystem/genai-stack/",children:"GenAI Stack"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://blog.langchain.com/building-langgraph/",children:"Building LangGraph: Designing an Agent Runtime from first principles"})}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"courses",children:"Courses"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://graphacademy.neo4j.com/",children:"GraphAcademy \u2014 Free, Self-Paced, Hands-on Online Training"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://graphacademy.neo4j.com/courses/modeling-fundamentals/",children:"Graph Data Modeling Fundamentals"})}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"langsmith",children:"LangSmith"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.langchain.com/langsmith",children:"LangSmith"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://medium.com/around-the-prompt/what-is-langsmith-and-why-should-i-care-as-a-developer-e5921deb54b5",children:"What is LangSmith and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://analyticsindiamag.com/ai-features/why-developers-are-quitting-langchain/",children:"Why Developers are Quitting LangChain"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://machinelearningmastery.com/10-python-one-liners-for-calling-llms-from-your-code/",children:"10 Python One-Liners for Calling LLMs from Your Code - MachineLearningMastery.com"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},107044:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/Pasted image 20241118181518-2aefbe281b2f1d9308743143c5ef0874.jpg"},938157:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/Screenshot 2024-04-16 at 7.02.28 PM-e80d354345abda939879a940d9c0eb4b.jpg"},28453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>l});var i=a(296540);const t={},r=i.createContext(t);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);