"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[21253],{352115:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var a=i(785893),n=i(511151);const o={},r="Q-Learning Algorithms",s={id:"ai/move-37/q-learning-algorithms",title:"Q-Learning Algorithms",description:"Q-Learning algorithms are a family of Reinforcement Learning algorithms.",source:"@site/docs/ai/move-37/q-learning-algorithms.md",sourceDirName:"ai/move-37",slug:"/ai/move-37/q-learning-algorithms",permalink:"/ai/move-37/q-learning-algorithms",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/move-37/q-learning-algorithms.md",tags:[],version:"current",lastUpdatedAt:1678191863,formattedLastUpdatedAt:"Mar 7, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Others",permalink:"/ai/move-37/others"},next:{title:"Quizzes",permalink:"/ai/move-37/quizzes"}},l={},c=[{value:"Policy Gradient Method - Attempts to learn functions which directly map an observation to an action",id:"policy-gradient-method---attempts-to-learn-functions-which-directly-map-an-observation-to-an-action",level:2},{value:"Q-Learning - Attempts to learn the value of being in a given state, and taking a specific action there",id:"q-learning---attempts-to-learn-the-value-of-being-in-a-given-state-and-taking-a-specific-action-there",level:2},{value:"Policy - Policy is a simple lookup table: state -&gt; best action",id:"policy---policy-is-a-simple-lookup-table-state---best-action",level:2},{value:"Reward - the reward from our immediate action, plus all discounted future rewards from applying the current policy (Denoted by capital G)",id:"reward---the-reward-from-our-immediate-action-plus-all-discounted-future-rewards-from-applying-the-current-policy-denoted-by-capital-g",level:2}];function d(e){const t={h1:"h1",h2:"h2",img:"img",p:"p",...(0,n.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"q-learning-algorithms",children:"Q-Learning Algorithms"}),"\n",(0,a.jsx)(t.p,{children:"Q-Learning algorithms are a family of Reinforcement Learning algorithms."}),"\n",(0,a.jsx)(t.p,{children:"Unlike policy gradient methods, which attempt to learn functions which directly map an observation to an action, Q-Learning attempts to learn the value of being in a given state, and taking a specific action there."}),"\n",(0,a.jsx)(t.h2,{id:"policy-gradient-method---attempts-to-learn-functions-which-directly-map-an-observation-to-an-action",children:"Policy Gradient Method - Attempts to learn functions which directly map an observation to an action"}),"\n",(0,a.jsx)(t.h2,{id:"q-learning---attempts-to-learn-the-value-of-being-in-a-given-state-and-taking-a-specific-action-there",children:"Q-Learning - Attempts to learn the value of being in a given state, and taking a specific action there"}),"\n",(0,a.jsx)(t.p,{children:"Q - Quality"}),"\n",(0,a.jsx)(t.p,{children:"Q - Long term discounted reward we expect from taking action a in state s"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:i(704627).Z+"",width:"1101",height:"415"})}),"\n",(0,a.jsx)(t.p,{children:"The policy for state s is to choose the actual bias Q value."}),"\n",(0,a.jsx)(t.h2,{id:"policy---policy-is-a-simple-lookup-table-state---best-action",children:"Policy - Policy is a simple lookup table: state -> best action"}),"\n",(0,a.jsx)(t.h2,{id:"reward---the-reward-from-our-immediate-action-plus-all-discounted-future-rewards-from-applying-the-current-policy-denoted-by-capital-g",children:"Reward - the reward from our immediate action, plus all discounted future rewards from applying the current policy (Denoted by capital G)"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"image",src:i(24048).Z+"",width:"1100",height:"580"})})]})}function m(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},704627:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/Q-Learning-Algorithms-image1-3abc6595fe95f21757cb6e30ce56a139.jpg"},24048:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/Q-Learning-Algorithms-image2-af1354d144e7d6ef5661eb3ffb9d7200.jpg"},511151:(e,t,i)=>{i.d(t,{Z:()=>s,a:()=>r});var a=i(667294);const n={},o=a.createContext(n);function r(e){const t=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),a.createElement(o.Provider,{value:t},e.children)}}}]);