"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[96779],{378451:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"cloud/others/gcp-bigquery-big-query","title":"GCP BigQuery / Big Query","description":"BigQuery is a serverless data analytics platform. You don\'t need to provision individual instances or virtual machines to use BigQuery. Instead, BigQuery automatically allocates computing resources as you need them. You can also reserve compute capacity ahead of time in the form of\xa0slots, which represent virtual CPUs","source":"@site/docs/cloud/others/gcp-bigquery-big-query.md","sourceDirName":"cloud/others","slug":"/cloud/others/gcp-bigquery-big-query","permalink":"/cloud/others/gcp-bigquery-big-query","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/cloud/others/gcp-bigquery-big-query.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1736494445000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"GCP Anthos","permalink":"/cloud/others/gcp-anthos"},"next":{"title":"GCP / Google Cloud Platform","permalink":"/cloud/others/gcp-google-cloud-platform"}}');var o=t(474848),s=t(28453);const a={},r="GCP BigQuery / Big Query",l={},c=[{value:"Architecture",id:"architecture",level:2},{value:"Separation of Compute and State",id:"separation-of-compute-and-state",level:2},{value:"Commands",id:"commands",level:2},{value:"Queries",id:"queries",level:2},{value:"Data scanning analysis",id:"data-scanning-analysis",level:3},{value:"SQL",id:"sql",level:3},{value:"Google Cloud Dataflow",id:"google-cloud-dataflow",level:2},{value:"Pricing",id:"pricing",level:2},{value:"Others",id:"others",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"gcp-bigquery--big-query",children:"GCP BigQuery / Big Query"})}),"\n",(0,o.jsxs)(n.p,{children:["BigQuery is a serverless data analytics platform. You don't need to provision individual instances or virtual machines to use BigQuery. Instead, BigQuery automatically allocates computing resources as you need them. You can also reserve compute capacity ahead of time in the form of\xa0",(0,o.jsx)(n.em,{children:"slots"}),", which represent virtual CPUs"]}),"\n",(0,o.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Dremel - The execution engine"}),"\n",(0,o.jsx)(n.li,{children:"Colossus - Distributed Storage"}),"\n",(0,o.jsx)(n.li,{children:"Borg - Compute"}),"\n",(0,o.jsx)(n.li,{children:"Jupiter - The Network"}),"\n",(0,o.jsx)(n.li,{children:"BigQuery - The Service"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"image",src:t(500264).A+"",width:"500",height:"381"})}),"\n",(0,o.jsx)(n.h2,{id:"separation-of-compute-and-state",children:"Separation of Compute and State"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.em,{children:"Separation of compute and state"})," refers to the ability to maintain intermediate state between processing stages in a high-performance component separate from either the compute cluster or storage."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Less state in compute means compute becomes more ephemeral and scalable. It's easier to re-parallelize processing intra-stage and interstage, and easier to recover from a lost node."}),"\n",(0,o.jsx)(n.li,{children:"Processing is more streamlined; processing stages don't conflict within the same compute nodes, resulting in resource contention and bottlenecks."}),"\n",(0,o.jsx)(n.li,{children:"It's easier for the processing engine to re-partition workloads between stages."}),"\n",(0,o.jsx)(n.li,{children:"Your processing engine can take advantage of pipelined execution. In other words, it doesn't have to wait for Stage N to finish before starting Stage N+1."}),"\n",(0,o.jsx)(n.li,{children:"The processing engine can implement dynamic work repartitioning (the ability to re-parallelize work due to slow workers or data skew)."}),"\n",(0,o.jsx)(n.li,{children:"Keeping less state in processing nodes makes workloads more resilient to individual node issues."}),"\n",(0,o.jsx)(n.li,{children:"The service can utilize available resources much more efficiently across compute as well as shuffle."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/blog/products/gcp/separation-of-compute-and-state-in-google-bigquery-and-cloud-dataflow-and-why-it-matters",children:"https://cloud.google.com/blog/products/gcp/separation-of-compute-and-state-in-google-bigquery-and-cloud-dataflow-and-why-it-matters"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/blog/products/gcp/bigquery-under-the-hood",children:"https://cloud.google.com/blog/products/gcp/bigquery-under-the-hood"})}),"\n",(0,o.jsx)(n.h2,{id:"commands",children:"Commands"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from google.cloud import bigquery\nclient = bigquery.Client()\ndataset_ref = client.dataset("hacker_news", project="bigquery-public-data")\ndataset_ref = client.dataset("chicago_crime", project="bigquery-public-data")\ndataset = client.get_dataset(dataset_ref)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"queries",children:"Queries"}),"\n",(0,o.jsx)(n.h3,{id:"data-scanning-analysis",children:"Data scanning analysis"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"-- find how much data is being scanned by month\nSELECT\n  FORMAT_TIMESTAMP('%Y-%m', creation_time) AS month,\n  ROUND(SUM(total_bytes_processed) / POW(2, 30), 2) AS total_gb_scanned\nFROM\n  `region-asia-south1.INFORMATION_SCHEMA.JOBS_BY_PROJECT`\nWHERE\n  state = 'DONE'\n  AND job_type = 'QUERY'\n  AND creation_time BETWEEN TIMESTAMP('2024-01-01') AND CURRENT_TIMESTAMP()\nGROUP BY\n  month\nORDER BY\n  month;\n\n-- find how much data is being scanned by day\nSELECT\n  FORMAT_TIMESTAMP('%Y-%m-%d', creation_time) AS day,\n  ROUND(SUM(total_bytes_processed) / POW(2, 30), 2) AS total_gb_scanned\nFROM\n  `region-REGION_NAME.INFORMATION_SCHEMA.JOBS_BY_PROJECT`\nWHERE\n  state = 'DONE'\n  AND job_type = 'QUERY'\n  AND creation_time BETWEEN TIMESTAMP('2025-01-01') AND CURRENT_TIMESTAMP()\nGROUP BY\n  day\nORDER BY\n  day;\n\n-- find the top queries that scanned the most amount of data\nSELECT\n  query,\n  user_email,\n  COUNT(*) AS query_count,\n  ROUND(SUM(total_bytes_processed) / POW(2, 30), 2) AS total_gb_scanned,\n  ROUND(SUM(total_bytes_processed) / COUNT(*) / POW(2, 30), 2) AS avg_gb_scanned_per_query,\n  ARRAY_AGG(FORMAT_TIMESTAMP('%Y-%m-%d %H:%M:%S', creation_time) ORDER BY creation_time) AS query_run_timestamps\nFROM\n  `region-asia-south1.INFORMATION_SCHEMA.JOBS_BY_PROJECT`\nWHERE\n  state = 'DONE'\n  AND job_type = 'QUERY'\n  AND creation_time BETWEEN TIMESTAMP('2025-01-01') AND CURRENT_TIMESTAMP()\nGROUP BY\n  query,\n  user_email\nORDER BY\n  total_gb_scanned DESC\nLIMIT 10;\n"})}),"\n",(0,o.jsx)(n.h3,{id:"sql",children:"SQL"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"-- standardSQL\nSELECT\n    departure_airport,\n    arrival_airport,\n    COUNT(1) AS num_flights\nFROM\n    `bigquery-samples.airline_ontime_data.flights`\nGROUP BY\n    departure_airport,\n    arrival_airport\nORDER BY\n    num_flights DESC\nLIMIT\n    10\n\n-- standardSQL\nSELECT\n    departure_delay,\n    COUNT(1) AS num_flights,\n    APPROX_QUANTILES(arrival_delay, 5) AS arrival_delay_quantiles\nFROM\n    `bigquery-samples.airline_ontime_data.flights`\nGROUP BY\n    departure_delay\nHAVING\n    num_flights > 100\nORDER BY\n    departure_delay ASC\n"})}),"\n",(0,o.jsx)(n.h2,{id:"google-cloud-dataflow",children:"Google Cloud Dataflow"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Dataflow is a unified programming model and a managed service for developing and executing a wide range of data processing patterns including ETL, batch computation, and continuous computation."}),"\n",(0,o.jsx)(n.li,{children:"The Dataflow model combines batch and stream processing so developers don't have to make tradeoffs between correctness, cost, and processing time."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"pricing",children:"Pricing"}),"\n",(0,o.jsx)(n.p,{children:"Queries (on-demand) - $6.25 per TiB - The first 1 TiB per month is free."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/pricing",children:"Pricing \xa0|\xa0 BigQuery: Cloud Data Warehouse \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/docs/slots",children:"Understand slots \xa0|\xa0 BigQuery \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"A BigQuery slot is a virtual compute unit used by BigQuery to execute SQL queries or other job types. During the execution of a query, BigQuery automatically determines how many slots are used by the query. The number of slots used depends on the amount of data being processed, the complexity of the query, and the number of slots available."}),"\n",(0,o.jsx)(n.li,{children:"Fair scheduling in BigQuery"}),"\n",(0,o.jsx)(n.li,{children:"Idle slots"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/quotas",children:"Quotas and limits \xa0|\xa0 BigQuery \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/docs/best-practices-costs",children:"Estimate and control costs \xa0|\xa0 BigQuery \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/pricing",children:"Pricing \xa0|\xa0 BigQuery: Cloud Data Warehouse \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/bigquery/docs/best-practices-costs",children:"Estimate and control costs \xa0|\xa0 BigQuery \xa0|\xa0 Google Cloud"})}),"\n",(0,o.jsx)(n.h2,{id:"others",children:"Others"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"BigQuery"}),"\xa0should not be used if you expect OLTP behavior or performance."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/02_generalization/repeatable_splitting.ipynb",children:"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/02_generalization/repeatable_splitting.ipynb"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/GoogleCloudPlatform/training-data-analyst",children:"https://github.com/GoogleCloudPlatform/training-data-analyst"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://stackoverflow.com/questions/69463609/speed-of-inserting-to-bigquery-should-this-be-batched-in-background",children:"php - Speed of inserting to BigQuery - should this be batched in background? - Stack Overflow"})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},500264:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/Cloud-Others-BigQuery-Big-Query-image1-66a1ac76371e51cdf315f82f1fab065e.jpg"},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var i=t(296540);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);