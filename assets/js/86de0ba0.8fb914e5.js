"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[52774],{740177:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var s=n(785893),i=n(511151);const r={},d="NLTK",o={id:"ai/nlp/nltk",title:"NLTK",description:"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing.",source:"@site/docs/ai/nlp/nltk.md",sourceDirName:"ai/nlp",slug:"/ai/nlp/nltk",permalink:"/ai/nlp/nltk",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/nlp/nltk.md",tags:[],version:"current",lastUpdatedAt:1701793554,formattedLastUpdatedAt:"Dec 5, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"NLP Concepts",permalink:"/ai/nlp/nlp-concepts"},next:{title:"Word Embedding to Transformers",permalink:"/ai/nlp/word-embedding-to-transformers"}},c={},l=[{value:"Commands",id:"commands",level:2},{value:"NLTK&#39;s Frequency Distributionss",id:"nltks-frequency-distributionss",level:3},{value:"Corpus",id:"corpus",level:3},{value:"Others",id:"others",level:2},{value:"python - indian-namematch 1.3.0",id:"python---indian-namematch-130",level:3}];function a(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"nltk",children:"NLTK"}),"\n",(0,s.jsx)(t.p,{children:"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing."}),"\n",(0,s.jsxs)(t.p,{children:["NLTK supports classification, tokenization, stemming ",(0,s.jsx)(t.strong,{children:"(lemmatization better than stemming)"}),", tagging, parsing, and semantic reasoning functionalities."]}),"\n",(0,s.jsx)(t.p,{children:"Library highlights"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Lexical_analysis",children:"Lexical analysis"}),": Word and text tokenizer"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/N-gram",children:"n-gram"})," and collocations"]}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Part-of-speech_tagging",children:"Part-of-speech tagger"})}),"\n",(0,s.jsxs)(t.li,{children:["Tree model and Text",(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Chunking_(computational_linguistics)",children:"chunker"})," for capturing"]}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Named-entity_recognition",children:"Named-entity recognition"})}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"commands",children:"Commands"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'import nltk\nnltk.download()\n\nfrom nltk.book import *\ntext1\nlen(text6)\ntexts()\nsents()\n    The sents() function divides the text up into its sentences, where each sentence is a list of words\n\ntext1.concordance("monstrous") #A concordance view shows us every occurrence of a given word, together with some context\ntext2.similar("monstrous")\ntext2.common_contexts(["monstrous", "very"])\ntext4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])\ntext6.dispersion_plot(["Arthur", "Holy", "Grail"])\ntext6.generate()\ntext6.count("Grail")\ntext6.count("grail")\nfdist1 = FreqDist(text1)\nfdist1.most_common(50)\nfdist1.plot(50, cumulative=True)\n\ncfd = nltk.ConditionalFreqDist(\n...           (genre, word)\n...           for genre in brown.categories()\n...           for word in brown.words(categories=genre))\ngenres = [\'news\', \'religion\', \'hobbies\', \'science_fiction\', \'romance\', \'humor\']\nmodals = [\'can\', \'could\', \'may\', \'might\', \'must\', \'will\']\ncfd.tabulate(conditions=genres, samples=modals)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"nltks-frequency-distributionss",children:"NLTK's Frequency Distributionss"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Example"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Description"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist = FreqDist(samples)"}),(0,s.jsx)(t.td,{children:"create a frequency distribution containing the given samples"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist[sample] += 1"}),(0,s.jsx)(t.td,{children:"increment the count for this sample"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist['monstrous']"}),(0,s.jsx)(t.td,{children:"count of the number of times a given sample occurred"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.freq('monstrous')"}),(0,s.jsx)(t.td,{children:"frequency of a given sample"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.N()"}),(0,s.jsx)(t.td,{children:"total number of samples"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.most_common(n)"}),(0,s.jsx)(t.td,{children:"the n most common samples and their frequencies"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"for sample in fdist:"}),(0,s.jsx)(t.td,{children:"iterate over the samples"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.max()"}),(0,s.jsx)(t.td,{children:"sample with the greatest count"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.tabulate()"}),(0,s.jsx)(t.td,{children:"tabulate the frequency distribution"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.plot()"}),(0,s.jsx)(t.td,{children:"graphical plot of the frequency distribution"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist.plot(cumulative=True)"}),(0,s.jsx)(t.td,{children:"cumulative plot of the frequency distribution"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist1"}),(0,s.jsx)(t.td,{children:"= fdist2"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fdist1 < fdist2"}),(0,s.jsx)(t.td,{children:"test if samples in fdist1 occur less frequently than in fdist2"})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"corpus",children:"Corpus"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"nltk.chat.chatbots()\nnltk.corpus.gutenberg.fileids()\nemma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\nlen(gutenberg.raw('austen-emma.txt'))\n    The raw() function gives us the contents of the file without any linguistic processing.\n\nfrom nltk.corpus import webtext\nwebtext.fileids()\n\nfrom nltk.corpus import nps_chat\nnps_chat.posts('10-19-20s_706posts.xml')\n\nThe Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics.\nfirst million-word electronic corpus of English\nfrom nltk.corpus import brown\nbrown.categories()\nbrown.words(categories='news')\nbrown.words(fileids=['cg22'])\nbrown.sents(categories=['news', 'editorial', 'reviews'])\n\nfrom nltk.corpus import reuters\nreuters.fileids()\nreuters.categories()\nreuters.categories(['training/9865', 'training/9880'])\n\nfrom nltk.corpus import inaugural\ninaugural.fileids()\ncfd = nltk.ConditionalFreqDist(\n...           (target, fileid[:4])\n...           for fileid in inaugural.fileids()\n...           for w in inaugural.words(fileid)\n...           for target in ['america', 'citizen']\n...           if w.lower().startswith(target))\ncfd.plot()\nnltk.corpus.indian.words('hindi.pos')\nnltk.corpus.cess_esp.words()\nnltk.corpus.floresta.words()\nnltk.corpus.udhr.fileids() #univeral declaration of human rights in 300 languages\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"image",src:n(360383).Z+"",width:"1100",height:"245"})}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Example"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Description"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fileids()"}),(0,s.jsx)(t.td,{children:"the files of the corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"fileids([categories])"}),(0,s.jsx)(t.td,{children:"the files of the corpus corresponding to these categories"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"categories()"}),(0,s.jsx)(t.td,{children:"the categories of the corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"categories([fileids])"}),(0,s.jsx)(t.td,{children:"the categories of the corpus corresponding to these files"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"raw()"}),(0,s.jsx)(t.td,{children:"the raw content of the corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"raw(fileids=[f1,f2,f3])"}),(0,s.jsx)(t.td,{children:"the raw content of the specified files"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"raw(categories=[c1,c2])"}),(0,s.jsx)(t.td,{children:"the raw content of the specified categories"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"words()"}),(0,s.jsx)(t.td,{children:"the words of the whole corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"words(fileids=[f1,f2,f3])"}),(0,s.jsx)(t.td,{children:"the words of the specified fileids"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"words(categories=[c1,c2])"}),(0,s.jsx)(t.td,{children:"the words of the specified categories"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"sents()"}),(0,s.jsx)(t.td,{children:"the sentences of the whole corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"sents(fileids=[f1,f2,f3])"}),(0,s.jsx)(t.td,{children:"the sentences of the specified fileids"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"sents(categories=[c1,c2])"}),(0,s.jsx)(t.td,{children:"the sentences of the specified categories"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"abspath(fileid)"}),(0,s.jsx)(t.td,{children:"the location of the given file on disk"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"encoding(fileid)"}),(0,s.jsx)(t.td,{children:"the encoding of the file (if known)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"open(fileid)"}),(0,s.jsx)(t.td,{children:"open a stream for reading the given corpus file"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"root"}),(0,s.jsx)(t.td,{children:"if the path to the root of locally installed corpus"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"readme()"}),(0,s.jsx)(t.td,{children:"if the path to the root of locally installed corpus the contents of the README file of the corpus"})]})]})]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://github.com/nltk/nltk",children:"https://github.com/nltk/nltk"})}),"\n",(0,s.jsx)(t.h2,{id:"others",children:"Others"}),"\n",(0,s.jsx)(t.h3,{id:"python---indian-namematch-130",children:"python - indian-namematch 1.3.0"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://pypi.org/project/indian-namematch",children:"https://pypi.org/project/indian-namematch"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e",children:"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e"})})]})}function h(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},360383:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/NLP_NLTK-image1-4b5a5ce00ba5805513a93673231690cd.jpg"},511151:(e,t,n)=>{n.d(t,{Z:()=>o,a:()=>d});var s=n(667294);const i={},r=s.createContext(i);function d(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:d(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);