"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[75036],{459568:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"data-warehouses/databricks/04-workflow","title":"Workflow","description":"Create, run, and manage Databricks Jobs | Databricks on AWS","source":"@site/docs/data-warehouses/databricks/04-workflow.md","sourceDirName":"data-warehouses/databricks","slug":"/data-warehouses/databricks/04-workflow","permalink":"/data-warehouses/databricks/04-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/data-warehouses/databricks/04-workflow.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1749575438000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Optimizations","permalink":"/data-warehouses/databricks/03-optimizations"},"next":{"title":"Medallion Architecture","permalink":"/data-warehouses/databricks/10-medallion-architecture"}}');var s=n(474848),r=n(28453);const o={},i="Workflow",l={},c=[{value:"Others",id:"others",level:2},{value:"DBX",id:"dbx",level:3},{value:"pyjaws",id:"pyjaws",level:3}];function d(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.header,{children:(0,s.jsx)(a.h1,{id:"workflow",children:"Workflow"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/workflows/jobs/jobs.html",children:"Create, run, and manage Databricks Jobs | Databricks on AWS"})}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-bash",children:"Type - Notebook\nSource - Github\nGit - https://github.com/cakedefi/cake-data-eng\nGit reference - main\nPath - silver_layer/product_revenue_bifurcation\nCluster - PROD Data Team Cluster\n-> Save\nAdd Schedules & Triggers\nAdd Notification\n"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://community.databricks.com/s/question/0D58Y00009dAEFCSA4/schedule-job-to-run-sequentially-after-another-job",children:"Question Detail"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/workflows/jobs/how-to/use-airflow-with-jobs.html",children:"Orchestrate Databricks jobs with Apache Airflow | Databricks on AWS"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/workflows/jobs/file-arrival-triggers.html",children:"Trigger jobs when new files arrive | Databricks on AWS"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/notebooks/notebook-workflows.html",children:"Run a Databricks notebook from another notebook | Databricks on AWS"})}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'dbutils.notebook.run("notebook-name", 60, {"argument": "data", "argument2": "data2", ...})\n\ndbutils.notebook.run(i[\'nb_path\'], i[\'timeout\'], i[\'args\']).split(\';\')\n'})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/notebooks/share-code.html",children:"Share code between Databricks notebooks | Databricks on AWS"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.databricks.com/workflows/jobs/share-task-context.html",children:"Share information between tasks in a Databricks job | Databricks on AWS"})}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'dbutils.jobs.taskValues.set(key = \'name\', value = \'Some User\')\ndbutils.jobs.taskValues.set(key = "age", value = 30)\n\ndbutils.jobs.taskValues.get(taskKey = "Get_user_data", key = "age", default = 42, debugValue = 0)\ndbutils.jobs.taskValues.get(taskKey = "Get_user_data", key = "name", default = "Jane Doe")\n'})}),"\n",(0,s.jsx)(a.h2,{id:"others",children:"Others"}),"\n",(0,s.jsx)(a.h3,{id:"dbx",children:"DBX"}),"\n",(0,s.jsxs)(a.p,{children:["Databricks CLI eXtensions - aka ",(0,s.jsx)(a.code,{children:"dbx"})," is a CLI tool for development and advanced Databricks workflows management."]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://github.com/databrickslabs/dbx",children:"GitHub - databrickslabs/dbx: \ud83e\uddf1 Databricks CLI eXtensions - aka dbx is a CLI tool for development and advanced Databricks workflows management."})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://dbx.readthedocs.io/en/latest/",children:"dbx | github"})}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-bash",children:'pip install dbx\n\ndbx init -p "cicd_tool=GitHub Actions" -p "cloud=AWS" -p "project_name=charming-aurora" -p "profile=DEFAULT" --no-input\n\ncd charming-aurora\n\npip install -e ".[local,test]"\n\npytest tests/unit --cov\n'})}),"\n",(0,s.jsx)(a.h3,{id:"pyjaws",children:"pyjaws"}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.strong,{children:"PyJaws"})," enables declaring ",(0,s.jsx)(a.a,{href:"https://docs.databricks.com/workflows/index.html",children:"Databricks Jobs and Workflows"})," as Python code, allowing for:"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Code Linting"}),"\n",(0,s.jsx)(a.li,{children:"Formatting"}),"\n",(0,s.jsx)(a.li,{children:"Parameter Validation"}),"\n",(0,s.jsx)(a.li,{children:"Modularity and reusability"}),"\n"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-bash",children:'pip install pyjaws\n\nexport DATABRICKS_HOST="https://dbc-1ae8e7ed-1d80.cloud.databricks.com"\nexport DATABRICKS_TOKEN="<token>"\necho $DATABRICKS_HOST\necho $DATABRICKS_TOKEN\n\npyjaws create <folder_name>\npyjaws create .\n\ndisplay(simple_workflow)\n'})}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'from pyjaws.api.base import (\n    Cluster,\n    Runtime,\n    Workflow\n)\nfrom pyjaws.api.tasks import PythonWheelTask, NotebookTask\n\ncluster = Cluster(\n    job_cluster_key = "ai_cluster",\n    spark_version = Runtime.DBR_13_ML,\n    num_workers = 2,\n    node_type_id = "r3.xlarge",\n    cluster_log_conf = {\n        "dbfs": {\n            "destination": "dbfs:/home/cluster_log"\n        }\n    }\n)\n\n# Create a Task object.\ningest_task = PythonWheelTask(\n    key = "ingest",\n    cluster = cluster,\n    entrypoint = "iot",\n    task_name = "ingest",\n    parameters = [\n        f"my_parameter_value",\n        "--output-table", "my_table"\n    ],\n    package_name = \'abc\'\n)\n\ntransform_task = PythonWheelTask(\n    key = "transform",\n    cluster = cluster,\n    entrypoint = "iot",\n    task_name = "ingest",\n    dependencies = [ingest_task],\n    parameters = [\n        f"my_parameter_value2",\n        "--input-table", "my_table"\n        "--output-table", "output_table"\n    ],\n    package_name = \'abc\'\n)\n\nnext_task = NotebookTask(\n    key = "next",\n    cluster = cluster,\n    entrypoint = "iot",\n    task_name = "next",\n    dependencies = [ingest_task],\n    source = "GIT",\n    notebook_path = "/test_repo_pipeline",\n    parameters = [\n        f"my_parameter_value2",\n        "--input-table", "my_table"\n        "--output-table", "output_table"\n    ],\n    package_name = \'abc\'\n)\n\n\n# Create a Workflow object to define dependencies\n# between previously defined tasks.\n\nworkflow = Workflow(\n    name = "my_workflow",\n    tasks = [ingest_task, transform_task, next_task]\n'})}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["Make sure to add the package_name, otherwise getting ",(0,s.jsx)(a.code,{children:"pydantic.error_wrappers.ValidationError"})]}),"\n",(0,s.jsx)(a.li,{children:"Change node_type_id since example node_type_id not present"}),"\n",(0,s.jsx)(a.li,{children:"Add NotebookTask for running notebooks"}),"\n",(0,s.jsx)(a.li,{children:"Add source to GIT"}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://github.com/rafaelpierre/pyjaws",children:"GitHub - rafaelpierre/pyjaws: PyJaws: A Pythonic Way to Define Databricks Jobs and Workflows"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://github.com/rafaelpierre/pyjaws/blob/main/pyjaws/pyjaws/api/tasks.py",children:"pyjaws/pyjaws/pyjaws/api/tasks.py at main \xb7 rafaelpierre/pyjaws \xb7 GitHub"})})]})}function h(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,a,n)=>{n.d(a,{R:()=>o,x:()=>i});var t=n(296540);const s={},r=t.createContext(s);function o(e){const a=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:a},e.children)}}}]);