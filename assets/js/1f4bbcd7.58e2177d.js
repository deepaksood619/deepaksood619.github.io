"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[90802],{25034:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"ai/libraries/jax","title":"JAX","description":"- J - Just-in-time","source":"@site/docs/ai/libraries/jax.md","sourceDirName":"ai/libraries","slug":"/ai/libraries/jax","permalink":"/ai/libraries/jax","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/libraries/jax.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1726756705000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Distributed Training","permalink":"/ai/libraries/distributed-training"},"next":{"title":"Keras","permalink":"/ai/libraries/keras"}}');var r=n(474848),a=n(28453);const o={},s="JAX",l={},c=[{value:"Links",id:"links",level:2}];function d(e){const i={a:"a",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"jax",children:"JAX"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"J - Just-in-time"}),"\n",(0,r.jsx)(i.li,{children:"A - Autograd"}),"\n",(0,r.jsx)(i.li,{children:"X - XLA - Accelerated Linear Algebra"}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"JAX is a Python library for accelerator-oriented array computation and program transformation, designed for high-performance numerical computing and large-scale machine learning."}),"\n",(0,r.jsx)(i.p,{children:"JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research."}),"\n",(0,r.jsxs)(i.p,{children:["JAX a library for array-oriented numerical computation (",(0,r.jsx)(i.em,{children:"\xe0 la"}),"\xa0",(0,r.jsx)(i.a,{href:"https://numpy.org/",children:"NumPy"}),"), with automatic differentiation and JIT compilation to enable high-performance machine learning research."]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"JAX provides a unified NumPy-like interface to computations that run on CPU, GPU, or TPU, in local or distributed settings."}),"\n",(0,r.jsxs)(i.li,{children:["JAX features built-in Just-In-Time (JIT) compilation via\xa0",(0,r.jsx)(i.a,{href:"https://github.com/openxla",children:"Open XLA"}),", an open-source machine learning compiler ecosystem."]}),"\n",(0,r.jsx)(i.li,{children:"JAX functions support efficient evaluation of gradients via its automatic differentiation transformations."}),"\n",(0,r.jsx)(i.li,{children:"JAX functions can be automatically vectorized to efficiently map them over arrays representing batches of inputs."}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"links",children:"Links"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://github.com/google/jax",children:"GitHub - google/jax: Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://jax.readthedocs.io/en/latest/notebooks/quickstart.html",children:"JAX Quickstart \u2014 JAX documentation"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://youtu.be/_0D5lXDjNpw",children:"JAX in 100 Seconds"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Google_JAX",children:"Google JAX - Wikipedia"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://www.kaggle.com/learn-guide/jax",children:"JAX Guide | Kaggle"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb",children:"neural-network-and-data-loading.ipynb - Colab"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.a,{href:"https://www.youtube.com/watch?v=uySOfXq-II0",children:"What is JAX? - YouTube"})}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>s});var t=n(296540);const r={},a=t.createContext(r);function o(e){const i=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:i},e.children)}}}]);