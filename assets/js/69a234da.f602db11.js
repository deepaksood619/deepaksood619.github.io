"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[12689],{674381:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"courses/course-launching-into-ml","title":"Course - Launching into ML","description":"Objectives","source":"@site/docs/courses/course-launching-into-ml.md","sourceDirName":"courses","slug":"/courses/course-launching-into-ml","permalink":"/courses/course-launching-into-ml","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/courses/course-launching-into-ml.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1707138374000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Course - Intro to TensorFlow","permalink":"/courses/course-intro-to-tensorflow"},"next":{"title":"Exponential Smoothing","permalink":"/courses/course-time-series-analysis/exponential-smoothing"}}');var r=i(474848),l=i(28453);const o={},t="Course - Launching into ML",a={},c=[{value:"Objectives",id:"objectives",level:2},{value:"Prediction Problem",id:"prediction-problem",level:2},{value:"Practical ML",id:"practical-ml",level:2},{value:"Optimization",id:"optimization",level:2},{value:"Generalization and Sampling",id:"generalization-and-sampling",level:2}];function d(n){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"course---launching-into-ml",children:"Course - Launching into ML"})}),"\n",(0,r.jsx)(e.h2,{id:"objectives",children:"Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Identify why deep learning is currently popular"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Optimize and evaluate models using loss functions and performance metrics"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Mitigate common problems that arise in Machine Learning"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Lack of generalization"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Create repeatable training, evaluation and test datasets"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Optimization - Set up a supervised learning problem and find solution using gradient descent"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Performance metrics and how to choose between different models"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Intuitive understanding of neural networks"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Tensor flow playground"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Generalization and sampling"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"prediction-problem",children:"Prediction Problem"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Supervised Learning"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Classification problem"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Classification models usually use cross entropy as their loss function (the penalty for cross entropy is almost linear and the predicted probability is close to actual label, but as it gets further away it becomes exponential, when it gets close to predicting the opposite class of the label)"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Regression problem"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Regression models usually use mean squared error as their loss function (Quadratic penalty for mean squared error, so it is essentially trying to minimize the euclidean distance between the actual label and the predicted label)"}),"\n",(0,r.jsx)(e.p,{children:"Description Problem"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Unsupervised learning"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.a,{href:"https://www.coursera.org/learn/launching-machine-learning",children:"https://www.coursera.org/learn/launching-machine-learning"})}),"\n",(0,r.jsx)(e.h2,{id:"practical-ml",children:"Practical ML"}),"\n",(0,r.jsx)(e.p,{children:"In this module, we will introduce some of the main types of machine learning and review the history of ML leading up to the state of the art so that you can accelerate your growth as an ML practitioner."}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsxs)(e.a,{href:"https://www.coursera.org/learn/launching-machine-learning/lecture/j4Rbd/introduction",children:["Video",":Introduction"]})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Supervised"," Learning"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Regression"," and Classification"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Linear Regression"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Perceptron"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Neural Networks"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Decision Trees"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Kernel Methods"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Random Forests"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Short"," History of ML: Modern Neural Networks"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Discussion Prompt",":Modern"," Neural Networks"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"optimization",children:"Optimization"}),"\n",(0,r.jsx)(e.p,{children:"In this module we will walk you through how to optimize your ML models."}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsxs)(e.a,{href:"https://www.coursera.org/learn/launching-machine-learning/lecture/ebCZS/introduction",children:["Video",":Introduction"]})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Defining"," ML Models"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Introducing"," the Natality Dataset"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Introducing"," Loss Functions"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Gradient"," Descent"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Troubleshooting"," a Loss Curve"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":ML"," Model Pitfalls"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Video:Lab: Introducing the TensorFlow Playground"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Video:Lab: TensorFlow Playground - Advanced"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Video:Lab: Practicing with Neural Networks"}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Loss"," Curve Troubleshooting"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Video",":Performance"," Metrics"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"generalization-and-sampling",children:"Generalization and Sampling"}),"\n",(0,r.jsx)(e.p,{children:"Now it's time to answer a rather weird question: when is the most accurate ML model not the right one to pick? As we hinted at in the last module on Optimization -- simply because a model has a loss metric of 0 for your training dataset does not mean it will perform well on new data in the real world."}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.a,{href:"https://github.com/GoogleCloudPlatform/training-data-analyst",children:"https://github.com/GoogleCloudPlatform/training-data-analyst"})})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},28453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>t});var s=i(296540);const r={},l=s.createContext(r);function o(n){const e=s.useContext(l);return s.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);