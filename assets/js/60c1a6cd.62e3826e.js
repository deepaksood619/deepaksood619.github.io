"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[26253],{826680:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"cloud/aws/ai/amazon-transcribe","title":"Amazon Transcribe","description":"Amazon Transcribe is an automatic speech recognition (ASR) service that makes it easy for you to add speech-to-text capabilities to your applications. Starting today, when transcribing audio streams, you can instruct Amazon Transcribe to automatically mask, remove, or tag specific terms in the transcription results based on a vocabulary that you specify. For example, you can use a vocabulary filter to automatically remove profane words from the transcription results for content moderation or generating family-friendly captions. You can create a vocabulary filter once and use it when processing multiple audio streams. You can also create multiple vocabulary filters and choose which one should be used for a particular audio stream. With this launch, vocabulary filtering is now available for both Amazon Transcribe\'s batch and streaming transcription APIs.","source":"@site/docs/cloud/aws/ai/amazon-transcribe.md","sourceDirName":"cloud/aws/ai","slug":"/cloud/aws/ai/amazon-transcribe","permalink":"/cloud/aws/ai/amazon-transcribe","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/cloud/aws/ai/amazon-transcribe.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1761613175000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Amazon Rekognition","permalink":"/cloud/aws/ai/amazon-rekognition"},"next":{"title":"Bedrock","permalink":"/cloud/aws/ai/bedrock"}}');var i=a(474848),s=a(28453);const r={},o="Amazon Transcribe",c={},l=[{value:"Amazon Transcribe Call Analytics",id:"amazon-transcribe-call-analytics",level:2},{value:"Features",id:"features",level:3},{value:"Quality assurance",id:"quality-assurance",level:3},{value:"How to use",id:"how-to-use",level:3},{value:"Post-call insights / Analytics",id:"post-call-insights--analytics",level:2},{value:"Call characteristics",id:"call-characteristics",level:3},{value:"Generative call summarization",id:"generative-call-summarization",level:3},{value:"Custom categorization",id:"custom-categorization",level:3},{value:"Sensitive data redaction",id:"sensitive-data-redaction",level:3},{value:"Sentiment analysis",id:"sentiment-analysis",level:3},{value:"Links",id:"links",level:3},{value:"Toxic Speech Detection",id:"toxic-speech-detection",level:2},{value:"How it works",id:"how-it-works",level:3},{value:"Benefits",id:"benefits",level:3},{value:"Amazon Transcribe",id:"amazon-transcribe-1",level:3}];function h(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"amazon-transcribe",children:"Amazon Transcribe"})}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://aws.amazon.com/transcribe/",children:"Amazon Transcribe"})," is an automatic speech recognition (ASR) service that makes it easy for you to add speech-to-text capabilities to your applications. Starting today, when transcribing audio streams, you can instruct Amazon Transcribe to automatically mask, remove, or tag specific terms in the transcription results based on a vocabulary that you specify. For example, you can use a vocabulary filter to automatically remove profane words from the transcription results for content moderation or generating family-friendly captions. You can create a vocabulary filter once and use it when processing multiple audio streams. You can also create multiple vocabulary filters and choose which one should be used for a particular audio stream. With this launch, vocabulary filtering is now available for both Amazon Transcribe's batch and streaming transcription APIs."]}),"\n",(0,i.jsx)(t.p,{children:"You can use streaming transcription to efficiently and accurately generate transcripts for diverse use cases, such as transcribing calls for contact centers, automatically generating captions for live media broadcasts, and capturing meeting notes for business productivity."}),"\n",(0,i.jsxs)(t.p,{children:["Vocabulary filtering is available for streaming transcription at no additional cost in all the ",(0,i.jsx)(t.a,{href:"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/",children:"AWS regions"})," where Amazon Transcribe streaming service is available. To learn more, visit the Amazon Transcribe ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/filter-unwanted-words.html",children:"documentation page."})]}),"\n",(0,i.jsx)(t.h2,{id:"amazon-transcribe-call-analytics",children:"Amazon Transcribe Call Analytics"}),"\n",(0,i.jsx)(t.p,{children:"Amazon Transcribe Call Analytics is a tool that can transcribe call audio, analyze sentiment, and perform quality assurance on customer service and sales calls. It uses machine learning and speech-to-text models to help improve customer experience and agent productivity."}),"\n",(0,i.jsx)(t.h3,{id:"features",children:"Features"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Call transcription"}),": Transcribes audio into text, including multi-speaker audio"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Sentiment analysis"}),": Analyzes the sentiment of the customer or agent"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Call categorization"}),": Classifies calls based on criteria like sentiment, phrases, or interruptions"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Call summarization"}),": Summarizes a call to capture key information"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Sensitive information redaction"}),": Detects and removes sensitive information like names, addresses, and credit card information"]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"quality-assurance",children:"Quality assurance"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Quality training programs"}),": Uses insights from call analytics to create targeted training programs"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Adherence to standards"}),": Helps ensure that agents adhere to standards"]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"how-to-use",children:"How to use"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You can use the AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS SDK"}),"\n",(0,i.jsx)(t.li,{children:"You can create a Lambda function and IAM policy"}),"\n",(0,i.jsx)(t.li,{children:"You can create an Amazon S3 bucket to store the audio file"}),"\n",(0,i.jsx)(t.li,{children:"You can use the Transcribe API to generate a transcript"}),"\n",(0,i.jsx)(t.li,{children:"You can use the Amazon Comprehend API to analyze the transcription text"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://aws.amazon.com/transcribe/call-analytics/",children:"Amazon Transcribe Call Analytics"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://aws.amazon.com/transcribe/pricing/",children:"Amazon Transcribe Pricing \u2013 Amazon Web Services (AWS)"})}),"\n",(0,i.jsx)(t.h2,{id:"post-call-insights--analytics",children:"Post-call insights / Analytics"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://github.com/aws-samples/amazon-transcribe-post-call-analytics",children:"GitHub - aws-samples/amazon-transcribe-post-call-analytics"})}),"\n",(0,i.jsx)(t.p,{children:"Call Analytics provides post-call analyses, which are useful for monitoring customer service trends."}),"\n",(0,i.jsx)(t.h3,{id:"call-characteristics",children:"Call characteristics"}),"\n",(0,i.jsx)(t.p,{children:"Include talk time, non-talk time, speaker loudness, interruptions, talk speed, issues, outcomes, and action items"}),"\n",(0,i.jsx)(t.p,{children:"The call characteristics feature measures the quality of agent-customer interactions using these criteria:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Interruption"}),": Measures if and when one participant cuts off the other participant mid-sentence. Frequent interruptions may be associated with rudeness or anger, and could correlate to negative sentiment for one or both participants."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Loudness"}),": Measures the volume at which each participant is speaking. Use this metric to see if the caller or the agent is speaking loudly or yelling, which is often indicative of being upset. This metric is represented as a normalized value (speech level per second of speech in a given segment) on a scale from 0 to 100, where a higher value indicates a louder voice."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Non-talk time"}),": Measures periods of time that do not contain speech. Use this metric to see if there are long periods of silence, such as an agent keeping a customer on hold for an excessive amount of time."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Talk speed"}),": Measures the speed at which both participants are speaking. Comprehension can be affected if one participant speaks too quickly. This metric is measured in words per minute."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Talk time"}),": Measures the amount of time (in milliseconds) each participant spoke during the call. Use this metric to help identify if one participant is dominating the call or if the dialogue is balanced."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Issues, Outcomes, and Action Items"}),": Identifies issues, outcomes and action items from the call transcript."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Here's an ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html#tca-output-characteristics-batch",children:"output example"}),"."]}),"\n",(0,i.jsx)(t.h3,{id:"generative-call-summarization",children:"Generative call summarization"}),"\n",(0,i.jsx)(t.p,{children:"Creates a concise summary of the entire call"}),"\n",(0,i.jsx)(t.p,{children:"Generative call summarization creates a concise summary of the entire call, capturing key components such as reason for the call, steps taken to resolve issue, and next steps."}),"\n",(0,i.jsx)(t.p,{children:"Using generative call summarization, you can:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Reduce the need for manual note-taking during and after calls."}),"\n",(0,i.jsx)(t.li,{children:"Improve agent efficiency as they can spend more time talking to callers waiting in queue rather than engaging in after-call work."}),"\n",(0,i.jsx)(t.li,{children:"Speed up supervisor reviews as call summaries are much quicker to review than entire transcripts."}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["To use generative call summarization with a post-call analytics job, see ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-enable-summarization.html",children:"Enabling generative call summarization"}),". For example output, see ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html#tca-output-summarization-batch",children:"Generative call summarization output example"}),". Generative call summarization is priced separately (please refer to ",(0,i.jsx)(t.a,{href:"https://aws.amazon.com/transcribe/pricing",children:"pricing page"}),")."]}),"\n",(0,i.jsx)(t.h3,{id:"custom-categorization",children:"Custom categorization"}),"\n",(0,i.jsx)(t.p,{children:"Rules that you can use to hone in on specific keywords and criteria"}),"\n",(0,i.jsx)(t.p,{children:"Use call categorization to flag keywords, phrases, sentiment, or actions within a call. Our categorization options can help you triage escalations, such as negative-sentiment calls with many interruptions, or organize calls into specific categories, such as company departments."}),"\n",(0,i.jsx)(t.p,{children:"The criteria you can add to a category include:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Non-talk time"}),": Periods of time when neither the customer nor the agent is talking."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Interruptions"}),": When the customer or the agent is interrupting the other person."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Customer or agent sentiment"}),": How the customer or the agent is feeling during a specified time period. If at least 50 percent of the conversation turns (the back-and-forth between two speakers) in a specified time period match the specified sentiment, Amazon Transcribe considers the sentiment a match."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Keywords or phrases"}),': Matches part of the transcription based on an exact phrase. For example, if you set a filter for the phrase "I want to speak to the manager", Amazon Transcribe filters for that ',(0,i.jsx)(t.em,{children:"exact"})," phrase."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"You can also flag the inverse of the previous criteria (talk time, lack of interruptions, a sentiment not being present, and the lack of a specific phrase)."}),"\n",(0,i.jsxs)(t.p,{children:["Here's an ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html#tca-output-categorization-batch",children:"output example"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["For more information on categories or to learn how to create a new category, see ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-categories-batch.html",children:"Creating categories for post-call transcriptions"}),"."]}),"\n",(0,i.jsx)(t.h3,{id:"sensitive-data-redaction",children:"Sensitive data redaction"}),"\n",(0,i.jsx)(t.p,{children:"Text transcript and your audio file"}),"\n",(0,i.jsxs)(t.p,{children:["Sensitive data redaction replaces personally identifiable information (PII) in the text transcript and the audio file. A redacted transcript replaces the original text with ",(0,i.jsx)(t.code,{children:"[PII]"}),"; a redacted audio file replaces spoken personal information with silence. This parameter is useful for protecting customer information."]}),"\n",(0,i.jsxs)(t.p,{children:["Here is an ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html#tca-output-pii-redact-batch",children:"output example"}),"."]}),"\n",(0,i.jsx)(t.h3,{id:"sentiment-analysis",children:"Sentiment analysis"}),"\n",(0,i.jsxs)(t.p,{children:["Sentiment analysis estimates how the customer and agent are feeling throughout the call. This metric is represented as both a quantitative value (with a range from ",(0,i.jsx)(t.code,{children:"5"})," to ",(0,i.jsx)(t.code,{children:"-5"}),") and a qualitative value (",(0,i.jsx)(t.code,{children:"positive"}),", ",(0,i.jsx)(t.code,{children:"neutral"}),", ",(0,i.jsx)(t.code,{children:"mixed"}),", or ",(0,i.jsx)(t.code,{children:"negative"}),"). Quantitative values are provided per quarter and per call; qualitative values are provided per turn."]}),"\n",(0,i.jsx)(t.p,{children:"This metric can help identify if your agent is able to delight an upset customer by the time the call ends."}),"\n",(0,i.jsx)(t.p,{children:"Sentiment analysis works out-of-the-box and thus doesn't support customization, such as model training or custom categories."}),"\n",(0,i.jsxs)(t.p,{children:["Here's an ",(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html#tca-output-sentiment-batch",children:"output example"}),"."]}),"\n",(0,i.jsx)(t.h3,{id:"links",children:"Links"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-batch.html",children:"Post-call analytics - Amazon Transcribe"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/tca-output-batch.html",children:"Post-call analytics output - Amazon Transcribe"})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"toxic-speech-detection",children:"Toxic Speech Detection"}),"\n",(0,i.jsx)(t.p,{children:"Toxic speech detection is the use of artificial intelligence (AI) to identify and flag harmful language in online communications. It helps to keep online spaces safe and inclusive by flagging toxic content like hate speech, harassment, and threats."}),"\n",(0,i.jsx)(t.h3,{id:"how-it-works",children:"How it works"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Classification"})," - Toxic speech detection is a classification task that identifies whether a comment is toxic, or what type of toxic comment it is."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Machine learning"})," - Machine learning models like logistic regression, support vector machines (SVM), and random forests are used to detect toxic speech."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Deep learning"})," - Deep learning models like convolutional neural networks (CNN), multi-layer perceptrons (MLP), and long short-term memory (LSTM) are used to detect toxic speech."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Audio and text"})," - Some models use both audio and text-based cues to detect toxic speech. For example, Amazon Transcribe Toxicity Detection uses speech cues like pitch and tone in addition to text."]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"benefits",children:"Benefits"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Helps to keep online spaces safe and inclusive"}),"\n",(0,i.jsx)(t.li,{children:"Helps moderators to quickly and efficiently manage discourse on their platforms"}),"\n",(0,i.jsx)(t.li,{children:"Helps to minimize the volume of data that must be manually processed"}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"amazon-transcribe-1",children:"Amazon Transcribe"}),"\n",(0,i.jsx)(t.p,{children:"Toxic speech is tagged and categorized in your transcription output. Each instance of toxic speech is categorized and assigned a confidence score (a value between 0 and 1. A larger confidence value indicates a greater likelihood that the content is toxic speech within the specified category."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-json",children:'{\n    "jobName": "my-toxicity-job",\n    "accountId": "111122223333",\n    "results": {\n        "transcripts": [...],\n        "items":[...],\n        "toxicity_detection": [\n            {\n                "text": "What the * are you doing man? That\'s why I didn\'t want to play with your * .  man it was a no, no I\'m not calming down * man. I well I spent I spent too much * money on this game.",\n                "toxicity": 0.7638,\n                "categories": {\n                    "profanity": 0.9913,\n                    "hate_speech": 0.0382,\n                    "sexual": 0.0016,\n                    "insult": 0.6572,\n                    "violence_or_threat": 0.0024,\n                    "graphic": 0.0013,\n                    "harassment_or_abuse": 0.0249\n                },\n                "start_time": 8.92,\n                "end_time": 21.45\n            },\n            Items removed for brevity\n            {\n                "text": "What? Who? What the * did you just say to me? What\'s your address? What is your * address? I will pull up right now on your * * man. Take your * back to , tired of this **.",\n                "toxicity": 0.9816,\n                "categories": {\n                    "profanity": 0.9865,\n                    "hate_speech": 0.9123,\n                    "sexual": 0.0037,\n                    "insult": 0.5447,\n                    "violence_or_threat": 0.5078,\n                    "graphic": 0.0037,\n                    "harassment_or_abuse": 0.0613\n                },\n                "start_time": 43.459,\n                "end_time": 54.639\n            },\n        ]\n    },\n    ...\n    "status": "COMPLETED"\n}\n'})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.aws.amazon.com/transcribe/latest/dg/toxicity-using.html",children:"Using toxic speech detection - Amazon Transcribe"})})]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},28453:(e,t,a)=>{a.d(t,{R:()=>r,x:()=>o});var n=a(296540);const i={},s=n.createContext(i);function r(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);