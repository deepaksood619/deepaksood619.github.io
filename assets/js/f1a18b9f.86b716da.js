"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[25956],{290202:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>d,frontMatter:()=>i,metadata:()=>c,toc:()=>l});var s=a(785893),n=a(511151);const i={},r="Kafka schema-registry",c={id:"technologies/kafka/kafka-schema-registry",title:"Kafka schema-registry",description:"https://www.confluent.io/blog/schemas-contracts-compatibility",source:"@site/docs/technologies/kafka/kafka-schema-registry.md",sourceDirName:"technologies/kafka",slug:"/technologies/kafka/kafka-schema-registry",permalink:"/technologies/kafka/kafka-schema-registry",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/kafka-schema-registry.md",tags:[],version:"current",lastUpdatedAt:1701793554,formattedLastUpdatedAt:"Dec 5, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"kafka-rest proxy",permalink:"/technologies/kafka/kafka-rest-proxy"},next:{title:"Kafka Streams",permalink:"/technologies/kafka/kafka-streams"}},o={},l=[{value:"Schema Registry Commands",id:"schema-registry-commands",level:2},{value:"References",id:"references",level:2}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"kafka-schema-registry",children:"Kafka schema-registry"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://www.confluent.io/blog/schemas-contracts-compatibility",children:"https://www.confluent.io/blog/schemas-contracts-compatibility"})}),"\n",(0,s.jsxs)(t.p,{children:["Schema Registry provides a serving layer for your metadata. It provides a RESTful interface for storing and retrieving Avro schemas. It stores a ",(0,s.jsx)(t.strong,{children:"versioned history"})," of all schemas, provides multiple compatibility settings and allows evolution of schemas according to the configured compatibility settings and expanded Avro support. It provides serializers that plug into Kafka clients that handle schema storage and retrieval for Kafka messages that are sent in the Avro format."]}),"\n",(0,s.jsx)(t.p,{children:"Schema Registry is a distributed storage layer for Avro Schemas which uses Kafka as its underlying storage mechanism. Some key design decisions:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Assigns globally unique ID to each registered schema. Allocated IDs are guaranteed to be monotonically increasing but not necessarily consecutive."}),"\n",(0,s.jsx)(t.li,{children:"Kafka provides the durable backend, and functions as a write-ahead changelog for the state of Schema Registry and the schemas it contains."}),"\n",(0,s.jsx)(t.li,{children:"Schema Registry is designed to be distributed, with single-master architecture, and ZooKeeper/Kafka coordinates master election (based on the configuration)."}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:'# to change the compatibility of schema-registry\ndocker exec schema-registry curl -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" \\\n    --data \'{"compatibility": "NONE"}\' \\\n    http://schema-registry:8081/config\n'})}),"\n",(0,s.jsx)(t.h2,{id:"schema-registry-commands",children:"Schema Registry Commands"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:'# Register a new version of a schema under the subject "Kafka-key"\ncurl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"schema": "{"type": "string"}"}\'\nhttp://localhost:8081/subjects/Kafka-key/versions\n{"id":1}\n\n# Register a new version of a schema under the subject "Kafka-value"\ncurl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"schema": "{"type": "string"}"}\'\nhttp://localhost:8081/subjects/Kafka-value/versions\n{"id":1}\n\n# List all subjects\ncurl -X GET http://localhost:8081/subjects\n["Kafka-value","Kafka-key"]\n\n# List all schema versions registered under the subject "Kafka-value"\ncurl -X GET http://localhost:8081/subjects/Kafka-value/versions\n[1]\n\n# Fetch a schema by globally unique id 1\ncurl -X GET http://localhost:8081/schemas/ids/1\n{"schema":""string""}\n\n# Fetch version 1 of the schema registered under subject "Kafka-value"\ncurl -X GET http://localhost:8081/subjects/Kafka-value/versions/1\n{"subject":"Kafka-value","version":1,"id":1,"schema":""string""}\n\n# Fetch the most recently registered schema under subject "Kafka-value"\ncurl -X GET http://localhost:8081/subjects/Kafka-value/versions/latest\n{"subject":"Kafka-value","version":1,"id":1,"schema":""string""}\n\n# Delete version 3 of the schema registered under subject "Kafka-value"\ncurl -X DELETE http://localhost:8081/subjects/Kafka-value/versions/3\n3\n\n# Delete all versions of the schema registered under subject "Kafka-value"\ncurl -X DELETE http://localhost:8081/subjects/Kafka-value\n[1, 2, 3, 4, 5]\n\n# Check whether a schema has been registered under subject "Kafka-key"\ncurl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"schema": "{"type": "string"}"}\'\nhttp://localhost:8081/subjects/Kafka-key\n{"subject":"Kafka-key","version":1,"id":1,"schema":""string""}\n\n# Test compatibility of a schema with the latest schema under subject "Kafka-value"\ncurl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"schema": "{"type": "string"}"}\'\nhttp://localhost:8081/compatibility/subjects/Kafka-value/versions/latest\n{"is_compatible":true}\n\n# Get top level config\ncurl -X GET http://localhost:8081/config\n{"compatibilityLevel":"BACKWARD"}\n\n# Update compatibility requirements globally\ncurl -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"compatibility": "NONE"}\'\nhttp://localhost:8081/config\n{"compatibility":"NONE"}\n\n# Update compatibility requirements under the subject "Kafka-value"\ncurl -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json"\n--data \'{"compatibility": "BACKWARD"}\'\nhttp://localhost:8081/config/Kafka-value\n{"compatibility":"BACKWARD"}\n'})}),"\n",(0,s.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://docs.confluent.io/current/schema-registry/docs/index.html",children:"https://docs.confluent.io/current/schema-registry/docs/index.html"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://github.com/confluentinc/schema-registry",children:"https://github.com/confluentinc/schema-registry"})})]})}function d(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},511151:(e,t,a)=>{a.d(t,{Z:()=>c,a:()=>r});var s=a(667294);const n={},i=s.createContext(n);function r(e){const t=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),s.createElement(i.Provider,{value:t},e.children)}}}]);