"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[40577],{695347:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>r,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"databases-sql/mysql/backup-policy","title":"Backup Policy","description":"Full Backups","source":"@site/docs/databases-sql/mysql/backup-policy.md","sourceDirName":"databases-sql/mysql","slug":"/databases-sql/mysql/backup-policy","permalink":"/databases-sql/mysql/backup-policy","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/databases-sql/mysql/backup-policy.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1753437649000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Backup Comparisons","permalink":"/databases-sql/mysql/backup-comparisons"},"next":{"title":"Backup Types","permalink":"/databases-sql/mysql/backup-types"}}');var t=a(474848),l=a(28453);const o={},i="Backup Policy",r={},c=[{value:"Full Backups",id:"full-backups",level:2},{value:"Incremental Backups",id:"incremental-backups",level:2},{value:"Note",id:"note",level:2},{value:"Grandfather-father-son or GFS?",id:"grandfather-father-son-or-gfs",level:2},{value:"Tools",id:"tools",level:2}];function h(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"backup-policy",children:"Backup Policy"})}),"\n",(0,t.jsx)(s.h2,{id:"full-backups",children:"Full Backups"}),"\n",(0,t.jsxs)(s.p,{children:["To be useful, backups must be scheduled regularly. A full backup (a snapshot of the data at a point in time) can be done in MySQL with several tools. For example, ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/mysql-enterprise-backup.html",children:"MySQL Enterprise Backup"})," can perform a ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_physical_backup",children:"physical backup"})," of an entire instance, with optimizations to minimize overhead and avoid disruption when backing up ",(0,t.jsx)(s.code,{children:"InnoDB"})," data files; ",(0,t.jsx)(s.strong,{children:"mysqldump"})," provides online ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_logical_backup",children:"logical backup"}),". This discussion uses ",(0,t.jsx)(s.strong,{children:"mysqldump"}),"."]}),"\n",(0,t.jsxs)(s.p,{children:["Assume that we make a full backup of all our ",(0,t.jsx)(s.code,{children:"InnoDB"})," tables in all databases using the following command on Sunday at 1 p.m., when load is low:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"$> mysqldump --all-databases --master-data --single-transaction > backup_sunday_1_PM.sql\n"})}),"\n",(0,t.jsxs)(s.p,{children:["The resulting ",(0,t.jsx)(s.code,{children:".sql"})," file produced by ",(0,t.jsx)(s.strong,{children:"mysqldump"})," contains a set of SQL ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/insert.html",children:(0,t.jsx)(s.code,{children:"INSERT"})})," statements that can be used to reload the dumped tables at a later time."]}),"\n",(0,t.jsxs)(s.p,{children:["This backup operation acquires a global read lock on all tables at the beginning of the dump (using ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/flush.html#flush-tables-with-read-lock",children:(0,t.jsx)(s.code,{children:"FLUSH TABLES WITH READ LOCK"})}),"). As soon as this lock has been acquired, the binary log coordinates are read and the lock is released. If long updating statements are running when the ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/flush.html",children:(0,t.jsx)(s.code,{children:"FLUSH"})})," statement is issued, the backup operation may stall until those statements finish. After that, the dump becomes lock-free and does not disturb reads and writes on the tables."]}),"\n",(0,t.jsxs)(s.p,{children:["It was assumed earlier that the tables to back up are ",(0,t.jsx)(s.code,{children:"InnoDB"})," tables, so ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_single-transaction",children:(0,t.jsx)(s.code,{children:"--single-transaction"})})," uses a consistent read and guarantees that data seen by ",(0,t.jsx)(s.strong,{children:"mysqldump"})," does not change. (Changes made by other clients to ",(0,t.jsx)(s.code,{children:"InnoDB"})," tables are not seen by the ",(0,t.jsx)(s.strong,{children:"mysqldump"})," process.) If the backup operation includes nontransactional tables, consistency requires that they do not change during the backup. For example, for the ",(0,t.jsx)(s.code,{children:"MyISAM"})," tables in the ",(0,t.jsx)(s.code,{children:"mysql"})," database, there must be no administrative changes to MySQL accounts during the backup."]}),"\n",(0,t.jsx)(s.h2,{id:"incremental-backups",children:"Incremental Backups"}),"\n",(0,t.jsx)(s.p,{children:"Full backups are necessary, but it is not always convenient to create them. They produce large backup files and take time to generate. They are not optimal in the sense that each successive full backup includes all data, even that part that has not changed since the previous full backup. It is more efficient to make an initial full backup, and then to make incremental backups. The incremental backups are smaller and take less time to produce. The tradeoff is that, at recovery time, you cannot restore your data just by reloading the full backup. You must also process the incremental backups to recover the incremental changes."}),"\n",(0,t.jsxs)(s.p,{children:["To make incremental backups, we need to save the incremental changes. In MySQL, these changes are represented in the binary log, so the MySQL server should always be started with the ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/replication-options-binary-log.html#option_mysqld_log-bin",children:(0,t.jsx)(s.code,{children:"--log-bin"})})," option to enable that log. With binary logging enabled, the server writes each data change into a file while it updates data. Looking at the data directory of a MySQL server that was started with the ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/replication-options-binary-log.html#option_mysqld_log-bin",children:(0,t.jsx)(s.code,{children:"--log-bin"})})," option and that has been running for some days, we find these MySQL binary log files:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-simple",children:"-rw-rw---- 1 guilhem  guilhem   1277324 Nov 10 23:59 gbichot2-bin.000001\n-rw-rw---- 1 guilhem  guilhem         4 Nov 10 23:59 gbichot2-bin.000002\n-rw-rw---- 1 guilhem  guilhem        79 Nov 11 11:06 gbichot2-bin.000003\n-rw-rw---- 1 guilhem  guilhem       508 Nov 11 11:08 gbichot2-bin.000004\n-rw-rw---- 1 guilhem  guilhem 220047446 Nov 12 16:47 gbichot2-bin.000005\n-rw-rw---- 1 guilhem  guilhem    998412 Nov 14 10:08 gbichot2-bin.000006\n-rw-rw---- 1 guilhem  guilhem       361 Nov 14 10:07 gbichot2-bin.index\n"})}),"\n",(0,t.jsxs)(s.p,{children:["Each time it restarts, the MySQL server creates a new binary log file using the next number in the sequence. While the server is running, you can also tell it to close the current binary log file and begin a new one manually by issuing a ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/flush.html#flush-logs",children:(0,t.jsx)(s.code,{children:"FLUSH LOGS"})})," SQL statement or with a ",(0,t.jsx)(s.strong,{children:"mysqladmin flush-logs"})," command. ",(0,t.jsx)(s.strong,{children:"mysqldump"})," also has an option to flush the logs. The ",(0,t.jsx)(s.code,{children:".index"})," file in the data directory contains the list of all MySQL binary logs in the directory."]}),"\n",(0,t.jsxs)(s.p,{children:["The MySQL binary logs are important for recovery because they form the set of incremental backups. If you make sure to flush the logs when you make your full backup, the binary log files created afterward contain all the data changes made since the backup. Let's modify the previous ",(0,t.jsx)(s.strong,{children:"mysqldump"})," command a bit so that it flushes the MySQL binary logs at the moment of the full backup, and so that the dump file contains the name of the new current binary log:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"mysqldump --single-transaction --flush-logs --master-data=2 --all-databases > backup_sunday_1_PM.sql\n"})}),"\n",(0,t.jsxs)(s.p,{children:["After executing this command, the data directory contains a new binary log file, ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000007"}),", because the ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_flush-logs",children:(0,t.jsx)(s.code,{children:"--flush-logs"})})," option causes the server to flush its logs. The ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_master-data",children:(0,t.jsx)(s.code,{children:"--master-data"})})," option causes ",(0,t.jsx)(s.strong,{children:"mysqldump"})," to write binary log information to its output, so the resulting ",(0,t.jsx)(s.code,{children:".sql"})," dump file includes these lines:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-simple",children:"-- Position to start replication or point-in-time recovery from\n-- CHANGE MASTER TO MASTER_LOG_FILE='gbichot2-bin.000007',MASTER_LOG_POS=4;\n"})}),"\n",(0,t.jsxs)(s.p,{children:["Because the ",(0,t.jsx)(s.strong,{children:"mysqldump"})," command made a full backup, those lines mean two things:"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["The dump file contains all changes made before any changes written to the ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000007"})," binary log file or higher."]}),"\n",(0,t.jsxs)(s.li,{children:["All data changes logged after the backup are not present in the dump file, but are present in the ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000007"})," binary log file or higher."]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["On Monday at 1 p.m., we can create an incremental backup by flushing the logs to begin a new binary log file. For example, executing a ",(0,t.jsx)(s.strong,{children:"mysqladmin flush-logs"})," command creates ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000008"}),". All changes between the Sunday 1 p.m. full backup and Monday 1 p.m. are in the ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000007"})," file. This incremental backup is important, so it is a good idea to copy it to a safe place. (For example, back it up on tape or DVD, or copy it to another machine.) On Tuesday at 1 p.m., execute another ",(0,t.jsx)(s.strong,{children:"mysqladmin flush-logs"})," command. All changes between Monday 1 p.m. and Tuesday 1 p.m. are in the ",(0,t.jsx)(s.code,{children:"gbichot2-bin.000008"})," file (which also should be copied somewhere safe)."]}),"\n",(0,t.jsx)(s.p,{children:"The MySQL binary logs take up disk space. To free up space, purge them from time to time. One way to do this is by deleting the binary logs that are no longer needed, such as when we make a full backup:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"mysqldump --single-transaction --flush-logs --master-data=2 --all-databases --delete-master-logs > backup_sunday_1_PM.sql\n"})}),"\n",(0,t.jsx)(s.h2,{id:"note",children:"Note"}),"\n",(0,t.jsxs)(s.p,{children:["Deleting the MySQL binary logs with ",(0,t.jsx)(s.strong,{children:"mysqldump --delete-master-logs"})," can be dangerous if your server is a replication source server, because replica servers might not yet fully have processed the contents of the binary log. The description for the ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/purge-binary-logs.html",children:(0,t.jsx)(s.code,{children:"PURGE BINARY LOGS"})})," statement explains what should be verified before deleting the MySQL binary logs. See ",(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/refman/5.7/en/purge-binary-logs.html",children:"PURGE BINARY LOGS Statement"}),"."]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.a,{href:"https://dev.mysql.com/doc/mysql-backup-excerpt/5.7/en/backup-policy.html",children:"1.3.1 Establishing a Backup Policy"})}),"\n",(0,t.jsx)(s.h2,{id:"grandfather-father-son-or-gfs",children:"Grandfather-father-son or GFS?"}),"\n",(0,t.jsx)(s.p,{children:"GFS backup is a common rotation scheme for backup, in which there are three or more backup cycles, such as daily, weekly, and monthly. Typically, It consists of daily backups (son, at fixed intervals of hours in a day), a weekly full backup (father, once a week), and monthly full backup (Grandfather, once a month)."}),"\n",(0,t.jsx)(s.p,{children:"It helps to restore the database from the most possible recovery points in case of any requirement or disaster."}),"\n",(0,t.jsx)(s.h2,{id:"tools",children:"Tools"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Veeam"})," is a software company that specializes in data protection, backup, and disaster recovery solutions for virtual, physical, and cloud-based workloads. Founded in 2006, the company is now a global leader in data resilience, helping businesses protect their data across various environments like cloud, virtual, physical, SaaS, and Kubernetes. Veeam's solutions aim to ensure business continuity, minimize downtime, and protect critical data in the face of various disruptions."]})]})}function d(e={}){const{wrapper:s}={...(0,l.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},28453:(e,s,a)=>{a.d(s,{R:()=>o,x:()=>i});var n=a(296540);const t={},l=n.createContext(t);function o(e){const s=n.useContext(l);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function i(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),n.createElement(l.Provider,{value:s},e.children)}}}]);