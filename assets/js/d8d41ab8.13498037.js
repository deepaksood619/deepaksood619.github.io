"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[65794],{319276:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});var t=n(785893),s=n(511151);const a={},l="Dimensionality Reduction",r={id:"ai/ml-algorithms/dimensionality-reduction",title:"Dimensionality Reduction",description:"Dimensionality Reduction",source:"@site/docs/ai/ml-algorithms/dimensionality-reduction.md",sourceDirName:"ai/ml-algorithms",slug:"/ai/ml-algorithms/dimensionality-reduction",permalink:"/ai/ml-algorithms/dimensionality-reduction",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/ml-algorithms/dimensionality-reduction.md",tags:[],version:"current",lastUpdatedAt:1707138374,formattedLastUpdatedAt:"Feb 5, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Decision Tree",permalink:"/ai/ml-algorithms/decision-tree"},next:{title:"Embeddings & Estimators",permalink:"/ai/ml-algorithms/embeddings-and-estimators"}},o={},d=[{value:"Dimensionality Reduction",id:"dimensionality-reduction-1",level:2},{value:"Data Dimensionaity",id:"data-dimensionaity",level:2},{value:"Curse of Dimensionality",id:"curse-of-dimensionality",level:2},{value:"Dimensionality Reduction",id:"dimensionality-reduction-2",level:2},{value:"Feature Subset Selection",id:"feature-subset-selection",level:2},{value:"Techniques",id:"techniques",level:3},{value:"Brute-force approach",id:"brute-force-approach",level:4},{value:"Embedded approaches",id:"embedded-approaches",level:4},{value:"Fiter approaches",id:"fiter-approaches",level:4},{value:"Wrapper approaches",id:"wrapper-approaches",level:4},{value:"Feature Creation",id:"feature-creation",level:2},{value:"Links",id:"links",level:2}];function c(e){const i={a:"a",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"dimensionality-reduction",children:"Dimensionality Reduction"}),"\n",(0,t.jsx)(i.h2,{id:"dimensionality-reduction-1",children:"Dimensionality Reduction"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Purpose","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Avoid curse of dimensionality"}),"\n",(0,t.jsx)(i.li,{children:"Reduce amount of time and memory required by data mining algorithms"}),"\n",(0,t.jsx)(i.li,{children:"Allow data to be more easily visualized"}),"\n",(0,t.jsx)(i.li,{children:"May help to eliminate irrelevant features or reduce noise"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["Techniques","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Principle Component Analysis"}),"\n",(0,t.jsx)(i.li,{children:"Singular Value Decomposition"}),"\n",(0,t.jsx)(i.li,{children:"Others: supervised and non-linear techniques"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"data-dimensionaity",children:"Data Dimensionaity"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"From a theoretical point of view, increasing the number of features should lead to better performance"}),"\n",(0,t.jsx)(i.li,{children:"In practice, the inclusion of more features leads to worse performance (i.e., curse of dimensionality)"}),"\n",(0,t.jsx)(i.li,{children:"The number of training examples required increases exponentially with dimensionality"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"curse-of-dimensionality",children:"Curse of Dimensionality"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"When dimensionality increases, data becomes increasingly sparse in the space that it occupies"}),"\n",(0,t.jsx)(i.li,{children:"Definitions of density and distance between points, which is critical for clustering and outlier detection, become less meaningful"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"dimensionality-reduction-2",children:"Dimensionality Reduction"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Purpose","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Avoid curse of dimensionality"}),"\n",(0,t.jsx)(i.li,{children:"Reduce amount of time and memory required by data mining algorithms"}),"\n",(0,t.jsx)(i.li,{children:"Allow data to be more easily visualized"}),"\n",(0,t.jsx)(i.li,{children:"May help to eliminate irrelevant features or reduce noise"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["Techniques","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Principle Component Analysis"}),"\n",(0,t.jsx)(i.li,{children:"Single Value Decomposition"}),"\n",(0,t.jsx)(i.li,{children:"Others: Supervised and non-linear techniques"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(152322).Z+"",width:"1100",height:"573"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(420558).Z+"",width:"1100",height:"431"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(714916).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(711615).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(894480).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(374363).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(573095).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(886793).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(885939).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(322645).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(825055).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(558464).Z+"",width:"1440",height:"810"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python",children:"https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python"})}),"\n",(0,t.jsx)(i.h2,{id:"feature-subset-selection",children:"Feature Subset Selection"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Another way to reduce dimensionality of data"}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Redundant features"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"duplicate much or all of the information contained in one or more other attributes"}),"\n",(0,t.jsx)(i.li,{children:"Example: purchase price of a product and the amount of sales tax paid"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Irrelevant features"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"contain no information that is useful for the data mining task at hand"}),"\n",(0,t.jsx)(i.li,{children:"Examples: students' ID is often irrelevant to the task of predicting students' GPA"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Evaluate a subset of feature"}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Search for the best subset"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"techniques",children:"Techniques"}),"\n",(0,t.jsx)(i.h4,{id:"brute-force-approach",children:"Brute-force approach"}),"\n",(0,t.jsx)(i.p,{children:"Try all possible feature subsets as input to data mining algorithm"}),"\n",(0,t.jsx)(i.h4,{id:"embedded-approaches",children:"Embedded approaches"}),"\n",(0,t.jsx)(i.p,{children:"Feature selection occurs natually as part of the data mining algorithm"}),"\n",(0,t.jsx)(i.h4,{id:"fiter-approaches",children:"Fiter approaches"}),"\n",(0,t.jsx)(i.p,{children:"Features are selected before data mining algorithm is run"}),"\n",(0,t.jsx)(i.h4,{id:"wrapper-approaches",children:"Wrapper approaches"}),"\n",(0,t.jsx)(i.p,{children:"Use the data mining algorithm as a black box to find best subset of attributes"}),"\n",(0,t.jsx)(i.h2,{id:"feature-creation",children:"Feature Creation"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Create new attributes that can capture the important information in a data set much more efficiently than the original attributes"}),"\n",(0,t.jsxs)(i.li,{children:["Three general methodologies","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Feature Extraction - domain-specific"}),"\n",(0,t.jsx)(i.li,{children:"Mapping data to new space"}),"\n",(0,t.jsx)(i.li,{children:"Feature construction - combining features"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"links",children:"Links"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://hex.tech/blog/dimensionality-reduction/",children:"Introduction to dimensionality reduction - Blog | Hex"})})]})}function h(e={}){const{wrapper:i}={...(0,s.a)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},152322:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image1-0aa3997ee2c52cb127a831444433580b.jpg"},573095:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image10-36036158fc1fdf1ec41a5b47255b3280.jpg"},886793:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image11-52572bcec170d6e79380694acbf4dd4b.jpg"},885939:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image12-4983879520fb15e44c6e00cc5b03412a.jpg"},322645:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image13-a6cb85ff455afd6d4313231ebb3a0718.jpg"},825055:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image14-7f416b540f482c2190b26860048c9a94.jpg"},558464:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image15-a68eb0a8a319d063490304fc77841f4b.jpg"},420558:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image2-44848af5b9ab757c269a87b08e83e260.jpg"},714916:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image6-b96dba732268c282222f6f15bccfadaf.jpg"},711615:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image7-3c195cf7b28a8fa4fa43ec5d6435309b.jpg"},894480:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image8-216621f6608ecf42407f24e95643db4c.jpg"},374363:(e,i,n)=>{n.d(i,{Z:()=>t});const t=n.p+"assets/images/Dimensionality-Reduction-image9-bd1dbdddeb663899ee18da95b722c1ed.jpg"},511151:(e,i,n)=>{n.d(i,{Z:()=>r,a:()=>l});var t=n(667294);const s={},a=t.createContext(s);function l(e){const i=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(a.Provider,{value:i},e.children)}}}]);