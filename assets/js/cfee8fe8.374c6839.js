"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[589],{986072:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>c,contentTitle:()=>p,default:()=>d,frontMatter:()=>n,metadata:()=>i,toc:()=>l});var r=s(785893),t=s(511151);const n={},p="SQL Functions / Datasources",i={id:"technologies/apache-spark/10-sql-functions-datasources",title:"SQL Functions / Datasources",description:"PySpark SQL Functions",source:"@site/docs/technologies/apache-spark/10-sql-functions-datasources.md",sourceDirName:"technologies/apache-spark",slug:"/technologies/apache-spark/10-sql-functions-datasources",permalink:"/technologies/apache-spark/10-sql-functions-datasources",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/apache-spark/10-sql-functions-datasources.md",tags:[],version:"current",lastUpdatedAt:1734022610,formattedLastUpdatedAt:"Dec 12, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"DataFrame",permalink:"/technologies/apache-spark/09-dataframe"},next:{title:"Built-In Functions",permalink:"/technologies/apache-spark/11-built-in-functions"}},c={},l=[{value:"PySpark SQL Functions",id:"pyspark-sql-functions",level:2},{value:"PySpark Datasources",id:"pyspark-datasources",level:2}];function o(e){const a={a:"a",h1:"h1",h2:"h2",li:"li",ul:"ul",...(0,t.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.h1,{id:"sql-functions--datasources",children:"SQL Functions / Datasources"}),"\n",(0,r.jsx)(a.h2,{id:"pyspark-sql-functions",children:"PySpark SQL Functions"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/",children:"PySpark - Aggregate Functions"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-window-functions/",children:"PySpark - Window Functions"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/",children:"PySpark - Date and Timestamp Functions"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-json-functions-with-examples/",children:"PySpark - JSON Functions"})}),"\n"]}),"\n",(0,r.jsx)(a.h2,{id:"pyspark-datasources",children:"PySpark Datasources"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-read-csv-file-into-dataframe/",children:"PySpark - Read & Write CSV File"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-read-and-write-parquet-file/",children:"PySpark - Read & Write Parquet File"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-read-json-file-into-dataframe/",children:"PySpark - Read & Write JSON file"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/apache-hive/pyspark-sql-read-hive-table/",children:"PySpark - Read Hive Table"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/apache-hive/pyspark-save-dataframe-to-hive-table/",children:"PySpark - Save to Hive Table"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/read-jdbc-in-parallel-using-pyspark/",children:"PySpark - Read JDBC in Parallel"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-query-database-table-using-jdbc/",children:"PySpark - Query Database Table"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-with-sql-server-read-and-write-table/",children:"PySpark - Read and Write SQL Server"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-read-and-write-mysql-database-table/",children:"PySpark - Read and Write MySQL"})}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://sparkbyexamples.com/pyspark/pyspark-read-jdbc-table-to-dataframe/",children:"PySpark - Read JDBC Table"})}),"\n"]})]})}function d(e={}){const{wrapper:a}={...(0,t.a)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},511151:(e,a,s)=>{s.d(a,{Z:()=>i,a:()=>p});var r=s(667294);const t={},n=r.createContext(t);function p(e){const a=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:p(e.components),r.createElement(n.Provider,{value:a},e.children)}}}]);