"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[78576],{241349:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>l,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var n=i(785893),s=i(511151);const a={},r="Cache Access Patterns (Writing Policies)",o={id:"computer-science/operating-system/cache-access-patterns",title:"Cache Access Patterns (Writing Policies)",description:"When a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as thewrite policy.",source:"@site/docs/computer-science/operating-system/cache-access-patterns.md",sourceDirName:"computer-science/operating-system",slug:"/computer-science/operating-system/cache-access-patterns",permalink:"/computer-science/operating-system/cache-access-patterns",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/computer-science/operating-system/cache-access-patterns.md",tags:[],version:"current",lastUpdatedAt:1699511710,formattedLastUpdatedAt:"Nov 9, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Basic Computer Organization",permalink:"/computer-science/operating-system/basic-computer-organization"},next:{title:"Cache Coherence",permalink:"/computer-science/operating-system/cache-coherence-invalidation"}},c={},h=[{value:"Write-through",id:"write-through",level:2},{value:"Write-back (write-behind)",id:"write-back-write-behind",level:2},{value:"Write-around",id:"write-around",level:2}];function d(e){const t={h1:"h1",h2:"h2",img:"img",p:"p",strong:"strong",...(0,s.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"cache-access-patterns-writing-policies",children:"Cache Access Patterns (Writing Policies)"}),"\n",(0,n.jsx)(t.p,{children:"When a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as thewrite policy."}),"\n",(0,n.jsx)(t.h2,{id:"write-through",children:"Write-through"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"image",src:i(415051).Z+"",width:"831",height:"540"})}),"\n",(0,n.jsx)(t.p,{children:"write is done synchronously both to the cache and to the backing store. The significance here is not the order in which it happens or whether it happens in parallel. The significance is that I/O completion is only confirmed once the data has been written to both places."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Advantage:"})}),"\n",(0,n.jsx)(t.p,{children:"Ensures fast retrieval while making sure the data is in the backing store and is not lost in case the cache is disrupted."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Disadvantage:"})}),"\n",(0,n.jsx)(t.p,{children:"Writing data will experience latency as you have to write to two places every time."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"What is it good for?"})}),"\n",(0,n.jsx)(t.p,{children:"The write-through policy is good for applications that has more reads than writes. This will result in slightly higher write latency but low read latency. So, it's ok to spend a bit longer writing once, but then benefit from reading frequently with low latency."}),"\n",(0,n.jsx)(t.h2,{id:"write-back-write-behind",children:"Write-back (write-behind)"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"image",src:i(74671).Z+"",width:"784",height:"543"})}),"\n",(0,n.jsx)(t.p,{children:"Initially, writing is done only to the cache. The write to the backing store is postponed until the modified content is about to be replaced by another cache block."}),"\n",(0,n.jsx)(t.p,{children:"Using the write-back policy, data is written to the cache and immediately I/O completion is confirmed. The data is then typically also written to the backing store in the background but the completion confirmation is not blocked on that."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Advantage:"})}),"\n",(0,n.jsx)(t.p,{children:"Low latency and high throughput for write-intensive applications."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Disadvantage:"})}),"\n",(0,n.jsx)(t.p,{children:"There is data availability risk because the cache could fail (and so suffer from data loss) before the data is persisted to the backing store. This result in the data being lost."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"What is it good for?"})}),"\n",(0,n.jsx)(t.p,{children:"The write-back policy is the best performer for mixed workloads as both read and write I/O have similar response time levels. In reality, you can add resiliency (e.g. by duplicating writes) to reduce the likelihood of data loss."}),"\n",(0,n.jsx)(t.h2,{id:"write-around",children:"Write-around"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"image",src:i(788157).Z+"",width:"1182",height:"776"})}),"\n",(0,n.jsx)(t.p,{children:"Using the write-around policy, data is written only to the backing store without writing to the cache. So, I/O completion is confirmed as soon as the data is written to the backing store."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Advantage:"})}),"\n",(0,n.jsx)(t.p,{children:"Good for not flooding the cache with data that may not subsequently be re-read."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Disadvantage:"})}),"\n",(0,n.jsx)(t.p,{children:"Reading recently written data will result in a cache miss (and so a higher latency) because the data can only be read from the slower backing store."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"What is it good for?"})}),"\n",(0,n.jsx)(t.p,{children:"The write-around policy is good for applications that don't frequently re-read recently written data. This will result in lower write latency but higher read latency which is a acceptable trade-off for these scenarios."})]})}function l(e={}){const{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},415051:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/Caches-Caching-image1-d953625e5a299ffff827180d8771c440.jpg"},74671:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/Caches-Caching-image2-76cbc1f3356deacecb636eba187aa1ac.jpg"},788157:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/Caches-Caching-image3-e875c4f888578f563dbb50b045f9ba54.jpg"},511151:(e,t,i)=>{i.d(t,{Z:()=>o,a:()=>r});var n=i(667294);const s={},a=n.createContext(s);function r(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);