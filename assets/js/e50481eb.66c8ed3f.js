"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[5501],{52937:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"ai/llm/voice-models","title":"Voice Models","description":"Speech to text Model - Whisper / Voice to Text / Audio to Text","source":"@site/docs/ai/llm/voice-models.md","sourceDirName":"ai/llm","slug":"/ai/llm/voice-models","permalink":"/ai/llm/voice-models","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/llm/voice-models.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1769226241000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Tuning","permalink":"/ai/llm/tuning"},"next":{"title":"ML Algorithms","permalink":"/ai/ml-algorithms/"}}');var s=t(474848),a=t(28453);const o={},r="Voice Models",l={},c=[{value:"Speech to text Model - Whisper / Voice to Text / Audio to Text",id:"speech-to-text-model---whisper--voice-to-text--audio-to-text",level:2},{value:"Speech to Speech",id:"speech-to-speech",level:3},{value:"Call Transcribing",id:"call-transcribing",level:2},{value:"Purpose",id:"purpose",level:3},{value:"Benefits",id:"benefits",level:3},{value:"Quality assurance process",id:"quality-assurance-process",level:3},{value:"Real-Time Factor (RTF)",id:"real-time-factor-rtf",level:3},{value:"Tools",id:"tools",level:2},{value:"Text to Voice",id:"text-to-voice",level:2},{value:"Voice ChatBot / Voice AI",id:"voice-chatbot--voice-ai",level:2},{value:"GitHub - freddyaboulton/fastrtc: The python library for real-time communication",id:"github---freddyaboultonfastrtc-the-python-library-for-real-time-communication",level:3}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"voice-models",children:"Voice Models"})}),"\n",(0,s.jsx)(n.h2,{id:"speech-to-text-model---whisper--voice-to-text--audio-to-text",children:"Speech to text Model - Whisper / Voice to Text / Audio to Text"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://huggingface.co/openai/whisper-large-v3",children:"openai/whisper-large-v3 \xb7 Hugging Face"})}),"\n",(0,s.jsx)(n.li,{children:"Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification."}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/openai/whisper",children:"GitHub - openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/petewarden/spchcat",children:"GitHub - petewarden/spchcat: Speech recognition tool to convert audio to text transcripts, for Linux and Raspberry Pi."})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://zapier.com/blog/best-text-dictation-software/",children:"The best dictation and speech-to-text software | Zapier"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.regal.ai/",children:"REGAL | The AI Agent Platform"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://livekit.io/",children:"LiveKit"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://demo.gigaml.com/",children:"Demo | GigaML"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.teneo.ai/",children:"Teneo.ai | Make Your AI Agent the Smartest"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.voiceflow.com/",children:"Build Chat and Voice AI Agents Without Code | Voiceflow"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"speech-to-speech",children:"Speech to Speech"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Personaplex"})," is a real-time speech-to-speech conversational model that jointly performs streaming speech understanding and speech generation. The model operates on continuous audio encoded with a neural codec and predicts both text tokens and audio tokens autoregressively to produce its spoken responses. Incoming user audio is incrementally encoded and fed to the model while Personaplex simultaneously generates its own outgoing speech, enabling natural conversational dynamics such as interruptions, barge-ins, overlaps, and rapid turn-taking. Personaplex runs in a dual-stream configuration in which listening and speaking occur concurrently. This design allows the model to update its internal state based on the user\u2019s ongoing speech while still producing fluent output audio, supporting highly interactive conversations. Before the conversation begins, Personaplex is conditioned on two prompts: a voice prompt and a text prompt. The voice prompt consists of a sequence of audio tokens that establish the target vocal characteristics and speaking style. The text prompt specifies persona attributes such as role, background, and scenario context. Together, these prompts define the model's conversational identity and guide its linguistic and acoustic behavior throughout the interaction."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/NVIDIA/personaplex",children:"GitHub - NVIDIA/personaplex: PersonaPlex code."})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://huggingface.co/nvidia/personaplex-7b-v1",children:"nvidia/personaplex-7b-v1 \xb7 Hugging Face"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"call-transcribing",children:"Call Transcribing"}),"\n",(0,s.jsx)(n.p,{children:'"Call transcribing" refers to the process of converting a recorded phone conversation into written text, while "quality assurance" in this context means the practice of reviewing those transcribed calls to ensure accuracy and adherence to quality standards, often used to evaluate customer service interactions and agent performance within a company.'}),"\n",(0,s.jsx)(n.p,{children:"Key points about call transcribing and quality assurance:"}),"\n",(0,s.jsx)(n.h3,{id:"purpose",children:"Purpose"}),"\n",(0,s.jsx)(n.p,{children:"Companies often record customer service calls for quality assurance, which involves transcribing the conversation to review details like agent responses, issue resolution, and adherence to company policies."}),"\n",(0,s.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Agent training:"})," Transcripts can be used to identify areas where agents need improvement in communication skills or product knowledge."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Customer experience evaluation:"})," Analyzing transcripts allows companies to assess customer satisfaction and identify potential issues."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Compliance checks:"})," In industries with strict regulations, call transcripts can be used to verify compliance with legal requirements."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"quality-assurance-process",children:"Quality assurance process"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sampling:"})," A representative sample of calls is selected for transcription."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Transcription:"})," The audio is converted into written text, ensuring accuracy and capturing key details like pauses and tone of voice."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Review and evaluation:"})," Quality assurance specialists review the transcripts against established criteria, assessing aspects like agent greetings, problem-solving techniques, and overall professionalism."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"real-time-factor-rtf",children:"Real-Time Factor (RTF)"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"real-time factor (RTF)"})," is the ratio of the processing (or transcription) time to the actual duration of the audio. In other words, it measures how fast a system processes audio relative to real time. An RTF less than 1 means the system is faster than real time."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example:"})}),"\n",(0,s.jsx)(n.p,{children:"Suppose an AI tool transcribes a 1\u2011minute (60\u2011second) call in 1 second. Here, the RTF is:"}),"\n",(0,s.jsx)(n.p,{children:"\u2003\u2003RTF = Processing Time / Audio Duration = 1 sec / 60 sec = 1/60"}),"\n",(0,s.jsx)(n.p,{children:"This indicates that the system is 60 times faster than real time. If you have a call lasting x minutes and the system transcribes it in x seconds, the RTF remains 1/60, meaning it delivers the transcript at 60\xd7 real-time speed."}),"\n",(0,s.jsx)(n.p,{children:"This fast turnaround is particularly valuable in call quality monitoring, where near real\u2011time feedback can help promptly address issues or monitor performance."}),"\n",(0,s.jsx)(n.h2,{id:"tools",children:"Tools"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/cloud/aws/ai/amazon-transcribe",children:"Amazon Transcribe"})}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://voxjar.com/",children:"AI for Call Center Quality Assurance | Voxjar"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://app.voxjar.com/dashboard",children:"app.voxjar.com/dashboard"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://convin.ai/",children:"Convin: Omnichannel Contact Centers Powered By Conversation Intelligence"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://convin.ai/news-collection/g2-rank-speech-analytics-category",children:"Kicking Off 2024 on a High: Convin Ranked as G2's #1 Speech Analytics Solution"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://convin.ai/products/call-center-monitoring-software",children:"Call Center Monitoring Software | Convin"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://thelevel.ai/quality-assurance-contact-center/",children:"Quality Assurance Software for Contact and Call Centers"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://trellissoft.ai/products/chatterscore/",children:"Call Quality Monitoring Software with 100% AI | Chatterscore"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://callcenterstudio.com/blog/ai-powered-quality-management-and-performance-monitoring-in-call-centers/",children:"AI-Powered Quality Management and Performance Monitoring in Call Centers 1"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://enthu.ai/blog/call-center-quality-monitoring-software/",children:"10 Best Call Monitoring Software in 2024 - Enthu AI"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/jiaaro/pydub",children:"GitHub - jiaaro/pydub: Manipulate audio with a simple and easy high level interface"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"text-to-voice",children:"Text to Voice"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://voicemaker.in/",children:"Voicemaker\xae - Text to Speech Converter"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://elevenlabs.io/",children:"Bring Agents and Creative to Life with our AI Voice Generator"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"voice-chatbot--voice-ai",children:"Voice ChatBot / Voice AI"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/KoljaB/RealtimeVoiceChat",children:"GitHub - KoljaB/RealtimeVoiceChat: Have a natural, spoken conversation with AI!"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/bigsk1/voice-chat-ai",children:"GitHub - bigsk1/voice-chat-ai: \ud83c\udf99\ufe0f Speak with AI - Run locally using Ollama, OpenAI, Anthropic or xAI - Speech uses SparkTTS, OpenAI, ElevenLabs or Kokoro"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/kaymen99/AI-Voice-assistant",children:"GitHub - kaymen99/AI-Voice-assistant: AI Voice Assistant: Talk to an AI agent that helps you with event scheduling, contact management, accessing your knowledge base, and web searches using simple voice commands"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/alinaqi/AIVoiceBot",children:"GitHub - alinaqi/AIVoiceBot: Complete AI Based Voice Bot service for both inbound and outbound calls."})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/iamaziz/llm-voice-bot",children:"GitHub - iamaziz/llm-voice-bot: Speak (speech-to-text) to LLMs (Ollama) in any lanaguage - Streamlit app https://deepwiki.com/iamaziz/llm-voice-bot"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"github---freddyaboultonfastrtc-the-python-library-for-real-time-communication",children:(0,s.jsx)(n.a,{href:"https://github.com/freddyaboulton/fastrtc",children:"GitHub - freddyaboulton/fastrtc: The python library for real-time communication"})}),"\n",(0,s.jsx)(n.p,{children:"Turn any python function into a real-time audio and video stream over WebRTC or WebSockets."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"\ud83d\udde3\ufe0f Automatic Voice Detection and Turn Taking built-in, only worry about the logic for responding to the user."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udcbb Automatic UI - Use the\xa0",(0,s.jsx)(n.code,{children:".ui.launch()"}),"\xa0method to launch the webRTC-enabled built-in Gradio UI."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udd0c Automatic WebRTC Support - Use the\xa0",(0,s.jsx)(n.code,{children:".mount(app)"}),"\xa0method to mount the stream on a FastAPI app and get a webRTC endpoint for your own frontend!"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["\u26a1\ufe0f Websocket Support - Use the\xa0",(0,s.jsx)(n.code,{children:".mount(app)"}),"\xa0method to mount the stream on a FastAPI app and get a websocket endpoint for your own frontend!"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udcde Automatic Telephone Support - Use the\xa0",(0,s.jsx)(n.code,{children:"fastphone()"}),"\xa0method of the stream to launch the application and get a free temporary phone number!"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83e\udd16 Completely customizable backend - A\xa0",(0,s.jsx)(n.code,{children:"Stream"}),"\xa0can easily be mounted on a FastAPI app so you can easily extend it to fit your production application. See the\xa0",(0,s.jsx)(n.a,{href:"https://huggingface.co/spaces/fastrtc/talk-to-claude",children:"Talk To Claude"}),"\xa0demo for an example on how to serve a custom JS frontend."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"/about-deepak-sood/projects/39-ai-powered-call-quality-monitoring",children:"39-ai-powered-call-quality-monitoring"})}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(296540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);