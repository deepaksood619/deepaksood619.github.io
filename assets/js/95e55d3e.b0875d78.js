"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[91472],{171105:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>o,toc:()=>c});var s=r(785893),i=r(511151);const l={},t="Google Crawlers / Crawling",o={id:"frontend/seo/google-crawlers-crawling",title:"Google Crawlers / Crawling",description:"How Google Search crawls pages - YouTube",source:"@site/docs/frontend/seo/google-crawlers-crawling.md",sourceDirName:"frontend/seo",slug:"/frontend/seo/google-crawlers-crawling",permalink:"/frontend/seo/google-crawlers-crawling",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/frontend/seo/google-crawlers-crawling.md",tags:[],version:"current",lastUpdatedAt:1734020743,formattedLastUpdatedAt:"Dec 12, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Core Web Vitals",permalink:"/frontend/seo/core-web-vitals"},next:{title:"SEO / ASO",permalink:"/frontend/seo/seo-aso"}},a={},c=[{value:"Web Crawlers",id:"web-crawlers",level:2},{value:"Use Case",id:"use-case",level:3},{value:"Features",id:"features",level:3},{value:"Crawl rate",id:"crawl-rate",level:2},{value:"Crawl Budget",id:"crawl-budget",level:2},{value:"Crawl capacity limit",id:"crawl-capacity-limit",level:3},{value:"Crawl demand",id:"crawl-demand",level:3},{value:"Links",id:"links",level:2}];function d(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"google-crawlers--crawling",children:"Google Crawlers / Crawling"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=JuK7NnfyEuc",children:"How Google Search crawls pages - YouTube"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Google bot"}),"\n",(0,s.jsx)(n.li,{children:"Sitemaps"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"web-crawlers",children:"Web Crawlers"}),"\n",(0,s.jsx)(n.h3,{id:"use-case",children:"Use Case"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Search engine"}),"\n",(0,s.jsx)(n.li,{children:"Copywrite violation detection"}),"\n",(0,s.jsxs)(n.li,{children:["Keyword based finding","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"New analysis (share market)"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"Web malware detection"}),"\n",(0,s.jsx)(n.li,{children:"Web analytics"}),"\n",(0,s.jsx)(n.li,{children:"Data science data crawlers"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"features",children:"Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Politeness / Crawl rate"}),"\n",(0,s.jsx)(n.li,{children:"DNS query"}),"\n",(0,s.jsx)(n.li,{children:"Distributed crawling"}),"\n",(0,s.jsx)(n.li,{children:"Priority crawling"}),"\n",(0,s.jsxs)(n.li,{children:["Duplicate detection","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Bruteforce"}),"\n",(0,s.jsx)(n.li,{children:"Hashing (MD5-SHA1)"}),"\n",(0,s.jsx)(n.li,{children:"MinHash"}),"\n",(0,s.jsx)(n.li,{children:"SimHash (Google uses this)"}),"\n",(0,s.jsx)(n.li,{children:"Fuzzy search"}),"\n",(0,s.jsx)(n.li,{children:"Latent semantic indexing"}),"\n",(0,s.jsx)(n.li,{children:"Standard boolean model"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=BKZxZwUgL3Y",children:"System Design distributed web crawler to crawl Billions of web pages | web crawler system design"})}),"\n",(0,s.jsx)(n.h2,{id:"crawl-rate",children:"Crawl rate"}),"\n",(0,s.jsxs)(n.p,{children:["Crawl rate is the number of requests a\xa0",(0,s.jsx)(n.a,{href:"https://www.lumar.io/learn/seo/crawlability/search-engine-crawling/",children:"search engine crawler"}),"\xa0makes to a website in a day and was introduced to reduce server overload. Due to sophisticated algorithms, Google is able to determine and set an optimal crawl budget for individual sites, this is covered within our SEO Office Hours Notes along with further best practice advice."]}),"\n",(0,s.jsx)(n.p,{children:"==If Your Average Server Response Time Goes Up Significantly Because of a CDN Implementation, Google Will Crawl Your Site Less.== This is because Google's crawl rate is based on average response time and server errors.\xa0A longer response time can mean that Googlebot is unable to crawl as much of a site as it would ideally like."}),"\n",(0,s.jsx)(n.p,{children:"Here are some things you can try to increase your site's crawl rate:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Add new content regularly"}),"\n",(0,s.jsx)(n.li,{children:"Improve your site's load time"}),"\n",(0,s.jsx)(n.li,{children:"Include sitemaps"}),"\n",(0,s.jsx)(n.li,{children:"Improve server response time"}),"\n",(0,s.jsx)(n.li,{children:"Avoid duplicate content"}),"\n",(0,s.jsx)(n.li,{children:"Block unwanted pages via Robots"}),"\n",(0,s.jsx)(n.li,{children:"Optimize images and videos"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"crawl-budget",children:"Crawl Budget"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://developers.google.com/search/docs/crawling-indexing/large-site-managing-crawl-budget",children:"Crawl Budget Management For Large Sites | Google Search Central \xa0|\xa0 Documentation \xa0|\xa0 Google for Developers"})}),"\n",(0,s.jsxs)(n.p,{children:["Crawl budget is determined by two main elements:\xa0",(0,s.jsx)(n.em,{children:"crawl capacity limit"}),"\xa0and\xa0",(0,s.jsx)(n.em,{children:"crawl demand"}),"."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=am4g0hXAA8Q",children:"Crawl Budget: SEO Mythbusting - YouTube"})}),"\n",(0,s.jsx)(n.h3,{id:"crawl-capacity-limit",children:"Crawl capacity limit"}),"\n",(0,s.jsxs)(n.p,{children:["Googlebot wants to crawl your site without overwhelming your servers. To prevent this, Googlebot calculates a\xa0",(0,s.jsx)(n.em,{children:"crawl capacity limit"}),", which is the maximum number of simultaneous parallel connections that Googlebot can use to crawl a site, as well as the time delay between fetches. This is calculated to provide coverage of all your important content without overloading your servers."]}),"\n",(0,s.jsx)(n.p,{children:"The crawl capacity limit can go up and down based on a few factors:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Crawl health:"}),"\xa0If the site responds quickly for a while, the limit goes up, meaning more connections can be used to crawl. If the site slows down or responds with server errors, the limit goes down and Googlebot crawls less."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Google's crawling limits"}),": Google has a lot of machines, but not infinite machines. We still need to make choices with the resources that we have."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"crawl-demand",children:"Crawl demand"}),"\n",(0,s.jsx)(n.p,{children:"Google typically spends as much time as necessary crawling a site, given its size, update frequency, page quality, and relevance, compared to other sites."}),"\n",(0,s.jsx)(n.p,{children:"The factors that play a significant role in determining crawl demand are:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Perceived inventory:"}),"\xa0Without guidance from you, Googlebot will try to crawl all or most of the URLs that it knows about on your site. If many of these URLs are duplicates, or you don't want them crawled for some other reason (removed, unimportant, and so on), this wastes a lot of Google crawling time on your site. This is the factor that you can positively control the most."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Popularity:"}),"\xa0URLs that are more popular on the Internet tend to be crawled more often to keep them fresher in our index."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Staleness:"}),"\xa0Our systems want to re-crawl documents frequently enough to pick up any changes."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Additionally, site-wide events like site moves may trigger an increase in crawl demand in order to reindex the content under the new URLs."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://developers.google.com/search/docs/crawling-indexing",children:"Google Crawling and Indexing | Google Search Central \xa0|\xa0 Documentation \xa0|\xa0 Google for Developers"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://developers.google.com/search/docs/crawling-indexing/overview-google-crawlers",children:"Google Crawler (User Agent) Overview | Google Search Central \xa0|\xa0 Documentation \xa0|\xa0 Google for Developers"})}),"\n",(0,s.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/frontend/seo/seo-aso",children:"SEO / ASO"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/@GoogleSearchCentral",children:"Google Search Central - YouTube"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/@AhrefsCom",children:"Ahrefs - YouTube"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.youtube.com/playlist?list=PLKoqnv2vTMUN83JWBNM6MoBuBcyqhFNY3",children:"How Search Works - YouTube"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},511151:(e,n,r)=>{r.d(n,{Z:()=>o,a:()=>t});var s=r(667294);const i={},l=s.createContext(i);function t(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);