"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[61497],{895864:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"technologies/kafka/kafka-producers","title":"Kafka Producers","description":"The producer is the creator of the message in Kafka","source":"@site/docs/technologies/kafka/kafka-producers.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/kafka-producers","permalink":"/technologies/kafka/kafka-producers","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/kafka-producers.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1769598990000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Partitions","permalink":"/technologies/kafka/kafka-partitions"},"next":{"title":"kafka-python","permalink":"/technologies/kafka/kafka-python"}}');var s=n(474848),r=n(28453);const a={},o="Kafka Producers",d={},h=[{value:"Three primary methods of sending messages",id:"three-primary-methods-of-sending-messages",level:2},{value:"Fire-and-forget",id:"fire-and-forget",level:3},{value:"Synchronous send",id:"synchronous-send",level:3},{value:"Asynchronous send",id:"asynchronous-send",level:3},{value:"Serializers",id:"serializers",level:2},{value:"Avro",id:"avro",level:3},{value:"Using Avro records with Kafka",id:"using-avro-records-with-kafka",level:3},{value:"Partitioners - Dynamic Partition Assignment",id:"partitioners---dynamic-partition-assignment",level:2},{value:"1. The Core Architecture: Decoupling Logical from Physical",id:"1-the-core-architecture-decoupling-logical-from-physical",level:3},{value:"A. The Metadata Store (The &quot;Brain&quot;)",id:"a-the-metadata-store-the-brain",level:4},{value:"B. The Smart Producer (Custom Partitioner)",id:"b-the-smart-producer-custom-partitioner",level:4},{value:"2. Achieving Hotspot Prevention &amp; Load Balancing",id:"2-achieving-hotspot-prevention--load-balancing",level:3},{value:"Step 1: Observation (The Metrics)",id:"step-1-observation-the-metrics",level:4},{value:"Step 2: Decision (The Reassignment)",id:"step-2-decision-the-reassignment",level:4},{value:"Step 3: Propagation",id:"step-3-propagation",level:4},{value:"Step 4: Execution",id:"step-4-execution",level:4},{value:"3. Advanced Strategies for &quot;Elephant&quot; Tenants",id:"3-advanced-strategies-for-elephant-tenants",level:3},{value:"1. Tenant Isolation (Dedicated Partition)",id:"1-tenant-isolation-dedicated-partition",level:4},{value:"2. Tenant Sharding (Sub-Partitioning)",id:"2-tenant-sharding-sub-partitioning",level:4},{value:"4. Critical Challenge: The Ordering Guarantee",id:"4-critical-challenge-the-ordering-guarantee",level:3},{value:"Summary of Components",id:"summary-of-components",level:3},{value:"Links",id:"links",level:2}];function l(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"kafka-producers",children:"Kafka Producers"})}),"\n",(0,s.jsx)(t.p,{children:"The producer is the creator of the message in Kafka"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"The producers place the message to a particular topic"}),"\n",(0,s.jsx)(t.li,{children:"The producers also decide which partition to place the message into"}),"\n",(0,s.jsx)(t.li,{children:"Topics should already exist before a message is placed by the producer"}),"\n",(0,s.jsx)(t.li,{children:"Messages are added at one end of the partition"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"image",src:n(131582).A+"",width:"1000",height:"1106"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"We start producing messages to Kafka by creating a ProducerRecord, which must include the topic we want to send the record to and a value. Optionally, we can also specifiy a key and/or a partition. Once we send the ProducerRecord, the first thing the producer will do is serialize the key and value objects to ByteArrays so they can be send over the network."}),"\n",(0,s.jsxs)(t.li,{children:["Next, the data is sent to a partitioner. If we specified a partition in the ProducerRecord, the partitioner doesn't do anything and simply returns the partition we specified. If we didn't, the partitioner will choose a partition for us, usually based on the ProducerRecord key. Once a partition is selected, the producer knows which topic and partition the record will go to. It then adds the record to a batch of records that will also be sent to the same topic and partition. A separate thread is responsible for sending those batches of records to the appropriate Kafka brokers.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Kafka's default partitioner routes messages based on the k",(0,s.jsx)(t.strong,{children:"ey's hash, unless the key is null in which case it uses round robin to distribute messages."})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.li,{children:"When the broker receives the messages, it sends back a response. If the messages were successfully written to Kafka, it will return a RecordMetadata object with the topic, partition, and the offset of the record within the partition. If the broker failed to write the messages, it will return an error. When the producer receives an error, it may retry sending the message a few more times before giving up and returning an error."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"three-primary-methods-of-sending-messages",children:"Three primary methods of sending messages"}),"\n",(0,s.jsx)(t.h3,{id:"fire-and-forget",children:"Fire-and-forget"}),"\n",(0,s.jsx)(t.p,{children:"We send a message to the server and don't really care if it arrives succesfully or not. Most of the time, it will arrive successfully, since Kafka is highly available and the producer will retry sending messages automatically. However, some messages will get lost using this method"}),"\n",(0,s.jsx)(t.h3,{id:"synchronous-send",children:"Synchronous send"}),"\n",(0,s.jsx)(t.p,{children:"We send a message, the send() method returns a Future object, and we use get() to wait on the future and see if the send() was successful or not"}),"\n",(0,s.jsx)(t.h3,{id:"asynchronous-send",children:"Asynchronous send"}),"\n",(0,s.jsx)(t.p,{children:"We call the send() method with a callback function, which gets triggered when it receives a response from the Kafka broker"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.em,{children:"ProducerRecord"})}),"\n",(0,s.jsx)(t.li,{children:"Handling Errors"}),"\n",(0,s.jsx)(t.li,{children:"Configuration options"}),"\n",(0,s.jsx)(t.li,{children:"Different Partitioning Methods, partitioners"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"serializers",children:"Serializers"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Thrift"}),"\n",(0,s.jsx)(t.li,{children:"Protobuf"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"avro",children:"Avro"}),"\n",(0,s.jsx)(t.p,{children:"One of the most interesting features of Avro, and what makes it a good fit for use in a messaging system like Kafka, is that when the application that is writing messages switches to a new schema, the application reading the data can continue processing messages without requiring any change or update."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Kafka has a binary wire protocol, so anyone can read messages from Kafka or write messages to Kafka simply by sending the correct byte sequences to Kafka's network port."}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"using-avro-records-with-kafka",children:"Using Avro records with Kafka"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Unlike Avro files, where storing the entire schema in the data file is associated with a fairly reasonable overhead, storing the entire schema in each record will usually more than double the record size. However, Avro still requires the entire schema to be present when reading the record, so we need to locate the schema elsewhere. To achieve this, we follow a common architecture pattern and use a ",(0,s.jsx)(t.em,{children:"Schema Registry"}),"."]}),"\n",(0,s.jsx)(t.li,{children:"The idea is to store all the schemas used to write data to Kafka in the registry. Then we simply store the identifier for the schema in the record we produce to Kafka. The consumers can then use the identifier to pull the record out of the schema registry and deserialize the data. The key is that all this work - storing the schema in the reg\u2010 istry and pulling it up when required - is done in the serializers and deserializers. The code that produces data to Kafka simply uses the Avro serializer just like it would any other serializer."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"image",src:n(174665).A+"",width:"996",height:"478"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Partitions"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Keys serve two goals: they are additional information that gets stored with the message, and they are also used to decide which one of the topic partitions the message will be written to. All messages with the same key will go to the same partition."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"partitioners---dynamic-partition-assignment",children:"Partitioners - Dynamic Partition Assignment"}),"\n",(0,s.jsx)(t.p,{children:"In dynamic multi-tenant environments, tenants might not have equal traffic. Some tenants may generate a high volume of messages, while others contribute minimally. Using dynamic partition assignment with tenant IDs can help distribute messages evenly by adjusting partition counts and reassigning tenants dynamically."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Load Balancing:"}),"\xa0This helps avoid overloaded partitions when certain tenants generate more traffic. Kafka can handle dynamic rebalancing based on the load, ensuring fair distribution across partitions."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Hotspot Prevention:"}),'\xa0Dynamic reassignment mitigates the risk of certain partitions becoming "hotspots" due to uneven traffic from larger tenants.']}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["It is important to clarify a key architectural distinction upfront: Standard Apache Kafka ",(0,s.jsx)(t.strong,{children:"does not"})," automatically reassign specific Tenant IDs to different partitions based on live traffic load out of the box."]}),"\n",(0,s.jsxs)(t.p,{children:["The capability you described\u2014dynamically routing specific tenants to specific partitions based on their real-time volume\u2014is achieved through an architectural pattern often called ",(0,s.jsx)(t.strong,{children:'"Smart Partitioning"'})," or ",(0,s.jsx)(t.strong,{children:'"Virtual Partitioning."'})]}),"\n",(0,s.jsxs)(t.p,{children:["This is achieved by moving away from the default hashing mechanism (",(0,s.jsx)(t.code,{children:"hash(TenantID) % PartitionCount"}),") and implementing a control layer that dictates exactly where each tenant's data goes."]}),"\n",(0,s.jsx)(t.p,{children:"Here is the detailed breakdown of how this architecture is achieved."}),"\n",(0,s.jsx)(t.h3,{id:"1-the-core-architecture-decoupling-logical-from-physical",children:"1. The Core Architecture: Decoupling Logical from Physical"}),"\n",(0,s.jsxs)(t.p,{children:["In a standard setup, a tenant is permanently bound to a partition by their ID. In a ",(0,s.jsx)(t.strong,{children:"Dynamic Assignment"})," setup, you introduce a layer of indirection."]}),"\n",(0,s.jsx)(t.h4,{id:"a-the-metadata-store-the-brain",children:'A. The Metadata Store (The "Brain")'}),"\n",(0,s.jsxs)(t.p,{children:['You maintain a separate "Routing Table" or "State Store" (often kept in a fast database like Redis, Zookeeper, or a compacted Kafka topic). This table maps ',(0,s.jsx)(t.strong,{children:"Logical Tenant IDs"})," to ",(0,s.jsx)(t.strong,{children:"Physical Partition IDs"}),"."]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Tenant ID"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Assigned Partition(s)"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Status"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Tenant_A (Small)"}),(0,s.jsx)(t.td,{children:"Partition 0"}),(0,s.jsx)(t.td,{children:"Shared"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Tenant_B (Small)"}),(0,s.jsx)(t.td,{children:"Partition 0"}),(0,s.jsx)(t.td,{children:"Shared"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Tenant_C (Huge)"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Partition 1, 2, 3"})}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Dedicated/Sharded"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Tenant_D (Medium)"}),(0,s.jsx)(t.td,{children:"Partition 4"}),(0,s.jsx)(t.td,{children:"Dedicated"})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"b-the-smart-producer-custom-partitioner",children:"B. The Smart Producer (Custom Partitioner)"}),"\n",(0,s.jsxs)(t.p,{children:["You must implement a ",(0,s.jsx)(t.strong,{children:"Custom Partitioner"})," in your Kafka Producer configuration."]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Fetch Map:"}),' When the producer starts (and periodically afterwards), it fetches the "Routing Table" from the Metadata Store.']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Intercept Record:"})," When a message comes in for ",(0,s.jsx)(t.code,{children:"Tenant_C"}),", the producer does ",(0,s.jsx)(t.em,{children:"not"})," hash the ID."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Look up:"})," It looks at its local cache of the table: ",(0,s.jsx)(t.em,{children:'"Where does Tenant_C go currently?"'})]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Dispatch:"})," It sees ",(0,s.jsx)(t.code,{children:"Tenant_C"})," is assigned to Partitions 1, 2, and 3. It then uses a round-robin or sticky strategy to send the message to one of those specific partitions."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"2-achieving-hotspot-prevention--load-balancing",children:"2. Achieving Hotspot Prevention & Load Balancing"}),"\n",(0,s.jsx)(t.p,{children:"Here is the workflow for how the system dynamically adjusts to traffic spikes (Hotspot Prevention):"}),"\n",(0,s.jsx)(t.h4,{id:"step-1-observation-the-metrics",children:"Step 1: Observation (The Metrics)"}),"\n",(0,s.jsx)(t.p,{children:'An external monitoring process (The "Observer") watches the throughput metrics of the topics.'}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.em,{children:"Scenario:"})," ",(0,s.jsx)(t.code,{children:"Tenant_A"})," was small and shared Partition 0 with 50 other tenants. Suddenly, ",(0,s.jsx)(t.code,{children:"Tenant_A"})," starts sending 10,000 events/sec."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.em,{children:"Alert:"})," Partition 0 lag spikes, and the Observer identifies ",(0,s.jsx)(t.code,{children:"Tenant_A"})," as the source of the volume."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-2-decision-the-reassignment",children:"Step 2: Decision (The Reassignment)"}),"\n",(0,s.jsxs)(t.p,{children:["The Observer decides to isolate ",(0,s.jsx)(t.code,{children:"Tenant_A"})," to prevent it from starving the other small tenants on Partition 0."]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"It selects a currently under-utilized partition (e.g., Partition 5)."}),"\n",(0,s.jsxs)(t.li,{children:["It updates the ",(0,s.jsx)(t.strong,{children:"Metadata Store"}),":","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"Tenant_A"})," -> ",(0,s.jsx)(t.code,{children:"Partition 5"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["(Optional) If ",(0,s.jsx)(t.code,{children:"Tenant_A"})," is too big for ",(0,s.jsx)(t.em,{children:"any"})," single partition, the Observer assigns it multiple partitions (",(0,s.jsx)(t.code,{children:"Partition 5, 6, 7"}),")."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-3-propagation",children:"Step 3: Propagation"}),"\n",(0,s.jsx)(t.p,{children:"The Kafka Producers (which are polling the Metadata Store for updates) detect the change. They update their internal routing map."}),"\n",(0,s.jsx)(t.h4,{id:"step-4-execution",children:"Step 4: Execution"}),"\n",(0,s.jsxs)(t.p,{children:["The very next message produced for ",(0,s.jsx)(t.code,{children:"Tenant_A"})," is routed directly to Partition 5. Partition 0 cools down, and the other tenants there return to normal latency."]}),"\n",(0,s.jsx)(t.h3,{id:"3-advanced-strategies-for-elephant-tenants",children:'3. Advanced Strategies for "Elephant" Tenants'}),"\n",(0,s.jsx)(t.p,{children:'The prompt mentions "reassigning tenants." There are two main ways to handle a tenant that becomes too large:'}),"\n",(0,s.jsx)(t.h4,{id:"1-tenant-isolation-dedicated-partition",children:"1. Tenant Isolation (Dedicated Partition)"}),"\n",(0,s.jsx)(t.p,{children:'You give the high-volume tenant their own partition. This ensures their traffic does not impact the "Noisy Neighbor" tenants, and their consumer lag does not delay the processing of other tenants\' data.'}),"\n",(0,s.jsx)(t.h4,{id:"2-tenant-sharding-sub-partitioning",children:"2. Tenant Sharding (Sub-Partitioning)"}),"\n",(0,s.jsx)(t.p,{children:"If a single tenant produces more data than a single partition/consumer can handle (e.g., 50MB/s), mapping them to one partition isn't enough."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Technique:"})," The Metadata Store assigns ",(0,s.jsx)(t.code,{children:"Tenant_Huge"})," to a ",(0,s.jsx)(t.strong,{children:"list"})," of partitions: ",(0,s.jsx)(t.code,{children:"[10, 11, 12]"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Producer Logic:"})," When sending data for ",(0,s.jsx)(t.code,{children:"Tenant_Huge"}),", the producer uses a secondary key (like ",(0,s.jsx)(t.code,{children:"UserID"})," or ",(0,s.jsx)(t.code,{children:"TransactionID"})," within that tenant) to round-robin across partitions 10, 11, and 12. This allows you to consume that single tenant's data in parallel."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"4-critical-challenge-the-ordering-guarantee",children:"4. Critical Challenge: The Ordering Guarantee"}),"\n",(0,s.jsxs)(t.p,{children:["There is a massive trade-off you must manage: ",(0,s.jsx)(t.strong,{children:"Message Ordering."})]}),"\n",(0,s.jsxs)(t.p,{children:["Kafka only guarantees ordering ",(0,s.jsx)(t.em,{children:"within"})," a partition. If you dynamically move ",(0,s.jsx)(t.code,{children:"Tenant_A"})," from Partition 0 to Partition 5:"]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"Messages 1-100 are on Partition 0 (waiting to be consumed)."}),"\n",(0,s.jsx)(t.li,{children:"You switch the map."}),"\n",(0,s.jsx)(t.li,{children:"Message 101 goes to Partition 5."}),"\n",(0,s.jsxs)(t.li,{children:["If the consumer for Partition 5 is faster than the consumer for Partition 0, ",(0,s.jsx)(t.strong,{children:"Message 101 might be processed before Message 100."})]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"How to solve this?"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:'The "Stop-and-Wait" Approach:'})," The system must signal the producer to stop sending data for ",(0,s.jsx)(t.code,{children:"Tenant_A"}),", wait for Partition 0 to be fully consumed (lag = 0), and ",(0,s.jsx)(t.em,{children:"then"})," update the map to point to Partition 5."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Accepting Out-of-Order:"})," For some use cases (e.g., logging), strict ordering isn't required, and you can switch immediately."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"summary-of-components",children:"Summary of Components"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Component"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Responsibility in Dynamic Assignment"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Metrics Collector"})}),(0,s.jsx)(t.td,{children:"Monitors throughput per tenant/partition to detect hotspots."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Control Plane"})}),(0,s.jsx)(t.td,{children:"Calculates fair distribution and updates the Tenant-to-Partition map."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Metadata Store"})}),(0,s.jsx)(t.td,{children:'Holds the "Source of Truth" map (e.g., Zookeeper, Redis).'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:"Smart Producer"})}),(0,s.jsx)(t.td,{children:"Consults the map to route messages to the correct physical partition."})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"links",children:"Links"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://www.jesseyates.com/2020/01/01/high-performance-kafka-producers.html",children:"https://www.jesseyates.com/2020/01/01/high-performance-kafka-producers.html"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://developer.confluent.io/courses/architecture/producer-hands-on/",children:"Tutorial: How to Tune the Kafka Producer Client"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://developer.confluent.io/tutorials/optimize-producer-throughput/confluent.html",children:"How to optimize your Kafka producer for throughput using Confluent"})}),"\n"]})]})}function c(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},131582:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Technologies-Kafka-Kafka-Producers-image1-0d08afe3652975835dcc548e20cbb763.jpg"},174665:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/Technologies-Kafka-Kafka-Producers-image2-9c9a7d875cf3654a315ba265e94f7b5b.jpg"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var i=n(296540);const s={},r=i.createContext(s);function a(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);