"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[31177],{238430:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>c,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"ai/ml-algorithms/id3-c45-and-chaid","title":"ID3, C4.5 and CHAID","description":"CHAID - Chi-Squared Automatic Interaction Detection","source":"@site/docs/ai/ml-algorithms/id3-c45-and-chaid.md","sourceDirName":"ai/ml-algorithms","slug":"/ai/ml-algorithms/id3-c45-and-chaid","permalink":"/ai/ml-algorithms/id3-c45-and-chaid","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/ml-algorithms/id3-c45-and-chaid.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1707138374000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Graph Neural Networks (GNN)","permalink":"/ai/ml-algorithms/graph-neural-networks-gnn"},"next":{"title":"K-Nearest Neighbor (KNN)","permalink":"/ai/ml-algorithms/k-nearest-neighbor-knn"}}');var s=i(474848),r=i(28453);const l={},a="ID3, C4.5 and CHAID",o={},d=[{value:"C4.5 and CHAID Algorithm",id:"c45-and-chaid-algorithm",level:2},{value:"Outline",id:"outline",level:2},{value:"ID3 Algorithm",id:"id3-algorithm",level:2},{value:"C4.5 Algorithm",id:"c45-algorithm",level:2},{value:"Fix overfitting / overleaning problem",id:"fix-overfitting--overleaning-problem",level:2},{value:"Chi-Squared Automatic Interation Detection (CHAID)",id:"chi-squared-automatic-interation-detection-chaid",level:2},{value:"Algorithm",id:"algorithm",level:2}];function h(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"id3-c45-and-chaid",children:"ID3, C4.5 and CHAID"})}),"\n",(0,s.jsx)(n.p,{children:"CHAID - Chi-Squared Automatic Interaction Detection"}),"\n",(0,s.jsx)(n.h2,{id:"c45-and-chaid-algorithm",children:"C4.5 and CHAID Algorithm"}),"\n",(0,s.jsx)(n.h2,{id:"outline",children:"Outline"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Disadvantages of ID3 algorithm"}),"\n",(0,s.jsxs)(n.li,{children:["C4.5 algorithm","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Gain ratio"}),"\n",(0,s.jsx)(n.li,{children:"Noisy data and overfitting"}),"\n",(0,s.jsx)(n.li,{children:"Tree pruning"}),"\n",(0,s.jsx)(n.li,{children:"Handling of missing values"}),"\n",(0,s.jsx)(n.li,{children:"Error estimation"}),"\n",(0,s.jsx)(n.li,{children:"Continuous data"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"CHAID"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"id3-algorithm",children:"ID3 Algorithm"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Top down construction of decision tree by recursively selecting the "best attribute" to use at the current node, based on the training data'}),"\n",(0,s.jsx)(n.li,{children:"It can only deal with nominal data"}),"\n",(0,s.jsx)(n.li,{children:"It is not robust in dealing with noisy data sets"}),"\n",(0,s.jsx)(n.li,{children:"It overfits the tree to the training data"}),"\n",(0,s.jsx)(n.li,{children:"It creates unnessarily complex trees without pruning"}),"\n",(0,s.jsx)(n.li,{children:"It does not handle missing data values well"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"c45-algorithm",children:"C4.5 Algorithm"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"An Improvement over ID3 algorithm"}),"\n",(0,s.jsxs)(n.li,{children:["Designed to handle","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Noisy data better"}),"\n",(0,s.jsx)(n.li,{children:"Missing data"}),"\n",(0,s.jsx)(n.li,{children:"Pre and post pruning of decision trees"}),"\n",(0,s.jsx)(n.li,{children:"Attributes with continuous values"}),"\n",(0,s.jsx)(n.li,{children:"Rule Derivation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"fix-overfitting--overleaning-problem",children:"Fix overfitting / overleaning problem"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Pre-prune: Stop growing a branch when information becomes unrealiable"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Post-prune: Take a fully-grown decision tree and discard unreliable parts"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"chi-squared-automatic-interation-detection-chaid",children:"Chi-Squared Automatic Interation Detection (CHAID)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"It is one of the oldest tree classification methods originally proposed by Kass in 1980"}),"\n",(0,s.jsx)(n.li,{children:"The first step is to create categorical predictors out of any continuous predictors by dividing the respective continuous distributions into a number of categories with an approximately equal number of observations"}),"\n",(0,s.jsx)(n.li,{children:"The next step is to cycle through the predictors to determine for each predictor the pair of (predictor) categories that is least significantly different with respect to the dependent variable"}),"\n",(0,s.jsx)(n.li,{children:"The next step is to choose the split the predictor variable with the smallest adjusted p-value, i.e., the predictor variable that will yield the most significant split"}),"\n",(0,s.jsx)(n.li,{children:"Continue this process until no further splits can be performed"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"algorithm",children:"Algorithm"}),"\n",(0,s.jsx)(n.p,{children:"Dividing the cases that reach a certain node in the tree"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Cross tabulate the response variable (target) with each of the explanatory variables"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"When there are more than two columns, find the best subtable formed by combining column categories"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"This is applied to each table with more than 2 columns"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Compute Pearson X^2^ tests for independence for each allowable subtable"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Look for the smallest X^2^ value. If it is not significant, combine the column categories"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Repeat step 2 if the new table has more than two columns"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Allows categories combined at step 2 to be broken apart"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'For each compound category consisting of at least 3 of the original categories, find the "most signifcant" binary split'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"If X^2^ is significant, implement the split and return to step 2"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Otherwise retain the compound categories for this variable, and move on to the next variable"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'You have now completed the "optimal" combining of categories for each explanatory variable'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Find the most significant of these "optimally" merged explanatory variables'}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Compute a "Bonferroni" adjusted chi-squared test of independence for the reduced table for each explanatory variable'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Use the "most significant" variable in step 4 to split the node with respect to the merged categories for that variable'}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"repeat steps 1-5 for each of the offspring nodes"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Stop if"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"no variable is significant in step 4"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"the number of cases reaching a node is below a specified limit"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"http://www.statsoft.com/textbook/chaid-analysis",children:"http://www.statsoft.com/textbook/chaid-analysis"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"http://www.public.iastate.edu/~kkoehler/stat557/tree14p.pdf",children:"http://www.public.iastate.edu/~kkoehler/stat557/tree14p.pdf"})})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var t=i(296540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);