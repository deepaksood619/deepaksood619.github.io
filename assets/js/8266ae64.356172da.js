"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[92309],{696544:(e,s,i)=>{i.r(s),i.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"technologies/kafka/intro-to-kafka","title":"Intro to Kafka","description":"- Kafka Core is the distributed, durable equivalent of Unix pipes. Use it to connect and compose your large-scale data applications","source":"@site/docs/technologies/kafka/intro-to-kafka.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/intro-to-kafka","permalink":"/technologies/kafka/intro-to-kafka","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/intro-to-kafka.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1739572825000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Installing Kafka","permalink":"/technologies/kafka/installing-kafka"},"next":{"title":"Intro","permalink":"/technologies/kafka/intro"}}');var n=i(474848),t=i(28453);const r={},o="Intro to Kafka",l={},c=[{value:"Characteristics",id:"characteristics",level:2},{value:"History",id:"history",level:2},{value:"Kafka Data Model",id:"kafka-data-model",level:2},{value:"Topics",id:"topics",level:2},{value:"Partitions",id:"partitions",level:2},{value:"Partiton distribution",id:"partiton-distribution",level:3},{value:"Some Major Points to Remember in Topics, Partitions, and Offsets",id:"some-major-points-to-remember-in-topics-partitions-and-offsets",level:2},{value:"Kafka Architecture",id:"kafka-architecture",level:2},{value:"Types of messaging systems",id:"types-of-messaging-systems",level:2},{value:"Brokers",id:"brokers",level:2},{value:"Kafka Guarantees",id:"kafka-guarantees",level:2},{value:"Transactions in Kafka",id:"transactions-in-kafka",level:2},{value:"Replication in Kafka",id:"replication-in-kafka",level:2},{value:"Persistence in Kafka",id:"persistence-in-kafka",level:2},{value:"3 major components",id:"3-major-components",level:2}];function d(e){const s={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.header,{children:(0,n.jsx)(s.h1,{id:"intro-to-kafka",children:"Intro to Kafka"})}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Kafka Core is the distributed, durable equivalent of Unix pipes. Use it to connect and compose your large-scale data applications"}),"\n",(0,n.jsx)(s.li,{children:"Kafka Streams are the commands of your Unix pipelines. Use it to transform data stored in Kafka"}),"\n",(0,n.jsx)(s.li,{children:"Kafka Connect is the I/O redirection in your Unix pipelines. Use it to get your data into an out of Kafka."}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"characteristics",children:"Characteristics"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"It is a distributed and partitioned messaging system"}),"\n",(0,n.jsx)(s.li,{children:"It is highly fault-tolerant"}),"\n",(0,n.jsx)(s.li,{children:"It is highly scalable"}),"\n",(0,n.jsx)(s.li,{children:"It can process and send millions of messages per second to several receivers"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"history",children:"History"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Originally developed by LinkedIn and later, handed over to the open source community in early 2011"}),"\n",(0,n.jsx)(s.li,{children:"It became a main Apache project in October, 2012"}),"\n",(0,n.jsx)(s.li,{children:"A stable Apache Kafka version 0.8.2.0 was release in Feb, 2015."}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"kafka-data-model",children:"Kafka Data Model"}),"\n",(0,n.jsx)(s.p,{children:"The Kafka data model consists of messages and topics"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Messages represent information such as, lines in a log file, a row of stock market data, or an error message from a system"}),"\n",(0,n.jsx)(s.li,{children:"Messages are grouped into categories called topics. Example: LogMessage and Stock Message"}),"\n",(0,n.jsx)(s.li,{children:"The processes that publish messages into a topic in Kafka are known as producers."}),"\n",(0,n.jsx)(s.li,{children:"The processes that receive the messages from a topic in Kafka are known as consumers."}),"\n",(0,n.jsx)(s.li,{children:"The processes or servers within Kafka that process the messages are known as brokers."}),"\n",(0,n.jsx)(s.li,{children:"A Kafka cluster consists of a set of brokers that process the messages"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"topics",children:"Topics"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"A topic is a category of messages in Kafka"}),"\n",(0,n.jsx)(s.li,{children:"The producers publish the messages into topics"}),"\n",(0,n.jsx)(s.li,{children:"The consumers read the messages from topics"}),"\n",(0,n.jsx)(s.li,{children:"A topic is divided into one or more partitions"}),"\n",(0,n.jsx)(s.li,{children:"A partition is also known as a commit log"}),"\n",(0,n.jsx)(s.li,{children:"Each partition contains an ordered set of messages"}),"\n",(0,n.jsx)(s.li,{children:"Each message is identified by its offset in the partition"}),"\n",(0,n.jsx)(s.li,{children:"Messages are added at one end of the partition and consumed at the other"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"partitions",children:"Partitions"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["Topics are divided into partitions, which are the unit of parallelism in Kafka","\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Partitions allow messages in a topic to be distributed to multiple servers"}),"\n",(0,n.jsx)(s.li,{children:"A topic can have any number of partitions"}),"\n",(0,n.jsx)(s.li,{children:"Each partition should fit in a single Kafka server"}),"\n",(0,n.jsx)(s.li,{children:"The number of partitions decide the parallelism of the topic"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(s.h3,{id:"partiton-distribution",children:"Partiton distribution"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Partitions can be distributed across the Kafka cluster"}),"\n",(0,n.jsx)(s.li,{children:"Each Kafka server may handle one or more partitions"}),"\n",(0,n.jsx)(s.li,{children:"A partition can be replicated across serveral servers for fault-tolerance"}),"\n",(0,n.jsx)(s.li,{children:"One server is marked as a leader for the partition and the others are marked as followers"}),"\n",(0,n.jsx)(s.li,{children:"The leader controls the read and write for the partition, whereas the followers replicate the data"}),"\n",(0,n.jsx)(s.li,{children:"If a leader fails, one of the followers automatically become the leader."}),"\n",(0,n.jsx)(s.li,{children:"Zookeeper is used for the leader selection"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"some-major-points-to-remember-in-topics-partitions-and-offsets",children:"Some Major Points to Remember in Topics, Partitions, and Offsets"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Offsets only have a meaning for a specific partition"}),". That means offset number 3 in Partition 0 does not represent the same data or the same message as offset number 3 in partition 1."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Order is going to be guaranteed"})," only from within a partition."]}),"\n",(0,n.jsxs)(s.li,{children:["But across partitions, we have no ordering guarantee. So this is a very important certainty of Kafka is that you\u2019re going to have ",(0,n.jsx)(s.strong,{children:"ordered at the partition level only"}),"."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Data in Kafka by default is kept only for a limited amount of time"})," and the default is one week. That means that after one week the data is going to be erased from a partition and this allows Kafka to keep on renewing its disk and to make sure it does not run out of disk space."]}),"\n",(0,n.jsxs)(s.li,{children:["Kafka is ",(0,n.jsx)(s.strong,{children:"immutable"}),". That means once the data is written into a partition, it cannot be changed. So if you write the message number 3 in partition 0 you cannot overwrite. So as such, you want to be careful about the kind of data you send to a Kafka topic and your recovery mechanism instead of in case you send bad data."]}),"\n",(0,n.jsx)(s.li,{children:"Also if you don\u2019t provide a key to your message, then when you send a message to a Kafka topic the data is going to be assigned to a random partition."}),"\n",(0,n.jsx)(s.li,{children:"Finally, a topic can have as many partitions as you want but it is not common to have topics with say 10, 20, 30, or 1000 partitions unless you have a truly high throughput topic."}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"kafka-architecture",children:"Kafka Architecture"}),"\n",(0,n.jsx)(s.p,{children:"Kafka consists of brokers that take messages from the producers and add to a partition of a topic. Brokers provide the messages to the consumers from the partitions."}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"A topic is divided into multiple partitions"}),"\n",(0,n.jsx)(s.li,{children:"The messages are added to the partitions at one end and consumed in the same order"}),"\n",(0,n.jsx)(s.li,{children:"Each partition acts as a message queue"}),"\n",(0,n.jsx)(s.li,{children:"Consumers are divided into consumer groups"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"types-of-messaging-systems",children:"Types of messaging systems"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Kafka architecture supports the publish-subscribe and queue system"}),"\n",(0,n.jsxs)(s.li,{children:["Publish-subscribe system","\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Each message is received by all the subscribers"}),"\n",(0,n.jsx)(s.li,{children:"Each subscriber receives all the messages"}),"\n",(0,n.jsx)(s.li,{children:"Messages are received in the same order that they are produced"}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(s.li,{children:["Queue system","\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Each message has to be consumed by only one consumer"}),"\n",(0,n.jsx)(s.li,{children:"Each message is consumed by any one of the available consumers"}),"\n",(0,n.jsx)(s.li,{children:"Messages are consumed in the same order that they are received"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{alt:"image",src:i(521757).A+"",width:"1000",height:"750"})}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{alt:"image",src:i(11858).A+"",width:"1000",height:"750"})}),"\n",(0,n.jsx)(s.h2,{id:"brokers",children:"Brokers"}),"\n",(0,n.jsx)(s.p,{children:"Brokers are the Kafka processes that process the messages in Kafka"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Each machine in the cluster can run one broker"}),"\n",(0,n.jsx)(s.li,{children:"They coordinate among each other using Zookeeper"}),"\n",(0,n.jsx)(s.li,{children:"One broker acts as a leader for a partition and handles the delivery and persistence, where as, the others act as followers"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"kafka-guarantees",children:"Kafka Guarantees"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Messages sent by a producer to a topic and a partition are appended in the same order"}),"\n",(0,n.jsx)(s.li,{children:"A consumer instance gets the messages in the same order as they are produced"}),"\n",(0,n.jsx)(s.li,{children:"A topic with replication factor N, tolerates upto N-1 server failures"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"transactions-in-kafka",children:"Transactions in Kafka"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Atomic multi-partition writes"}),"\n",(0,n.jsx)(s.li,{children:"Zombie fencing"}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.a,{href:"https://www.confluent.io/blog/transactions-apache-kafka/",children:"Transactions in Apache Kafka | Confluent"})}),"\n",(0,n.jsx)(s.h2,{id:"replication-in-kafka",children:"Replication in Kafka"}),"\n",(0,n.jsx)(s.p,{children:"Kafka uses the primary-backup method of replication"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"One machine (one replica) is called a leader and is chosen as the primary; the remaining machines (replicas) are chosen as the followers and act as backups"}),"\n",(0,n.jsx)(s.li,{children:"The leader propagates the writes to the followers"}),"\n",(0,n.jsx)(s.li,{children:"The leader waits until the writes are completed on all the replicas"}),"\n",(0,n.jsx)(s.li,{children:"If a replica is down, it is skipped for the write until it comes back"}),"\n",(0,n.jsx)(s.li,{children:"If the leader fails, one of the followers will be chosen as the new leader; this mechanism can tolerate n-1 failures if the replication factor is n"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"persistence-in-kafka",children:"Persistence in Kafka"}),"\n",(0,n.jsx)(s.p,{children:"Kafka uses the Linux file system for persistence of messages"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Persistence ensures no messages are lost"}),"\n",(0,n.jsx)(s.li,{children:"Kafka relies on the file system page cache for fast reads and writes"}),"\n",(0,n.jsx)(s.li,{children:"All the data is immediately written to a file in file system"}),"\n",(0,n.jsx)(s.li,{children:"Messages are grouped as message sets for more efficient writes"}),"\n",(0,n.jsx)(s.li,{children:"Message sets can be compressed to reduce network bandwidth"}),"\n",(0,n.jsx)(s.li,{children:"A standarized binary message format is used among producers, brokers, and consumers to minimize data modification"}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"3-major-components",children:"3 major components"}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Kafka Core:"})," A central hub to transport and store event streams in real-time"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Kafka Connect:"})," A framework to import event streams from other soure data systems into Kafka and export event streams from Kafka to destination data systems"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Kafka Streams:"})," A Java library to process event streams live as they occur"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},521757:(e,s,i)=>{i.d(s,{A:()=>a});const a=i.p+"assets/images/Technologies-Kafka-Intro-to-Kafka-image1-a6cd51e38b71d58188824d87eb9744e2.jpg"},11858:(e,s,i)=>{i.d(s,{A:()=>a});const a=i.p+"assets/images/Technologies-Kafka-Intro-to-Kafka-image2-2bc8a748dda4c5ae0ce16c5956fc1eeb.jpg"},28453:(e,s,i)=>{i.d(s,{R:()=>r,x:()=>o});var a=i(296540);const n={},t=a.createContext(n);function r(e){const s=a.useContext(t);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),a.createElement(t.Provider,{value:s},e.children)}}}]);