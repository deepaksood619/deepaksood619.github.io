"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[10783],{207911:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>l});var i=n(785893),a=n(511151);const s={},o="14. Intro to Bayesian Inference",r={id:"mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference",title:"14. Intro to Bayesian Inference",description:"The power of Bayesian statistics",source:"@site/docs/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference.md",sourceDirName:"mathematics/probability/intro-to-probability",slug:"/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference",permalink:"/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/mathematics/probability/intro-to-probability/14.-intro-to-bayesian-inference.md",tags:[],version:"current",lastUpdatedAt:1707138374,formattedLastUpdatedAt:"Feb 5, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"13. Conditional expectation and variance revisited",permalink:"/mathematics/probability/intro-to-probability/13.-conditional-expectation-and-variance-revisited"},next:{title:"2. Conditioning and Independence",permalink:"/mathematics/probability/intro-to-probability/2.-conditioning-and-independence"}},c={},l=[{value:"The power of Bayesian statistics",id:"the-power-of-bayesian-statistics",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",ul:"ul",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"14-intro-to-bayesian-inference",children:"14. Intro to Bayesian Inference"}),"\n",(0,i.jsx)(t.h2,{id:"the-power-of-bayesian-statistics",children:"The power of Bayesian statistics"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Outcome characterization - This is the distribution of things that happened"}),"\n",(0,i.jsx)(t.li,{children:"Latent factor analysis - These are the things affect your outcome"}),"\n",(0,i.jsx)(t.li,{children:"Decision making - Given all the potential outcomes here's the most optimal choice we should make today"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=pJH_2y9J9-I",children:"https://www.youtube.com/watch?v=pJH_2y9J9-I"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"We apply the Bayes rule to find the posterior distribution of an unknown random variable given one or multiple observations of related random variables."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"We discuss the most common methods for coming up with a point estimate of the unknown random variable (Maximum a Posteriori probability estimate, Least Mean Squares estimate, and Linear Least Mean Squares estimate)."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"We consider the question of performance analysis, namely, the calculation of the probability of error in hypothesis testing problems or the calculation of the mean squared error in estimation problems."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"To illustrate the methodology, we pay special attention to a few canonical problems such as linear normal models and the problem of estimating the unknown bias of a coin."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(514320).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(318562).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(619329).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(766724).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(721062).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(843988).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(29900).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(439973).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(644438).Z+"",width:"1755",height:"987"})}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=HZGCoVF3YvM",children:"Bayes theorem, and making probability intuitive"}),"- Bayes' theorem describe the probability of an event occurring, based upon prior knowledge of other variables related to that event"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"In effect, it is a conditional probability, with the probability of an event conditioned on the information/knowledge you have"}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Since the information/knowledge that different individuals can have about an event can vary, Bayes' thorem allows for differences in probability estimates for the same event across individuals"}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"In Bayesian Inference, you update the probability of an event happening as you receive new evidence or information"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"The probability that you assign to an event before you receive the new information represent your priors"}),"\n",(0,i.jsx)(t.li,{children:"The probability that you assign to that same event after receiving and processing new information represent your posterior estimate"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},514320:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image1-8b988724e8fdbfd6937f8d2c6ddd0dfc.jpg"},318562:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image2-195b4a89d5837b668a2ea003cd0c5d5d.jpg"},619329:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image3-982c3c3a36e7c5a0b8830e8176df0290.jpg"},766724:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image4-b27690b9668f06b2d32b134cc52d19b7.jpg"},721062:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image5-2e80adbe3bdec1c160b436920bd0e4d3.jpg"},843988:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image6-c371c3eeaae3a4c7954f3261b56f5a59.jpg"},29900:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image7-19a3906525edab9683d6fc0d2580252d.jpg"},439973:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image8-9acdf54431eb6112669bd6d5fd837a23.jpg"},644438:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Intro-Syllabus_14.-Intro-to-Bayesian-Inference-image9-26cac48841c8adb1f23e420dc12dfe9e.jpg"},511151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>o});var i=n(667294);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);