"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[6996],{595379:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>A,contentTitle:()=>r,default:()=>c,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"ai/deep-learning/neural-network-and-deep-learning","title":"Neural network and deep learning","description":"Logistic Regression - Binary Classification","source":"@site/docs/ai/deep-learning/neural-network-and-deep-learning.md","sourceDirName":"ai/deep-learning","slug":"/ai/deep-learning/neural-network-and-deep-learning","permalink":"/ai/deep-learning/neural-network-and-deep-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/deep-learning/neural-network-and-deep-learning.md","tags":[],"version":"current","lastUpdatedBy":"Deeapak Sood","lastUpdatedAt":1765917138000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"DL Specialization","permalink":"/ai/deep-learning/dl-specialization"},"next":{"title":"Others","permalink":"/ai/deep-learning/others"}}');var t=n(474848),s=n(28453);const o={},r="Neural network and deep learning",A={},d=[{value:"Logistic Regression - Binary Classification",id:"logistic-regression---binary-classification",level:2},{value:"Notation",id:"notation",level:2},{value:"Logistic Regression cost function",id:"logistic-regression-cost-function",level:2},{value:"Gradient Descent",id:"gradient-descent",level:2},{value:"Intuition about derivatives",id:"intuition-about-derivatives",level:2},{value:"Computation Graph",id:"computation-graph",level:2},{value:"Derivatives with a computation graph",id:"derivatives-with-a-computation-graph",level:2},{value:"Logistic Regression Gradient Descent",id:"logistic-regression-gradient-descent",level:2},{value:"Logistic regression derivatives",id:"logistic-regression-derivatives",level:2},{value:"Gradient Descent on m examples",id:"gradient-descent-on-m-examples",level:2},{value:"Derivation of dL/dz",id:"derivation-of-dldz",level:2},{value:"Vectorization",id:"vectorization",level:2},{value:"Python and Vectorization",id:"python-and-vectorization",level:2},{value:"Example",id:"example",level:2},{value:"Neural network programming guideline",id:"neural-network-programming-guideline",level:2},{value:"Vectors and matrix valued functions",id:"vectors-and-matrix-valued-functions",level:2},{value:"Logistic regression derivatives",id:"logistic-regression-derivatives-1",level:2},{value:"Vectorizing Logistic Regression",id:"vectorizing-logistic-regression",level:2},{value:"Forward propagation",id:"forward-propagation",level:2},{value:"Vectorizing Logistic Regression&#39;s Gradient Output",id:"vectorizing-logistic-regressions-gradient-output",level:2},{value:"Broadcasting in Python",id:"broadcasting-in-python",level:2},{value:"Logistic Regression cost function",id:"logistic-regression-cost-function-1",level:2},{value:"IID - Identically Independently Distributed",id:"iid---identically-independently-distributed",level:2},{value:"Programming Assignment 1",id:"programming-assignment-1",level:2},{value:"L1 Loss",id:"l1-loss",level:2}];function l(e){const i={a:"a",code:"code",del:"del",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"neural-network-and-deep-learning",children:"Neural network and deep learning"})}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression---binary-classification",children:"Logistic Regression - Binary Classification"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(959967).A+"",width:"999",height:"537"})}),"\n",(0,t.jsx)(i.p,{children:"And so we're going to use nx=12288to represent the dimension of the input features x.And sometimes for brevity, I will also just use lowercase nto represent the dimension of this input feature vector."}),"\n",(0,t.jsx)(i.h2,{id:"notation",children:"Notation"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(876240).A+"",width:"999",height:"531"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(843514).A+"",width:"1000",height:"589"})}),"\n",(0,t.jsx)(i.p,{children:"What are the parameters of Logistic Regression"}),"\n",(0,t.jsxs)(i.p,{children:["W, an n",(0,t.jsx)(i.del,{children:"x"})," dimensional vector, and b, a real number."]}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression-cost-function",children:"Logistic Regression cost function"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(421286).A+"",width:"998",height:"469"})}),"\n",(0,t.jsx)(i.p,{children:"What is the difference between the cost function and the loss function for logistic regression?"}),"\n",(0,t.jsx)(i.p,{children:"The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set."}),"\n",(0,t.jsx)(i.h2,{id:"gradient-descent",children:"Gradient Descent"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(311395).A+"",width:"998",height:"436"})}),"\n",(0,t.jsx)(i.p,{children:"A Convex function only have 1 local optima"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(365332).A+"",width:"999",height:"546"})}),"\n",(0,t.jsx)(i.h2,{id:"intuition-about-derivatives",children:"Intuition about derivatives"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(337137).A+"",width:"999",height:"458"})}),"\n",(0,t.jsxs)(i.p,{children:["On a straight line, the function's derivative ",(0,t.jsx)(i.strong,{children:"doesn't change"})]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(966026).A+"",width:"999",height:"517"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(933767).A+"",width:"998",height:"520"})}),"\n",(0,t.jsx)(i.h2,{id:"computation-graph",children:"Computation Graph"}),"\n",(0,t.jsx)(i.p,{children:"The computations of a neural network are organized in terms of a forward pass or a forward propagation step, in which we compute the output of the neural network, followed by a backward pass or back propagation step, which we use to compute gradients or compute derivatives. The computation graph explains why it is organized this way."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(958415).A+"",width:"999",height:"443"})}),"\n",(0,t.jsxs)(i.p,{children:["One step of ",(0,t.jsx)(i.strong,{children:"backward"})," propagation on a computation graph yields derivative of final output variable."]}),"\n",(0,t.jsx)(i.h2,{id:"derivatives-with-a-computation-graph",children:"Derivatives with a computation graph"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(882034).A+"",width:"998",height:"526"})}),"\n",(0,t.jsx)(i.p,{children:"What does the coding convention dvar represent?"}),"\n",(0,t.jsx)(i.p,{children:"The derivative of a final output variable with respect to various intermediate quantities."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(900989).A+"",width:"998",height:"490"})}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression-gradient-descent",children:"Logistic Regression Gradient Descent"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(175424).A+"",width:"998",height:"485"})}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression-derivatives",children:"Logistic regression derivatives"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(715731).A+"",width:"998",height:"422"})}),"\n",(0,t.jsx)(i.p,{children:"What is the simplified formula for the derivative of the losswith respect to z?"}),"\n",(0,t.jsx)(i.p,{children:"a - y"}),"\n",(0,t.jsx)(i.h2,{id:"gradient-descent-on-m-examples",children:"Gradient Descent on m examples"}),"\n",(0,t.jsx)(i.p,{children:"Cost- function w, b, which you care about is this average,1/m sum from i equals one through m ofthe loss when you algorithm output a_i on the example y, where a_i is the prediction on the ith training example which is sigma of z_i, which is equal to sigma of w transpose x_i plus b."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(560470).A+"",width:"999",height:"381"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(293729).A+"",width:"999",height:"539"})}),"\n",(0,t.jsx)(i.p,{children:"In the for loop depicted in the video, why is there only one dw variable (i.e. no i superscripts in the for loop)?"}),"\n",(0,t.jsx)(i.p,{children:"The value of dw in the code is cumulative."}),"\n",(0,t.jsx)(i.h2,{id:"derivation-of-dldz",children:"Derivation of dL/dz"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/2/threads/ysF-gYfISSGBfoGHyLkhYg",children:"https://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/2/threads/ysF-gYfISSGBfoGHyLkhYg"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e",children:"https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e"})}),"\n",(0,t.jsx)(i.h2,{id:"vectorization",children:"Vectorization"}),"\n",(0,t.jsx)(i.p,{children:"When you're implementing deep learning algorithms, you find that having explicit for loops inyour code makes your algorithm run less efficiency.So, in the deep learning era, we would move to a bigger and bigger datasets, and so being able to implement your algorithms without using explicitfor loops is really important and will help you to scale to much bigger datasets."}),"\n",(0,t.jsx)(i.p,{children:"So, it turns out that there are a set of techniques called vectorizationtechniques that allow you to get rid of these explicit for-loops in your code.I think in the pre-deep learning era, that's before the rise of deep learning, vectorization was a nice to have, so you could sometimes do it to speed up your code and sometimes not.But in the deep learning era, vectorization, that is getting rid of for loops, has become really important, because we're more and more training on very large datasets, and so you really need your code to be very efficient."}),"\n",(0,t.jsx)(i.h2,{id:"python-and-vectorization",children:"Python and Vectorization"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(615684).A+"",width:"1000",height:"474"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.code,{children:"Z = W^T^X + b"})}),"\n",(0,t.jsx)(i.h2,{id:"example",children:"Example"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'import time\n\na = np.random.rand(1000000)\nb = np.random.rand(1000000)\n\ntic = time.time()\nc = np.dot(a, b)\ntoc = time.time()\n\nprint(c)\nprint(f"Vectorized version {1000*(toc-tic)} ms")\n\nc = 0\ntic = time.time()\nfor i in range(1000000):\n    c += a[i]*b[i]\n\ntoc = time.time()\n\nprint(c)\nprint(f"For loop {1000*(toc-tic)} ms")\n'})}),"\n",(0,t.jsx)(i.h2,{id:"neural-network-programming-guideline",children:"Neural network programming guideline"}),"\n",(0,t.jsx)(i.p,{children:"Whenever possible, avoid explicit for-loops"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(203895).A+"",width:"1000",height:"457"})}),"\n",(0,t.jsx)(i.h2,{id:"vectors-and-matrix-valued-functions",children:"Vectors and matrix valued functions"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(732730).A+"",width:"1000",height:"465"})}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression-derivatives-1",children:"Logistic regression derivatives"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(982346).A+"",width:"999",height:"461"})}),"\n",(0,t.jsx)(i.h2,{id:"vectorizing-logistic-regression",children:"Vectorizing Logistic Regression"}),"\n",(0,t.jsx)(i.h2,{id:"forward-propagation",children:"Forward propagation"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(433735).A+"",width:"998",height:"456"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.code,{children:"Size of matrix X - (n~x~ , m)"})}),"\n",(0,t.jsx)(i.h2,{id:"vectorizing-logistic-regressions-gradient-output",children:"Vectorizing Logistic Regression's Gradient Output"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(153752).A+"",width:"998",height:"544"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(58069).A+"",width:"998",height:"525"})}),"\n",(0,t.jsxs)(i.p,{children:["How do you compute the derivative of ",(0,t.jsx)(i.em,{children:"b"})," in one line of code in Python numpy?"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.code,{children:"1 / m*(np.sum(dz))"})}),"\n",(0,t.jsx)(i.h2,{id:"broadcasting-in-python",children:"Broadcasting in Python"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(538798).A+"",width:"998",height:"322"})}),"\n",(0,t.jsx)(i.p,{children:"Calculate % of calories from carb, protein, fat, without explicit for loop?"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"cal = A.sum(axis = 0)\npercentage = 100*A / (cal.reshape(1, 4))\nmatrix (3, 4) / matrix (1, 4)\n"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(216843).A+"",width:"999",height:"548"})}),"\n",(0,t.jsx)(i.h2,{id:"logistic-regression-cost-function-1",children:"Logistic Regression cost function"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(832188).A+"",width:"999",height:"537"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(302713).A+"",width:"999",height:"510"})}),"\n",(0,t.jsx)(i.h2,{id:"iid---identically-independently-distributed",children:"IID - Identically Independently Distributed"}),"\n",(0,t.jsxs)(i.p,{children:["True or False: Minimizing the loss corresponds with maximizing logp(y|x) - ",(0,t.jsx)(i.strong,{children:"True"})]}),"\n",(0,t.jsx)(i.h2,{id:"programming-assignment-1",children:"Programming Assignment 1"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:'We rarely use the "math" library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful.'}),"\n",(0,t.jsx)(i.li,{children:"sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is:"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.code,{children:"sigmoid_derivative(x)=\u03c3\u2032(x)=\u03c3(x)(1\u2212\u03c3(x))"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Another common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean changing x tox/\u2225x\u2225(dividing each row vector of x by its norm)."}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"For example, if"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(268226).A+"",width:"912",height:"402"})}),"\n",(0,t.jsx)(i.p,{children:"Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. Normalization is also required for some algorithms to model the data correctly."}),"\n",(0,t.jsx)(i.p,{children:"For example, assume your input dataset contains one column with values ranging from 0 to 1, and another column with values ranging from 10,000 to 100,000. The great difference in thescaleof the numbers could cause problems when you attempt to combine the values as features during modeling."}),"\n",(0,t.jsx)(i.p,{children:"Normalizationavoids these problems by creating new values that maintain the general distribution and ratios in the source data, while keeping values within a scale applied across all numeric columns used in the model."}),"\n",(0,t.jsx)(i.h2,{id:"l1-loss",children:"L1 Loss"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"The loss is used to evaluate the performance of your model. The bigger your loss is, the more different your predictions (y\u0302y^) are from the true values (yy). In deep learning, you use optimization algorithms like Gradient Descent to train your model and to minimize the cost."}),"\n",(0,t.jsx)(i.li,{children:"L1 loss is defined as:"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(459935).A+"",width:"362",height:"96"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"L2 loss is defined as:"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"image",src:n(509441).A+"",width:"376",height:"112"})})]})}function c(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},959967:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image1-4b95dbac2bb48d77544d8ce3ec0f4b68.jpg"},958415:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image10-7a28ef0875260240ba471b74f9624317.jpg"},882034:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image11-7796f54ef4b8890808b90a9af8689205.jpg"},900989:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image12-4e6d6fd2a7236f0cea1a6acc5d4b9101.jpg"},175424:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image13-137fd40326d502d1d80060260b970600.jpg"},715731:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image14-1fd870954d544baeb856ba62aa27ae92.jpg"},560470:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image15-0ef27dd4f90981bd9e8c9b0d25986767.jpg"},293729:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image16-8972aec0d1f6a72bbdad37fe89197358.jpg"},615684:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image17-4f75e6fad185b321bc8661adf1dcf22c.jpg"},203895:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image18-1a846d5838acf4501b585228f1bf41c6.jpg"},732730:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image19-a93bd34595c155f059713256ab54737a.jpg"},876240:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image2-a41dd14e5345b0769ff35d3e50d3f668.jpg"},982346:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image20-91902b045d3b2a2dd72bfe648b065396.jpg"},433735:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image21-9941b8b579dc09e5b71d8d531d8c3a08.jpg"},153752:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image22-c44b5a15409bf1693ea279a3ca53ee79.jpg"},58069:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image23-a6afcd8b5fa79c0cb32e2d95ce009a95.jpg"},538798:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image24-de85b1e14e14e7a341c1225008a65f1d.jpg"},216843:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image25-fbf2c15f58dbc435fb322d87357c2e88.jpg"},832188:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image26-7e705df39ae37237af80142c70a4bf4b.jpg"},302713:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image27-a0efe66e1ba36429fd032c90551f2122.jpg"},268226:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image28-90e2f38ddbb5a3410cc97a27e44a064e.jpg"},459935:(e,i,n)=>{n.d(i,{A:()=>a});const a="data:image/jpeg;base64,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"},843514:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image3-9101fec770a9786db0a5385095355fdd.jpg"},509441:(e,i,n)=>{n.d(i,{A:()=>a});const a="data:image/jpeg;base64,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"},421286:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image4-6227fb9ab7701f3779bac48b2fa18975.jpg"},311395:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image5-3eba824c1575e7a0e4a162acc84005c3.jpg"},365332:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image6-348bd2694213d22bf637e1dae6b70f9f.jpg"},337137:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image7-9fdefa5455b0663162a29bc173df2253.jpg"},966026:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image8-572e38d84a1abd56193aeb643960e1f4.jpg"},933767:(e,i,n)=>{n.d(i,{A:()=>a});const a=n.p+"assets/images/DL-Specialization_Neural-network-and-deep-learning-image9-93f0e4afe310e4e77b4e5f38fede7c48.jpg"},28453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>r});var a=n(296540);const t={},s=a.createContext(t);function o(e){const i=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),a.createElement(s.Provider,{value:i},e.children)}}}]);