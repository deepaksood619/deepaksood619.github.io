"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[66013],{940154:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>d,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"ai/nlp/nltk","title":"NLTK","description":"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing.","source":"@site/docs/ai/nlp/nltk.md","sourceDirName":"ai/nlp","slug":"/ai/nlp/nltk","permalink":"/ai/nlp/nltk","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/nlp/nltk.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1701793554000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"NLP Concepts","permalink":"/ai/nlp/nlp-concepts"},"next":{"title":"Word Embedding to Transformers","permalink":"/ai/nlp/word-embedding-to-transformers"}}');var i=n(474848),r=n(28453);const d={},o="NLTK",c={},l=[{value:"Commands",id:"commands",level:2},{value:"NLTK&#39;s Frequency Distributionss",id:"nltks-frequency-distributionss",level:3},{value:"Corpus",id:"corpus",level:3},{value:"Others",id:"others",level:2},{value:"python - indian-namematch 1.3.0",id:"python---indian-namematch-130",level:3}];function a(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"nltk",children:"NLTK"})}),"\n",(0,i.jsx)(t.p,{children:"NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing."}),"\n",(0,i.jsxs)(t.p,{children:["NLTK supports classification, tokenization, stemming ",(0,i.jsx)(t.strong,{children:"(lemmatization better than stemming)"}),", tagging, parsing, and semantic reasoning functionalities."]}),"\n",(0,i.jsx)(t.p,{children:"Library highlights"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Lexical_analysis",children:"Lexical analysis"}),": Word and text tokenizer"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/N-gram",children:"n-gram"})," and collocations"]}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Part-of-speech_tagging",children:"Part-of-speech tagger"})}),"\n",(0,i.jsxs)(t.li,{children:["Tree model and Text",(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Chunking_(computational_linguistics)",children:"chunker"})," for capturing"]}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Named-entity_recognition",children:"Named-entity recognition"})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"commands",children:"Commands"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import nltk\nnltk.download()\n\nfrom nltk.book import *\ntext1\nlen(text6)\ntexts()\nsents()\n    The sents() function divides the text up into its sentences, where each sentence is a list of words\n\ntext1.concordance("monstrous") #A concordance view shows us every occurrence of a given word, together with some context\ntext2.similar("monstrous")\ntext2.common_contexts(["monstrous", "very"])\ntext4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])\ntext6.dispersion_plot(["Arthur", "Holy", "Grail"])\ntext6.generate()\ntext6.count("Grail")\ntext6.count("grail")\nfdist1 = FreqDist(text1)\nfdist1.most_common(50)\nfdist1.plot(50, cumulative=True)\n\ncfd = nltk.ConditionalFreqDist(\n...           (genre, word)\n...           for genre in brown.categories()\n...           for word in brown.words(categories=genre))\ngenres = [\'news\', \'religion\', \'hobbies\', \'science_fiction\', \'romance\', \'humor\']\nmodals = [\'can\', \'could\', \'may\', \'might\', \'must\', \'will\']\ncfd.tabulate(conditions=genres, samples=modals)\n'})}),"\n",(0,i.jsx)(t.h3,{id:"nltks-frequency-distributionss",children:"NLTK's Frequency Distributionss"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Example"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Description"})})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist = FreqDist(samples)"}),(0,i.jsx)(t.td,{children:"create a frequency distribution containing the given samples"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist[sample] += 1"}),(0,i.jsx)(t.td,{children:"increment the count for this sample"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist['monstrous']"}),(0,i.jsx)(t.td,{children:"count of the number of times a given sample occurred"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.freq('monstrous')"}),(0,i.jsx)(t.td,{children:"frequency of a given sample"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.N()"}),(0,i.jsx)(t.td,{children:"total number of samples"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.most_common(n)"}),(0,i.jsx)(t.td,{children:"the n most common samples and their frequencies"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"for sample in fdist:"}),(0,i.jsx)(t.td,{children:"iterate over the samples"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.max()"}),(0,i.jsx)(t.td,{children:"sample with the greatest count"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.tabulate()"}),(0,i.jsx)(t.td,{children:"tabulate the frequency distribution"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.plot()"}),(0,i.jsx)(t.td,{children:"graphical plot of the frequency distribution"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist.plot(cumulative=True)"}),(0,i.jsx)(t.td,{children:"cumulative plot of the frequency distribution"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist1"}),(0,i.jsx)(t.td,{children:"= fdist2"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fdist1 < fdist2"}),(0,i.jsx)(t.td,{children:"test if samples in fdist1 occur less frequently than in fdist2"})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"corpus",children:"Corpus"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"nltk.chat.chatbots()\nnltk.corpus.gutenberg.fileids()\nemma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\nlen(gutenberg.raw('austen-emma.txt'))\n    The raw() function gives us the contents of the file without any linguistic processing.\n\nfrom nltk.corpus import webtext\nwebtext.fileids()\n\nfrom nltk.corpus import nps_chat\nnps_chat.posts('10-19-20s_706posts.xml')\n\nThe Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics.\nfirst million-word electronic corpus of English\nfrom nltk.corpus import brown\nbrown.categories()\nbrown.words(categories='news')\nbrown.words(fileids=['cg22'])\nbrown.sents(categories=['news', 'editorial', 'reviews'])\n\nfrom nltk.corpus import reuters\nreuters.fileids()\nreuters.categories()\nreuters.categories(['training/9865', 'training/9880'])\n\nfrom nltk.corpus import inaugural\ninaugural.fileids()\ncfd = nltk.ConditionalFreqDist(\n...           (target, fileid[:4])\n...           for fileid in inaugural.fileids()\n...           for w in inaugural.words(fileid)\n...           for target in ['america', 'citizen']\n...           if w.lower().startswith(target))\ncfd.plot()\nnltk.corpus.indian.words('hindi.pos')\nnltk.corpus.cess_esp.words()\nnltk.corpus.floresta.words()\nnltk.corpus.udhr.fileids() #univeral declaration of human rights in 300 languages\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"image",src:n(660494).A+"",width:"997",height:"222"})}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Example"})}),(0,i.jsx)(t.th,{children:(0,i.jsx)(t.strong,{children:"Description"})})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fileids()"}),(0,i.jsx)(t.td,{children:"the files of the corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"fileids([categories])"}),(0,i.jsx)(t.td,{children:"the files of the corpus corresponding to these categories"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"categories()"}),(0,i.jsx)(t.td,{children:"the categories of the corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"categories([fileids])"}),(0,i.jsx)(t.td,{children:"the categories of the corpus corresponding to these files"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"raw()"}),(0,i.jsx)(t.td,{children:"the raw content of the corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"raw(fileids=[f1,f2,f3])"}),(0,i.jsx)(t.td,{children:"the raw content of the specified files"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"raw(categories=[c1,c2])"}),(0,i.jsx)(t.td,{children:"the raw content of the specified categories"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"words()"}),(0,i.jsx)(t.td,{children:"the words of the whole corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"words(fileids=[f1,f2,f3])"}),(0,i.jsx)(t.td,{children:"the words of the specified fileids"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"words(categories=[c1,c2])"}),(0,i.jsx)(t.td,{children:"the words of the specified categories"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"sents()"}),(0,i.jsx)(t.td,{children:"the sentences of the whole corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"sents(fileids=[f1,f2,f3])"}),(0,i.jsx)(t.td,{children:"the sentences of the specified fileids"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"sents(categories=[c1,c2])"}),(0,i.jsx)(t.td,{children:"the sentences of the specified categories"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"abspath(fileid)"}),(0,i.jsx)(t.td,{children:"the location of the given file on disk"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"encoding(fileid)"}),(0,i.jsx)(t.td,{children:"the encoding of the file (if known)"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"open(fileid)"}),(0,i.jsx)(t.td,{children:"open a stream for reading the given corpus file"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"root"}),(0,i.jsx)(t.td,{children:"if the path to the root of locally installed corpus"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"readme()"}),(0,i.jsx)(t.td,{children:"if the path to the root of locally installed corpus the contents of the README file of the corpus"})]})]})]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://github.com/nltk/nltk",children:"https://github.com/nltk/nltk"})}),"\n",(0,i.jsx)(t.h2,{id:"others",children:"Others"}),"\n",(0,i.jsx)(t.h3,{id:"python---indian-namematch-130",children:"python - indian-namematch 1.3.0"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://pypi.org/project/indian-namematch",children:"https://pypi.org/project/indian-namematch"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e",children:"https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e"})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},660494:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/NLP_NLTK-image1-e596fb2f4177950811573ba7004a684b.jpg"},28453:(e,t,n)=>{n.d(t,{R:()=>d,x:()=>o});var s=n(296540);const i={},r=s.createContext(i);function d(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:d(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);