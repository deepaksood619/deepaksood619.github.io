"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[70827],{741504:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"ai/move-37/readme","title":"Move37","description":"- Syllabus","source":"@site/docs/ai/move-37/readme.md","sourceDirName":"ai/move-37","slug":"/ai/move-37/","permalink":"/ai/move-37/","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/move-37/readme.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1706776448000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Others","permalink":"/ai/model-evaluation/others"},"next":{"title":"1. Markov Decision Process","permalink":"/ai/move-37/1-markov-decision-process"}}');var s=r(474848),o=r(28453);const t={},a="Move37",l={},c=[];function d(e){const n={a:"a",h1:"h1",header:"header",li:"li",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"move37",children:"Move37"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai/move-37/syllabus",children:"Syllabus"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"1-markov-decision-process",children:"Markov Decision Process"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"2-dynamic-programming",children:"Dynamic Programming"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"3-monte-carlo-methods",children:"Monte Carlo Methods"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"4-model-free-learning",children:"Model Free Learning"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"5-rl-in-continuous-space",children:"RL in Continuous Space"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"algorithms",children:"Algorithms"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"quizzes",children:"Quizzes"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"reinforcement-learning",children:"Reinforcement Learning"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"q-learning-algorithms",children:"Q-Learning Algorithms"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"open-ai-gym",children:"Open AI Gym"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai/move-37/others",children:"Others"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>a});var i=r(296540);const s={},o=i.createContext(s);function t(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);