"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[79948],{718858:(i,e,t)=>{t.r(e),t.d(e,{assets:()=>h,contentTitle:()=>o,default:()=>l,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"mathematics/statistics/nonparametric-statistics","title":"Nonparametric Statistics","description":"Nonparametric statisticsis the branch of statistics that is not based solely on parametrized families of probability distributions(common examples of parameters are the mean and variance). Nonparametric statistics is based on either being distribution-free or having a specified distribution but with the distribution\'s parameters unspecified. Nonparametric statistics includes both descriptive statistics and statistical inference.","source":"@site/docs/mathematics/statistics/nonparametric-statistics.md","sourceDirName":"mathematics/statistics","slug":"/mathematics/statistics/nonparametric-statistics","permalink":"/mathematics/statistics/nonparametric-statistics","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/mathematics/statistics/nonparametric-statistics.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1701793554000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Intro","permalink":"/mathematics/statistics/intro"},"next":{"title":"Other Statistics","permalink":"/mathematics/statistics/other-statistics"}}');var a=t(474848),n=t(28453);const r={},o="Nonparametric Statistics",h={},d=[{value:"Non-parametric models",id:"non-parametric-models",level:2},{value:"Methods",id:"methods",level:2}];function c(i){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...i.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"nonparametric-statistics",children:"Nonparametric Statistics"})}),"\n",(0,a.jsxs)(e.p,{children:["Nonparametric statisticsis the branch of ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistics",children:"statistics"})," that is not based solely on ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistical_parameter",children:"parametrized"})," families of ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Probability_distribution",children:"probability distributions"}),"(common examples of parameters are the mean and variance). Nonparametric statistics is based on either being distribution-free or having a specified distribution but with the distribution's parameters unspecified. Nonparametric statistics includes both ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Descriptive_statistics",children:"descriptive statistics"})," and ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistical_inference",children:"statistical inference"}),"."]}),"\n",(0,a.jsx)(e.h2,{id:"non-parametric-models",children:"Non-parametric models"}),"\n",(0,a.jsxs)(e.p,{children:["Non-parametric modelsdiffer from ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Parametric_statistics",children:"parametric"})," models in that the model structure is not specifieda prioribut is instead determined from data. The termnon-parametricis not meant to imply that such models completely lack parameters but that the number and nature of the parameters are flexible and not fixed in advance."]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["A ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Histogram",children:"histogram"})," is a simple nonparametric estimate of a probability distribution."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.strong,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kernel_density_estimation",children:"Kernel density estimation"}),"(KDE)"]})," provides better estimates of the density than histograms."]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["In ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistics",children:"statistics"}),", kernel density estimation(KDE) is a ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Non-parametric_statistics",children:"non-parametric"})," way to ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Density_estimation",children:"estimate"})," the ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Probability_density_function",children:"probability density function"})," of a ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Random_variable",children:"random variable"}),". Kernel density estimation is a fundamental data smoothing problem where inferences about the ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistical_population",children:"population"})," are made, based on a finite data ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Statistical_sample",children:"sample"}),". In some fields such as ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Signal_processing",children:"signal processing"})," and ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Econometrics",children:"econometrics"})," it is also termed the ",(0,a.jsx)(e.strong,{children:"Parzen--Rosenblatt window"})," method, after ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Emanuel_Parzen",children:"Emanuel Parzen"})," and ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Murray_Rosenblatt",children:"Murray Rosenblatt"}),", who are usually credited with independently creating it in its current form.One of the famous applications of kernel density estimation is in estimating the class-conditional marginal densities of data when using a ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Naive_Bayes_classifier",children:"naive Bayes classifier"}),", which can improve its prediction accuracy.- ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Nonparametric_regression",children:"Nonparametric regression"})," and ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Semiparametric_regression",children:"semiparametric regression"})," methods have been developed based on ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kernel_(statistics)",children:"kernels"}),", ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Spline_(mathematics)",children:"splines"}),", and ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Wavelet",children:"wavelets"}),"."]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Data_envelopment_analysis",children:"Data envelopment analysis"})," provides efficiency coefficients similar to those obtained by ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Multivariate_analysis",children:"multivariate analysis"})," without any distributional assumption."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm",children:"KNNs"})," classify the unseen instance based on the K points in the training set which are nearest to it."]}),"\n",(0,a.jsxs)(e.li,{children:["A ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Support_vector_machine",children:"support vector machine"}),"(with a Gaussian kernel) is a nonparametric large-margin classifier."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Method_of_moments_(statistics)",children:"Method of moments (statistics)"})," with polynomial probability distributions."]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"methods",children:"Methods"}),"\n",(0,a.jsxs)(e.p,{children:["Non-parametric(ordistribution-free)inferential statistical methodsare mathematical procedures for statistical hypothesis testing which, unlike ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Parametric_statistics",children:"parametric statistics"}),", make no assumptions about the ",(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Probability_distribution",children:"probability distributions"})," of the variables being assessed. The most frequently used tests include"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Analysis_of_similarities",children:"Analysis of similarities"})}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test",children:"Anderson--Darling test"}),": tests whether a sample is drawn from a given distribution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Bootstrapping_(statistics)",children:"Statistical bootstrap methods"}),": estimates the accuracy/sampling distribution of a statistic"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Cochran%27s_Q_test",children:"Cochran's Q"}),": tests whetherktreatments in randomized block designs with 0/1 outcomes have identical effects"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Cohen%27s_kappa",children:"Cohen's kappa"}),": measures inter-rater agreement for categorical items"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Friedman_test",children:"Friedman two-way analysis of variance"})," by ranks: tests whetherktreatments in randomized block designs have identical effects"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator",children:"Kaplan--Meier"}),": estimates the survival function from lifetime data, modeling censoring"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kendall_tau_rank_correlation_coefficient",children:"Kendall's tau"}),": measures statistical dependence between two variables"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kendall%27s_W",children:"Kendall's W"}),": a measure between 0 and 1 of inter-rater agreement"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test",children:"Kolmogorov--Smirnov test"}),": tests whether a sample is drawn from a given distribution, or whether two samples are drawn from the same distribution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance",children:"Kruskal--Wallis one-way analysis of variance"})," by ranks: tests whether >2 independent samples are drawn from the same distribution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Kuiper%27s_test",children:"Kuiper's test"}),": tests whether a sample is drawn from a given distribution, sensitive to cyclic variations such as day of the week"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Logrank_test",children:"Logrank test"}),": compares survival distributions of two right-skewed, censored samples"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U",children:"Mann--Whitney U"})," or Wilcoxon rank sum test: tests whether two samples are drawn from the same distribution, as compared to a given alternative hypothesis."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/McNemar%27s_test",children:"McNemar's test"}),": tests whether, in 2 \xd7 2 contingency tables with a dichotomous trait and matched pairs of subjects, row and column marginal frequencies are equal"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Median_test",children:"Median test"}),": tests whether two samples are drawn from distributions with equal medians"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Pitman_permutation_test",children:"Pitman's permutation test"}),": a statistical significance test that yields exactpvalues by examining all possible rearrangements of labels"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Rank_product",children:"Rank products"}),": detects differentially expressed genes in replicated microarray experiments"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Siegel%E2%80%93Tukey_test",children:"Siegel--Tukey test"}),": tests for differences in scale between two groups"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Sign_test",children:"Sign test"}),": tests whether matched pair samples are drawn from distributions with equal medians"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient",children:"Spearman's rank correlation coefficient"}),": measures statistical dependence between two variables using a monotonic function"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Squared_ranks_test",children:"Squared ranks test"}),": tests equality of variances in two or more samples"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Tukey%E2%80%93Duckworth_test",children:"Tukey--Duckworth test"}),": tests equality of two distributions by using ranks"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test",children:"Wald--Wolfowitz runs test"}),": tests whether the elements of a sequence are mutually independent/random"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test",children:"Wilcoxon signed-rank test"}),": tests whether matched pair samples are drawn from populations with different mean ranks"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Nonparametric_statistics",children:"https://en.wikipedia.org/wiki/Nonparametric_statistics"})})]})}function l(i={}){const{wrapper:e}={...(0,n.R)(),...i.components};return e?(0,a.jsx)(e,{...i,children:(0,a.jsx)(c,{...i})}):c(i)}},28453:(i,e,t)=>{t.d(e,{R:()=>r,x:()=>o});var s=t(296540);const a={},n=s.createContext(a);function r(i){const e=s.useContext(n);return s.useMemo((function(){return"function"==typeof i?i(e):{...e,...i}}),[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(a):i.components||a:r(i.components),s.createElement(n.Provider,{value:e},i.children)}}}]);