"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[31703],{469329:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var i=a(785893),n=a(511151);const s={},r="Delta Lake",o={id:"networking/others/delta-lake",title:"Delta Lake",description:"Delta Lake is an open-source storage framework that enables building a Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.",source:"@site/docs/networking/others/delta-lake.md",sourceDirName:"networking/others",slug:"/networking/others/delta-lake",permalink:"/networking/others/delta-lake",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/networking/others/delta-lake.md",tags:[],version:"current",lastUpdatedAt:1710702797,formattedLastUpdatedAt:"Mar 17, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Delta Lake Tutorial",permalink:"/networking/others/delta-lake-tutorial"},next:{title:"Falcor",permalink:"/networking/others/falcor"}},l={},c=[{value:"Concurrency control",id:"concurrency-control",level:2},{value:"Delta Lake Transaction Log",id:"delta-lake-transaction-log",level:2},{value:"Selectively overwrite data with Delta Lake",id:"selectively-overwrite-data-with-delta-lake",level:2},{value:"Dynamic partition overwrites",id:"dynamic-partition-overwrites",level:3},{value:"Partitioning best practice",id:"partitioning-best-practice",level:3},{value:"Unoptimized updates",id:"unoptimized-updates",level:4},{value:"Excessive partitioning",id:"excessive-partitioning",level:4},{value:"The deadly combination",id:"the-deadly-combination",level:4},{value:"Vacuum",id:"vacuum",level:2},{value:"Clone",id:"clone",level:2},{value:"Constraints",id:"constraints",level:2},{value:"Feature Compatibility",id:"feature-compatibility",level:2},{value:"Deletion Vectors",id:"deletion-vectors",level:2},{value:"Others",id:"others",level:2},{value:"FAQs",id:"faqs",level:2},{value:"What format does Delta Lake use to store data?",id:"what-format-does-delta-lake-use-to-store-data",level:3},{value:"Apache Hudi vs Delta Lake vs Apache Iceberg",id:"apache-hudi-vs-delta-lake-vs-apache-iceberg",level:3}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"delta-lake",children:"Delta Lake"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf",children:"Delta Lake"})," is an open-source storage framework that enables building a ",(0,i.jsx)(t.a,{href:"http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf",children:"Lakehouse architecture"})," with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Open Format Storage Layer"}),"\n",(0,i.jsx)(t.li,{children:"Built on Parquet"}),"\n",(0,i.jsx)(t.li,{children:"Enables ACID Transactions"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://delta.io/",children:"Home | Delta Lake"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/index.html",children:"Welcome to the Delta Lake documentation - Delta Lake Documentation"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/index.html",children:"What is Delta Lake? | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"concurrency-control",children:"Concurrency control"}),"\n",(0,i.jsx)(t.p,{children:"Delta Lake provides ACID transaction guarantees between reads and writes. This means that:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["For supported ",(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/delta-storage.html",children:"storage systems"}),", multiple writers across multiple clusters can simultaneously modify a table partition and see a consistent snapshot view of the table and there will be a serial order for these writes."]}),"\n",(0,i.jsx)(t.li,{children:"Readers continue to see a consistent snapshot view of the table that the Apache Spark job started with, even when a table is modified during a job."}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/concurrency-control.html#optimistic-concurrency-control",children:"Optimistic concurrency control"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/concurrency-control.html#write-conflicts",children:"Write conflicts"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/concurrency-control.html#avoid-conflicts-using-partitioning-and-disjoint-command-conditions",children:"Avoid conflicts using partitioning and disjoint command conditions"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://docs.delta.io/latest/concurrency-control.html#conflict-exceptions",children:"Conflict exceptions"})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"delta-lake-transaction-log",children:"Delta Lake Transaction Log"}),"\n",(0,i.jsxs)(t.p,{children:["The Delta Lake transaction log (also known as the ",(0,i.jsx)(t.code,{children:"DeltaLog"}),") is an ordered record of every transaction that has ever been performed on a Delta Lake table since its inception."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"What the transaction log is, how it\u2019s structured, and how commits are stored as files on disk."}),"\n",(0,i.jsx)(t.li,{children:"How the transaction log serves as a single source of truth, allowing Delta Lake to implement the principle of atomicity."}),"\n",(0,i.jsx)(t.li,{children:"How Delta Lake computes the state of each table - including how it uses the transaction log to catch up from the most recent checkpoint."}),"\n",(0,i.jsx)(t.li,{children:"Using optimistic concurrency control to allow multiple concurrent reads and writes even as tables change."}),"\n",(0,i.jsx)(t.li,{children:"How Delta Lake uses mutual exclusion to ensure that commits are serialized properly, and how they are retried silently in the event of a conflict."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.a,{href:"https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html",children:"Understanding the Delta Lake Transaction Log - Databricks Blog"})})}),"\n",(0,i.jsx)(t.h2,{id:"selectively-overwrite-data-with-delta-lake",children:"Selectively overwrite data with Delta Lake"}),"\n",(0,i.jsx)(t.p,{children:"Databricks leverages Delta Lake functionality to support two distinct options for selective overwrites:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"replaceWhere"})," option atomically replaces all records that match a given predicate."]}),"\n",(0,i.jsxs)(t.li,{children:["You can replace directories of data based on how tables are partitioned using ",(0,i.jsx)(t.strong,{children:"dynamic partition overwrites"}),"."]}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:'-- overwrite only writes those partitions that have been updated,\ntable_df_parent.write.format("delta")\n.mode("overwrite")\n.partitionBy("snapshotDate")\n.option("replaceWhere", f"snapshotDate=\'{run_date}\'")\n.saveAsTable(f"{uc_target_table_name_monthly}")\n'})}),"\n",(0,i.jsx)(t.h3,{id:"dynamic-partition-overwrites",children:"Dynamic partition overwrites"}),"\n",(0,i.jsxs)(t.p,{children:["When in dynamic partition overwrite mode, operations overwrite all existing data in each logical partition for which the write commits new data. Any existing logical partitions for which the write does not contain data remain unchanged. This mode is only applicable when data is being written in overwrite mode: either ",(0,i.jsx)(t.code,{children:"INSERT OVERWRITE"})," in SQL, or a DataFrame write with ",(0,i.jsx)(t.code,{children:'df.write.mode("overwrite")'}),"."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/selective-overwrite.html",children:"Selectively overwrite data with Delta Lake | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h3,{id:"partitioning-best-practice",children:"Partitioning best practice"}),"\n",(0,i.jsxs)(t.p,{children:["Data in Spark is ideally stored in a smaller number of large files between ",(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/optimizations/auto-optimize.html",children:"128MB and 1GB in size"}),". This allows the driver and workers to operate efficiently. Having the data fragmented into many small files will slow down reading of the Delta store and will overload the driver memory as it attempts to load metadata for many small files into memory at once."]}),"\n",(0,i.jsx)(t.p,{children:"There are two causes of file fragmentation - unoptimized updates and excessive partitioning."}),"\n",(0,i.jsx)(t.h4,{id:"unoptimized-updates",children:"Unoptimized updates"}),"\n",(0,i.jsx)(t.p,{children:"In a continuously streaming Delta stream, data is added in small chunks over time as it streams in in a series of micro batches. With default configuration this will cause the creation of a huge number of small files."}),"\n",(0,i.jsx)(t.h4,{id:"excessive-partitioning",children:"Excessive partitioning"}),"\n",(0,i.jsx)(t.p,{children:"If a data column with high ordinality (many discrete values) is chosen as a partition, the Delta store can end up with thousands of partitions. This makes the data look tidy in the file store but causes each micro batch of data to be split into many small files."}),"\n",(0,i.jsx)(t.h4,{id:"the-deadly-combination",children:"The deadly combination"}),"\n",(0,i.jsx)(t.p,{children:"If a stream has unoptimized updates and excessive partitioning, then the two factors multiply. A delta store organised this way can easily end up with millions of small fragmented files (the number of partitions times the number of tiny updates per partition)."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://medium.com/nintex-developers/databricks-delta-partitioning-best-practice-c19df9c8a7d2",children:"Databricks Delta - Partitioning best practice | by gregzrichardson | Nintex Developers | Medium"})}),"\n",(0,i.jsx)(t.h2,{id:"vacuum",children:"Vacuum"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/vacuum.html",children:"Remove unused data files with vacuum | Databricks on AWS"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:"VACUUM cake.dev.transactions;\n\nVACUUM cake.dev.transactions RETAIN 168 HOURS;\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/sql/language-manual/delta-vacuum.html",children:"VACUUM | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"clone",children:"Clone"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:"CREATE TABLE target_schema.gold.target_table_name CLONE source_schema.gold.source_table_name;\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/clone.html",children:"Clone a table on Databricks | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"constraints",children:"Constraints"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/tables/constraints.html",children:"Constraints on Databricks | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"feature-compatibility",children:"Feature Compatibility"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/en/delta/feature-compatibility.html",children:"How does Databricks manage Delta Lake feature compatibility? | Databricks on AWS"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:"-- For enabling drop and rename columns command\n\nALTER TABLE table_name SET TBLPROPERTIES (\n'delta.columnMapping.mode' = 'name',\n'delta.minReaderVersion' = '2',\n'delta.minWriterVersion' = '5');\n"})}),"\n",(0,i.jsx)(t.h2,{id:"deletion-vectors",children:"Deletion Vectors"}),"\n",(0,i.jsxs)(t.p,{children:["Deletion vectors are a storage optimization feature that can be enabled on Delta Lake tables. By default, when a single row in a data file is deleted, the entire Parquet file containing the record must be rewritten. With deletion vectors enabled for the table,\xa0",(0,i.jsx)(t.code,{children:"DELETE"}),"\xa0operations use deletion vectors to mark existing rows as removed without rewriting the Parquet file. Subsequent reads on the table resolve current table state by applying the deletions noted by deletion vectors to the most recent table version."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/en/delta/deletion-vectors.html",children:"What are deletion vectors? | Databricks on AWS"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/en/optimizations/predictive-io.html",children:"What is predictive I/O? | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"others",children:"Others"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://docs.databricks.com/delta/feature-compatibility.html",children:"How does Databricks manage Delta Lake feature compatibility? | Databricks on AWS"})}),"\n",(0,i.jsx)(t.h2,{id:"faqs",children:"FAQs"}),"\n",(0,i.jsx)(t.h3,{id:"what-format-does-delta-lake-use-to-store-data",children:"What format does Delta Lake use to store data?"}),"\n",(0,i.jsx)(t.p,{children:"Delta Lake uses versioned Parquet files to store your data in your cloud storage. Apart from the versions, Delta Lake also stores a transaction log to keep track of all the commits made to the table or blob store directory to provide ACID transactions."}),"\n",(0,i.jsx)(t.h3,{id:"apache-hudi-vs-delta-lake-vs-apache-iceberg",children:"Apache Hudi vs Delta Lake vs Apache Iceberg"}),"\n",(0,i.jsx)(t.p,{children:"Delta outperformed Iceberg and Hudi in loading and querying the data."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://databeans-blogs.medium.com/delta-vs-iceberg-vs-hudi-reassessing-performance-cb8157005eb0",children:"Delta vs Iceberg vs hudi : Reassessing Performance | by DataBeans | Medium"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://www.databricks.com/session_na20/a-thorough-comparison-of-delta-lake-iceberg-and-hudi",children:"A Thorough Comparison of Delta Lake, Iceberg and Hudi - Databricks"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison",children:"Apache Hudi vs Delta Lake vs Apache Iceberg - Lakehouse Feature Comparison"})})]})}function h(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},511151:(e,t,a)=>{a.d(t,{Z:()=>o,a:()=>r});var i=a(667294);const n={},s=i.createContext(n);function r(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);