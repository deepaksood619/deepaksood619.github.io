"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[5634],{548167:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"technologies/kafka/confluent-kafka","title":"confluent-kafka","description":"Confluent kafka-python","source":"@site/docs/technologies/kafka/confluent-kafka.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/confluent-kafka","permalink":"/technologies/kafka/confluent-kafka","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/confluent-kafka.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1729278358000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka","permalink":"/technologies/kafka/"},"next":{"title":"Installing Kafka","permalink":"/technologies/kafka/installing-kafka"}}');var a=t(474848),r=t(28453);const s={},i="confluent-kafka",l={},c=[{value:"Confluent kafka-python",id:"confluent-kafka-python",level:2},{value:"Consumer",id:"consumer",level:2},{value:"Producer",id:"producer",level:2},{value:"Others",id:"others",level:2},{value:"Resources",id:"resources",level:2}];function f(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"confluent-kafka",children:"confluent-kafka"})}),"\n",(0,a.jsx)(n.h2,{id:"confluent-kafka-python",children:"Confluent kafka-python"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'pip install confluent-kafka\npip install "confluent-kafka [avro]"\n'})}),"\n",(0,a.jsx)(n.h2,{id:"consumer",children:"Consumer"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from confluent_kafka import Consumer, KafkaError\n\nconsumer_config = {\n    'bootstrap.servers': 'my-cluster-kafka-brokers.kafka:9092',\n    'partition.assignment.strategy': 'roundrobin',\n    'group.id': 'test_bank_data_consumer',\n    'auto.offset.reset': 'earliest',  # earliest/latest\n    'enable.auto.commit': 'false',\n    # for limiting the amount of messages pre-fetched by librdkafka\n    'queued.max.messages.kbytes': '32000',\n    'fetch.message.max.bytes': '15728640',\n}\n\nc = Consumer(consumer_config)\n\n# callbacks\ndef print_on_assign(consumer, partitions):\n    logging.info(f'Assignment: {partitions}')\n\n    for partition in partitions:\n        logging.info(f'watermark: {c.get_watermark_offsets(partition=partition)}')\n\n    logging.info(f'committed offsets for all partitions: {c.committed(partitions=partitions)}')\n\n    logging.info(f'position: {c.position(partitions=partitions)}')\n\ndef print_on_revoke(consumer, partitions):\n    logging.info(f'Revoke Assignment: {partitions}')\n\nc.subscribe(['bank_data'], on_assign=print_on_assign, on_revoke=print_on_revoke)\n\ntimeout_seconds = 1\n\nwhile True:\n    msg = c.poll(1.0)\n\n    # initial error handling\n    if msg is None:\n        continue\n\n    if msg.error():\n        if msg.error().code() == KafkaError._PARTITION_EOF:\n            continue\n        else:\n            logging.error(f'druid consumer error: {msg.error()}')\n            break\n\n    logging.debug(f'{msg.topic()} [{msg.partition()}] at offset {msg.offset()}')\n\n    try:\n        # get value from message and convert bytes\n        final_data = msg.value()\n        final_data = json.loads(final_data.decode('utf-8'))\n        c.commit()\n\n    except Exception as e:\n        try:\n            logging.error(f'data/msg: {msg.value()}')\n        except Exception:\n            logging.exception(f'cannot print data')\n        logging.exception(\n            f'global exception occurred, Will not attempt for another {timeout_seconds} seconds.')\n    else:\n        continue\n\n    # exponential back-off if exception occurred\n    time.sleep(timeout_seconds)\n    timeout_seconds *= 2\n"})}),"\n",(0,a.jsx)(n.h2,{id:"producer",children:"Producer"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from confluent_kafka import Producer\n\np = Producer({\n    'bootstrap.servers': 'my-cluster-kafka-brokers.kafka:9092',\n    'queue.buffering.max.messages': '1000000',\n    'queue.buffering.max.kbytes': '1048576',\n    'message.max.bytes': '15728640',\n    'delivery.timeout.ms': '10000',\n    'request.timeout.ms': '5000'\n})\n\ndef delivery_report(err, msg):\n    \"\"\" Called once for each message produced to indicate delivery result.\n        Triggered by poll() or flush(). \"\"\"\n    if err is not None:\n        # raise error and handle using exception\n        logging.exception(f'kafka deliver_report error: {err}')\n    else:\n        logging.debug(f'Message delivered topic: {msg.topic()} partition: {msg.partition()} offset: {msg.offset()}')\n\np.produce('bank_data', json.dumps(payload), callback=delivery_report)\np.flush()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"others",children:"Others"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://www.confluent.io/blog/cloud-native-data-streaming-kafka-engine/",children:"Kora: The Cloud Native Engine for Apache Kafka"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://github.com/confluentinc/confluent-kafka-python",children:"https://github.com/confluentinc/confluent-kafka-python"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.confluent.io/current/clients/confluent-kafka-python",children:"https://docs.confluent.io/current/clients/confluent-kafka-python"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION",children:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://towardsdatascience.com/3-libraries-you-should-know-to-master-apache-kafka-in-python-c95fdf8700f2",children:"https://towardsdatascience.com/3-libraries-you-should-know-to-master-apache-kafka-in-python-c95fdf8700f2"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/security/authentication/ldap/client-authentication-ldap.html",children:"Configure Kafka clients for LDAP Authentication in Confluent Platform | Confluent Documentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.confluent.io/cloud/current/clusters/cluster-types.html",children:"Confluent Cloud Cluster Types | Confluent Documentation"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(f,{...e})}):f(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var o=t(296540);const a={},r=o.createContext(a);function s(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);