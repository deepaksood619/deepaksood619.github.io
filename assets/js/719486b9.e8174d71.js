"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[41510],{372111:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>d});var t=i(785893),r=i(511151);const s={},l="ID3, C4.5 and CHAID",a={id:"ai/ml-algorithms/id3-c45-and-chaid",title:"ID3, C4.5 and CHAID",description:"CHAID - Chi-Squared Automatic Interaction Detection",source:"@site/docs/ai/ml-algorithms/id3-c45-and-chaid.md",sourceDirName:"ai/ml-algorithms",slug:"/ai/ml-algorithms/id3-c45-and-chaid",permalink:"/ai/ml-algorithms/id3-c45-and-chaid",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/ml-algorithms/id3-c45-and-chaid.md",tags:[],version:"current",lastUpdatedAt:1707138374,formattedLastUpdatedAt:"Feb 5, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Graph Neural Networks (GNN)",permalink:"/ai/ml-algorithms/graph-neural-networks-gnn"},next:{title:"K-Nearest Neighbor (KNN)",permalink:"/ai/ml-algorithms/k-nearest-neighbor-knn"}},o={},d=[{value:"C4.5 and CHAID Algorithm",id:"c45-and-chaid-algorithm",level:2},{value:"Outline",id:"outline",level:2},{value:"ID3 Algorithm",id:"id3-algorithm",level:2},{value:"C4.5 Algorithm",id:"c45-algorithm",level:2},{value:"Fix overfitting / overleaning problem",id:"fix-overfitting--overleaning-problem",level:2},{value:"Chi-Squared Automatic Interation Detection (CHAID)",id:"chi-squared-automatic-interation-detection-chaid",level:2},{value:"Algorithm",id:"algorithm",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"id3-c45-and-chaid",children:"ID3, C4.5 and CHAID"}),"\n",(0,t.jsx)(n.p,{children:"CHAID - Chi-Squared Automatic Interaction Detection"}),"\n",(0,t.jsx)(n.h2,{id:"c45-and-chaid-algorithm",children:"C4.5 and CHAID Algorithm"}),"\n",(0,t.jsx)(n.h2,{id:"outline",children:"Outline"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Disadvantages of ID3 algorithm"}),"\n",(0,t.jsxs)(n.li,{children:["C4.5 algorithm","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Gain ratio"}),"\n",(0,t.jsx)(n.li,{children:"Noisy data and overfitting"}),"\n",(0,t.jsx)(n.li,{children:"Tree pruning"}),"\n",(0,t.jsx)(n.li,{children:"Handling of missing values"}),"\n",(0,t.jsx)(n.li,{children:"Error estimation"}),"\n",(0,t.jsx)(n.li,{children:"Continuous data"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"CHAID"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"id3-algorithm",children:"ID3 Algorithm"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Top down construction of decision tree by recursively selecting the "best attribute" to use at the current node, based on the training data'}),"\n",(0,t.jsx)(n.li,{children:"It can only deal with nominal data"}),"\n",(0,t.jsx)(n.li,{children:"It is not robust in dealing with noisy data sets"}),"\n",(0,t.jsx)(n.li,{children:"It overfits the tree to the training data"}),"\n",(0,t.jsx)(n.li,{children:"It creates unnessarily complex trees without pruning"}),"\n",(0,t.jsx)(n.li,{children:"It does not handle missing data values well"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"c45-algorithm",children:"C4.5 Algorithm"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"An Improvement over ID3 algorithm"}),"\n",(0,t.jsxs)(n.li,{children:["Designed to handle","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Noisy data better"}),"\n",(0,t.jsx)(n.li,{children:"Missing data"}),"\n",(0,t.jsx)(n.li,{children:"Pre and post pruning of decision trees"}),"\n",(0,t.jsx)(n.li,{children:"Attributes with continuous values"}),"\n",(0,t.jsx)(n.li,{children:"Rule Derivation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"fix-overfitting--overleaning-problem",children:"Fix overfitting / overleaning problem"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Pre-prune: Stop growing a branch when information becomes unrealiable"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Post-prune: Take a fully-grown decision tree and discard unreliable parts"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"chi-squared-automatic-interation-detection-chaid",children:"Chi-Squared Automatic Interation Detection (CHAID)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"It is one of the oldest tree classification methods originally proposed by Kass in 1980"}),"\n",(0,t.jsx)(n.li,{children:"The first step is to create categorical predictors out of any continuous predictors by dividing the respective continuous distributions into a number of categories with an approximately equal number of observations"}),"\n",(0,t.jsx)(n.li,{children:"The next step is to cycle through the predictors to determine for each predictor the pair of (predictor) categories that is least significantly different with respect to the dependent variable"}),"\n",(0,t.jsx)(n.li,{children:"The next step is to choose the split the predictor variable with the smallest adjusted p-value, i.e., the predictor variable that will yield the most significant split"}),"\n",(0,t.jsx)(n.li,{children:"Continue this process until no further splits can be performed"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"algorithm",children:"Algorithm"}),"\n",(0,t.jsx)(n.p,{children:"Dividing the cases that reach a certain node in the tree"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Cross tabulate the response variable (target) with each of the explanatory variables"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"When there are more than two columns, find the best subtable formed by combining column categories"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This is applied to each table with more than 2 columns"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Compute Pearson X^2^ tests for independence for each allowable subtable"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Look for the smallest X^2^ value. If it is not significant, combine the column categories"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Repeat step 2 if the new table has more than two columns"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Allows categories combined at step 2 to be broken apart"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'For each compound category consisting of at least 3 of the original categories, find the "most signifcant" binary split'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"If X^2^ is significant, implement the split and return to step 2"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Otherwise retain the compound categories for this variable, and move on to the next variable"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'You have now completed the "optimal" combining of categories for each explanatory variable'}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Find the most significant of these "optimally" merged explanatory variables'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Compute a "Bonferroni" adjusted chi-squared test of independence for the reduced table for each explanatory variable'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Use the "most significant" variable in step 4 to split the node with respect to the merged categories for that variable'}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"repeat steps 1-5 for each of the offspring nodes"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Stop if"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"no variable is significant in step 4"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"the number of cases reaching a node is below a specified limit"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"http://www.statsoft.com/textbook/chaid-analysis",children:"http://www.statsoft.com/textbook/chaid-analysis"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"http://www.public.iastate.edu/~kkoehler/stat557/tree14p.pdf",children:"http://www.public.iastate.edu/~kkoehler/stat557/tree14p.pdf"})})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},511151:(e,n,i)=>{i.d(n,{Z:()=>a,a:()=>l});var t=i(667294);const r={},s=t.createContext(r);function l(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);