"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[48376],{564580:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"technologies/flink/architecture-key-components","title":"Architecture and Key Components","description":"The diagram below shows the\xa0Flink components\xa0as well as the Flink runtime flow. The program code or SQL query is composed into an operator graph which is then submitted by the client to a job manager. The job manager breaks the job into operators which execute as tasks on nodes that are running task managers. These tasks process streaming data and interact with various data sources, such as the Hadoop Distributed File System (HDFS) and Apache Kafka.","source":"@site/docs/technologies/flink/architecture-key-components.md","sourceDirName":"technologies/flink","slug":"/technologies/flink/architecture-key-components","permalink":"/technologies/flink/architecture-key-components","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/flink/architecture-key-components.md","tags":[],"version":"current","lastUpdatedBy":"Deeapak Sood","lastUpdatedAt":1766218856000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Apache Flink","permalink":"/technologies/flink/"},"next":{"title":"Challenges","permalink":"/technologies/flink/challenges"}}');var i=t(474848),o=t(28453);const r={},a="Architecture and Key Components",l={},h=[{value:"Flink Components",id:"flink-components",level:2},{value:"External Components\xa0(all optional)",id:"external-componentsall-optional",level:2},{value:"Workflow",id:"workflow",level:2},{value:"Putting it all together",id:"putting-it-all-together",level:3},{value:"Links",id:"links",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"architecture-and-key-components",children:"Architecture and Key Components"})}),"\n",(0,i.jsxs)(n.p,{children:["The diagram below shows the\xa0",(0,i.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/flink/concepts/flink.html",children:"Flink components"}),"\xa0as well as the Flink runtime flow. The program code or SQL query is composed into an operator graph which is then submitted by the client to a job manager. The job manager breaks the job into operators which execute as tasks on nodes that are running task managers. These tasks process streaming data and interact with various data sources, such as the Hadoop Distributed File System (HDFS) and Apache Kafka."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Architecture and Key Components",src:t(887596).A+"",width:"835",height:"567"})}),"\n",(0,i.jsxs)(n.p,{children:["The figure below shows the building blocks of every Flink cluster. ",(0,i.jsx)(n.strong,{children:"There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a JobGraph and submits it to the JobManager."})]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"JobManager distributes the work onto the TaskManagers"}),", where the actual operators (such as sources, transformations and sinks) are running."]}),"\n",(0,i.jsx)(n.p,{children:"When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Flink Components",src:t(303348).A+"",width:"697",height:"354"})}),"\n",(0,i.jsx)(n.h2,{id:"flink-components",children:"Flink Components"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Purpose"}),(0,i.jsx)(n.th,{children:"Implementations"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Flink Client"}),(0,i.jsx)(n.td,{children:"Compiles batch or streaming applications into a dataflow graph, which it then submits to the JobManager."}),(0,i.jsxs)(n.td,{children:["- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/cli/",children:"Command Line Interface"}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/ops/rest_api/",children:"REST Endpoint"}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/sqlclient/",children:"SQL Client"}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/repls/python_shell/",children:"Python REPL"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"JobManager"}),(0,i.jsxs)(n.td,{children:["JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes.",(0,i.jsx)("br",{}),"JobManager\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/#deployment-modes",children:"modes for job submissions"}),":",(0,i.jsx)("br",{}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.strong,{children:"Application Mode"}),": runs the cluster exclusively for one application. The job's main method (or client) gets executed on the JobManager. Calling ",(0,i.jsx)(n.code,{children:"execute"}),"/",(0,i.jsx)(n.code,{children:"executeAsync"})," multiple times in an application is supported.",(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.strong,{children:"Per-Job Mode"}),": runs the cluster exclusively for one job. The job's main method (or client) runs only prior to the cluster creation.",(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.strong,{children:"Session Mode"}),": one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers"]}),(0,i.jsxs)(n.td,{children:["- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/overview/",children:"Standalone"}),"\xa0(this is the barebone mode that requires just JVMs to be launched. Deployment with\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/docker/",children:"Docker, Docker Swarm / Compose"}),",\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/kubernetes/",children:"non-native Kubernetes"}),"\xa0and other models is possible through manual setup in this mode)",(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/native_kubernetes/",children:"Kubernetes"}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/yarn/",children:"YARN"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TaskManager"}),(0,i.jsx)(n.td,{children:"TaskManagers are the services actually performing the work of a Flink job."}),(0,i.jsx)(n.td,{})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"external-componentsall-optional",children:"External Components\xa0(all optional)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Purpose"}),(0,i.jsx)(n.th,{children:"Implementations"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"High Availability Service Provider"}),(0,i.jsx)(n.td,{children:"Flink's JobManager can be run in high availability mode which allows Flink to recover from JobManager faults. In order to failover faster, multiple standby JobManagers can be started to act as backups."}),(0,i.jsxs)(n.td,{children:["- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/ha/zookeeper_ha/",children:"Zookeeper"}),(0,i.jsx)("br",{}),"- ",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/ha/kubernetes_ha/",children:"Kubernetes HA"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"File Storage and Persistency"}),(0,i.jsx)(n.td,{children:"For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems"}),(0,i.jsxs)(n.td,{children:["See\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/filesystems/overview/",children:"FileSystems"}),"\xa0page."]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Resource Provider"}),(0,i.jsx)(n.td,{children:"Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes or YARN."}),(0,i.jsxs)(n.td,{children:["See\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/#jmimpls",children:"JobManager"}),"\xa0implementations above."]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Metrics Storage"}),(0,i.jsx)(n.td,{children:"Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well."}),(0,i.jsxs)(n.td,{children:["See\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/metric_reporters/",children:"Metrics Reporter"}),"\xa0page."]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Application-level data sources and sinks"}),(0,i.jsx)(n.td,{children:"While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits"}),(0,i.jsxs)(n.td,{children:["For example:",(0,i.jsx)("br",{}),(0,i.jsx)("br",{}),"- Apache Kafka",(0,i.jsx)("br",{}),"- Amazon S3",(0,i.jsx)("br",{}),"- Elasticsearch",(0,i.jsx)("br",{}),"- Apache Cassandra",(0,i.jsx)("br",{}),(0,i.jsx)("br",{}),"See\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/datastream/overview/",children:"Connectors"}),"\xa0page."]})]})]})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/",children:"Overview | Apache Flink"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/sqlclient/",children:"Apache Flink - SQL Client"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"workflow",children:"Workflow"}),"\n",(0,i.jsx)(n.p,{children:"Apache Flink is extensively used for stream processing. In a simple Flink application, you define \u2014"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"One or more sources from where the data will be ingested."}),"\n",(0,i.jsx)(n.li,{children:"A series of operations on the data \u2014Both Stateful and stateless computations"}),"\n",(0,i.jsx)(n.li,{children:"Degree of parallelism for the operations to speed up the computation"}),"\n",(0,i.jsx)(n.li,{children:"One or more sinks to send the output of the computation"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here are a few of the important aspects that need to be understood to be able to start understanding how Flink manages and executed the application \u2014"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"In a Flink program, you define the data source/s, specify the operations on the input data, define the flow of data between the operators, and egress it to one or more sinks."}),"\n",(0,i.jsx)(n.li,{children:"Flink has its optimizer that optimizes the application from the execution efficiency perspective."}),"\n",(0,i.jsx)(n.li,{children:"Flink application will be converted into a \u201cDataflow graph\u201d and will be submitted to the Flink cluster for execution."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:700/1*rtt5hRAm4M3O3SeeYhiQRw.png",alt:"Flink application will be submitted to the Cluster for execution as a Job"})}),"\n",(0,i.jsxs)(n.p,{children:["Let\u2019s try to understand that what will the Job consist of that is submitted to the Flink cluster. It is not that complicated. It is a directed graph that consists of Nodes (nothing but the Operators or Tasks) and edges (defines inputs/outputs and relationship between nodes). So,\xa0",(0,i.jsx)(n.strong,{children:"Flink cluster should be able to provide some way to accept & execute the tasks the way it is submitted as part of the Job"}),". Consider this as our first requirement from the Flink Cluster."]}),"\n",(0,i.jsxs)(n.p,{children:["Flink supports distributed processing and horizontal scaling. So,\xa0",(0,i.jsx)(n.strong,{children:"Flink cluster should be able to support distributed processing and horizontal scaling."}),"\xa0Consider this as our second requirement from the Flink Cluster."]}),"\n",(0,i.jsx)(n.p,{children:"Considering the about requirements from the Flink cluster, it has two types of components \u2014"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Job manager \u2014"})," Accepts the task (Can be one or more)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Task manager \u2014"})," Executes the tasks (Can be one or more)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:544/1*HClBFUPLNGVOu1OmaXPSoA.png",alt:"Components of Flink Cluster"})}),"\n",(0,i.jsx)(n.p,{children:"Let\u2019s talk about the Job manager first. Here is the list of responsibilities of the Job manager-"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Its primary function is to accept the task from the Client and manage the execution of the job graph. A Flink cluster can be used for the execution of more than one Job Graph."}),"\n",(0,i.jsx)(n.li,{children:"It also manages the cluster of Task managers."}),"\n",(0,i.jsx)(n.li,{children:"Fault tolerance"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Considering the above responsibilities, Job manager has the following sub-components \u2014"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dispatcher"}),"\xa0\u2014 Provide an interface to submit a Job graph and starts a new Job master for each submitted job."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Job master"}),"\xa0\u2014 Responsible for managing the execution of the single job graph."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resource manager / Task scheduler"}),"\u2014 For managing the Task managers and assigning the tasks to the task managers for execution."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Checkpoint coordinator"}),"\xa0\u2014 To enable fault tolerance."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:458/1*xVDj_h8Ag2ecqymf-HuKHw.png",alt:"Job manager"})}),"\n",(0,i.jsx)(n.p,{children:"The responsibility of the task manager is to provide the resources for the execution of the tasks in the Flink Job. There might be multiple nodes as Task manager in the Flink cluster. Task manager nodes are also called \u201cWorker nodes\u201d. The smallest unit of resource scheduling in a Task Manager is a \u201cTask Slot\u201d. A Task manager can have one or more Task Slots. Task Scheduler in the Job Manager, schedules the task of a Flink Job using the Task slot."}),"\n",(0,i.jsx)(n.p,{children:"Task manager also contains the components that are responsible for memory management among the Task slots. Since the tasks of a Flink Job can be distributed to multiple task managers hence there has to be a network manager to coordinate and communicate data flow among the Task manager nodes."}),"\n",(0,i.jsx)(n.p,{children:"Task manager sends the Task status, Heartbeats, and various statistics to the Job Manager periodically for it to manage the cluster effectively."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:489/1*oeu6KkAwiLszkaxL29FSug.png",alt:"Task manager"})}),"\n",(0,i.jsx)(n.h3,{id:"putting-it-all-together",children:"Putting it all together"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Flink application has one or more sources (data source), a series of operations, and one or more sinks."}),"\n",(0,i.jsx)(n.li,{children:"Flink application is represented as a Job graph, where the nodes are the operators and links determine the input and output, to and from various operators."}),"\n",(0,i.jsx)(n.li,{children:"Flink Job is submitted as a Dataflow graph (Job graph)to the Job Manager."}),"\n",(0,i.jsx)(n.li,{children:"Task manager has one or more Task slots that provide an execution environment to the tasks."}),"\n",(0,i.jsx)(n.li,{children:"Job manager schedules the tasks from the Job graph to one more Task slots in the Task managers."}),"\n",(0,i.jsx)(n.li,{children:"Multiple tasks can be submitted to a Job Manager which creates a Job master for each of the submitted jobs."}),"\n",(0,i.jsx)(n.li,{children:"Job master also takes the responsibility of providing the Fault tolerance abilities using the checkpoint coordinator."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://miro.medium.com/v2/resize:fit:493/1*XNON5yC7PE2oGV41u1p2ig.png",alt:"Apache Flink Architecture"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://harshit-sharma.medium.com/understanding-apache-flink-architecture-and-its-components-ee7c67b1ab7d",children:"Understanding Apache Flink architecture and its components | by Harshit Sharma | Medium"})}),"\n",(0,i.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.confluent.io/learn/apache-flink/",children:"What Is Apache Flink\xae? Architecture & Use Cases | Confluent"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/flink/concepts/flink.html",children:"Understand Apache Flink | Confluent Documentation"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},887596:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/Screenshot 2025-12-16 at 10.43.13 PM-c28d04815471aaff51389c4d6b683aba.png"},303348:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/Screenshot 2025-12-16 at 10.49.46 PM-3c502be7e26883ff94c8ac5e73d7c6a5.png"},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var s=t(296540);const i={},o=s.createContext(i);function r(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);