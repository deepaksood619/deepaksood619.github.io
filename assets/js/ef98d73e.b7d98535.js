"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[38546],{765820:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"ai/ml-algorithms/graph-neural-networks-gnn","title":"Graph Neural Networks (GNN)","description":"Why Is a Graph Difficult To Analyze?","source":"@site/docs/ai/ml-algorithms/graph-neural-networks-gnn.md","sourceDirName":"ai/ml-algorithms","slug":"/ai/ml-algorithms/graph-neural-networks-gnn","permalink":"/ai/ml-algorithms/graph-neural-networks-gnn","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/ml-algorithms/graph-neural-networks-gnn.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1754102367000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Generative Adversarial Networks (GANs)","permalink":"/ai/ml-algorithms/generative-adversarial-networks-gans"},"next":{"title":"ID3, C4.5 and CHAID","permalink":"/ai/ml-algorithms/id3-c45-and-chaid"}}');var a=i(474848),r=i(28453);const o={},s="Graph Neural Networks (GNN)",l={},h=[{value:"Why Is a Graph Difficult To Analyze?",id:"why-is-a-graph-difficult-to-analyze",level:2},{value:"Why Use Graphs?",id:"why-use-graphs",level:2},{value:"Traditional Graph Analysis Methods",id:"traditional-graph-analysis-methods",level:2},{value:"Graph Neural Network",id:"graph-neural-network",level:2},{value:"What Can GNN do?",id:"what-can-gnn-do",level:2},{value:"Innode classification",id:"innode-classification",level:3},{value:"Inlink prediction",id:"inlink-prediction",level:3},{value:"Ingraph classification",id:"ingraph-classification",level:3},{value:"Some Real Applications",id:"some-real-applications",level:2},{value:"GNN in Natural Language Processing",id:"gnn-in-natural-language-processing",level:3},{value:"GNN in Computer Vision",id:"gnn-in-computer-vision",level:3},{value:"GNN in Other Domains",id:"gnn-in-other-domains",level:3},{value:"Graph ML",id:"graph-ml",level:2}];function d(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"graph-neural-networks-gnn",children:"Graph Neural Networks (GNN)"})}),"\n",(0,a.jsx)(n.h2,{id:"why-is-a-graph-difficult-to-analyze",children:"Why Is a Graph Difficult To Analyze?"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:'A graph does not exist in a Euclidean space, which means it cannot be represented by any coordinate systems that we are familiar with. This makes the interpretation of graph data much harder as compared to other types of data such as waves, images, or time-series signals("text" can also be treated as time-series), which can be easily mapped to a 2-D or 3-D Euclidean space.'}),"\n",(0,a.jsx)(n.li,{children:"A graph does not have a fixed form. Why? Graph (A) and Graph (B) have a completely different structure and visually different. But when we convert it to adjacency matrix representation, the two graphs have the same adjacency matrix (if we don't consider the weight of edges). So should we consider these two graphs are the same or different?"}),"\n",(0,a.jsx)(n.li,{children:"A graph is in general hard to visualize for human interpretation.. I'm talking about giant graphs that involve hundreds or thousands of nodes. The dimension is very high and nodes are densely grouped, making it even difficult for a human to understand the graph. Therefore, it is challenging to train a machine for this task."}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"why-use-graphs",children:"Why Use Graphs?"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Graphs provide a better way of dealing with abstract concepts like relationships and interactions. They also offer an intuitively visual way of thinking about these concepts. Graphs also form a natural basis for analyzing relationships in a social context."}),"\n",(0,a.jsx)(n.li,{children:"Graphs can solve more complex problems by simplifying the problems into simpler representations or transform the problems into representations from different perspectives."}),"\n",(0,a.jsxs)(n.li,{children:["Graph Theories and concepts are used to study and model Social Networks, Fraud patterns, Power consumption patterns, Virality and Influence in Social Media. Social Network Analysis (SNA) is probably the best-known application of Graph Theory for ",(0,a.jsx)(n.a,{href:"https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=IntroductionGraphTheoryarticle",children:"Data Science"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"traditional-graph-analysis-methods",children:"Traditional Graph Analysis Methods"}),"\n",(0,a.jsx)(n.p,{children:"Traditional methods are mostly algorithm-based, such as :"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"searching algorithms, e.g. BFS, DFS"}),"\n",(0,a.jsx)(n.li,{children:"shortest path algorithms, e.g. Dijkstra's algorithm, Nearest Neighbour"}),"\n",(0,a.jsx)(n.li,{children:"spanning-tree algorithms, e.g. Prim's algorithm"}),"\n",(0,a.jsx)(n.li,{children:"clustering methods, e.g. Highly Connected Components, k-mean"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The limitation of such algorithms is that we need to gain prior knowledge of the graph at certain confidence before we can apply the algorithm. In other words, it provides no mean for us to study the graph itself. And most importantly, there is no way to perform graph level classification."}),"\n",(0,a.jsx)(n.h2,{id:"graph-neural-network",children:"Graph Neural Network"}),"\n",(0,a.jsx)(n.p,{children:"Graph Neural Network, as how it is called, is a neural network that can directly be applied to graphs. It provides a convenient way for node level, edge level, and graph level prediction task."}),"\n",(0,a.jsx)(n.p,{children:"There are mainly three types of graph neural networks in the literature:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Recurrent Graph Neural Network (RecGNN)"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Spatial Convolutional Network"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.strong,{children:"Spectral Convolutional Network"})}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The intuition of GNN is that nodes are naturally defined by their neighbors and connections. To understand this we can simply imagine that if we remove the neighbors and connections around a node, then the node will lose all its information. Therefore, the neighbors of a node and connections to neighbors define the concept of the node."}),"\n",(0,a.jsx)(n.p,{children:'Having this in mind, we then give every node a state(x)to represent its concept. We can use the node state(x)to produce an output(o), i.e. decision about the concept. The final state(x_n)of the node is normally called "node embedding". The task of all GNN is to determine the "node embedding" of each node, by looking at the information on its neighboring nodes.'}),"\n",(0,a.jsx)(n.h2,{id:"what-can-gnn-do",children:"What Can GNN do?"}),"\n",(0,a.jsx)(n.p,{children:"The problems that GNN solve can be broadly classified into three categories:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Node Classification"}),"\n",(0,a.jsx)(n.li,{children:"Link Prediction"}),"\n",(0,a.jsx)(n.li,{children:"Graph Classification"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"innode-classification",children:"Innode classification"}),"\n",(0,a.jsx)(n.p,{children:"the task is to predict the node embedding for every node in a graph. This type of problem is usually trained in a semi-supervised way, where only part of the graph is labeled. Typical applications for node classification include citation networks, Reddit posts, Youtube videos, and Facebook friends relationships"}),"\n",(0,a.jsx)(n.h3,{id:"inlink-prediction",children:"Inlink prediction"}),"\n",(0,a.jsx)(n.p,{children:"the task is to understand the relationship between entities in graphs and predict if two entities have a connection in between. For example, a recommender system can be treated as link prediction problem where the model is given a set of users' reviews of different products, the task is to predict the users' preferences and tune the recommender system to push more relevant products according to users' interest"}),"\n",(0,a.jsx)(n.h3,{id:"ingraph-classification",children:"Ingraph classification"}),"\n",(0,a.jsx)(n.p,{children:"the task is to classify the whole graph into different categories. It is similar to image classification but the target changes into graph domain. There is a wide range of industrial problems where graph classification can be applied, for example, in chemistry, biomedical, physics, where the model is given a molecular structure and asked to classify the target into meaningful categories. It accelerates the analysis of atom, molecule or any other structured data types"}),"\n",(0,a.jsx)(n.h2,{id:"some-real-applications",children:"Some Real Applications"}),"\n",(0,a.jsx)(n.h3,{id:"gnn-in-natural-language-processing",children:"GNN in Natural Language Processing"}),"\n",(0,a.jsx)(n.p,{children:"GNN is widely used in Natural Language Processing (NLP). Actually, this is also where GNN initially gets started. If some of you have experience in NLP, you must be thinking that text should be a type of sequential or temporal data which can be best described by an RNN or an LTSM. Well, GNN approaches the problem from a completely different angle. GNN utilized the inner relations of words or documents to predict the categories. For example, the citation network is trying to predict the label of each paper in the network given by the paper citation relationship and the words that are cited in other papers. It can also build a syntactic model by looking at different parts of a sentence instead of purely sequential as in RNN or LTSM."}),"\n",(0,a.jsx)(n.h3,{id:"gnn-in-computer-vision",children:"GNN in Computer Vision"}),"\n",(0,a.jsx)(n.p,{children:"Many CNN based methods have achieved state-of-the-art performance in object detections in images, but yet we do not know the relationships of the objects. One successful employment of GNN in CV is using graphs to model the relationships between objects detected by a CNN based detector. After objects are detected from the images, they are then fed into a GNN inference for relationship prediction. The outcome of the GNN inference is a generated graph that models the relationships between different objects."}),"\n",(0,a.jsx)(n.p,{children:"Another interesting application in CV is image generation from graph descriptions. This can be interpreted as almost the reverse of the application mentioned above. The traditional way of image generation is text-to-image generation using GAN or autoencoder. Instead of using text for image description, graph to image generation provides more information on the semantic structures of the images."}),"\n",(0,a.jsxs)(n.p,{children:["The most interesting application I would like to share is zero-shot learning (ZSL). You can find ",(0,a.jsx)(n.a,{href:"https://towardsdatascience.com/applications-of-zero-shot-learning-f65bb232963f",children:"this post"}),' for a comprehensive introduction to ZSL. In short, ZSL is trying to learn to classify a class givenNOtraining samples (of the target classes) at all. It was quite challenging because if no training samples were given, we need to let the model "think" logically to recognize a target. For example, if we were given three images (as shown in the figure below) and told to find "okapi" among them. We may not have seen an "okapi" before. But if we were also given the information that an "okapi" is a deer-face animal with four legs and has zebra-striped skin, then it is not hard for us to figure out which one is "okapi". Typical methods are simulating this "thinking process" by converting the detected features into text. However, text encodings are independent among each other. It is hard to model the relationships between the text descriptions. In other hard, graph representations well model these relationships, making the machine to think in a more "human-like" manner.']}),"\n",(0,a.jsx)(n.h3,{id:"gnn-in-other-domains",children:"GNN in Other Domains"}),"\n",(0,a.jsxs)(n.p,{children:["More practical applications of GNN include ",(0,a.jsx)(n.em,{children:"human behavior detection, traffic control, molecular structure study, recommender system, program verification, logical reasoning, social influence prediction, and adversarial attack prevention."})," Below shows a graph that models the relationships of people in a social network. GNN can be applied to cluster people into different community groups."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc",children:"https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc"})}),"\n",(0,a.jsx)(n.h2,{id:"graph-ml",children:"Graph ML"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Google Maps uses\xa0graph ML\xa0for ETA prediction."}),"\n",(0,a.jsx)(n.li,{children:"Pinterest uses\xa0graph ML\xa0(PingSage) for recommendations."}),"\n",(0,a.jsx)(n.li,{children:"Netflix uses\xa0graph ML\xa0(SemanticGNN) for recommendations."}),"\n",(0,a.jsx)(n.li,{children:"Spotify uses\xa0graph ML\xa0(HGNNs) for audiobook recommendations."}),"\n",(0,a.jsx)(n.li,{children:"Uber Eats uses\xa0graph ML\xa0(a GraphSAGE variant) to suggest dishes, restaurants, etc."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://www.dailydoseofds.com/a-crash-course-on-graph-neural-networks-implementation-included/",children:"A Crash Course on Graph Neural Networks (Implementation Included) \u2013 Part 1"})})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var t=i(296540);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);