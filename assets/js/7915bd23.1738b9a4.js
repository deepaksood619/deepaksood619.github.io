"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[31542],{210256:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"devops/monitoring/prometheus/alert-manager","title":"Alert Manager","description":"The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integration such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts.","source":"@site/docs/devops/monitoring/prometheus/alert-manager.md","sourceDirName":"devops/monitoring/prometheus","slug":"/devops/monitoring/prometheus/alert-manager","permalink":"/devops/monitoring/prometheus/alert-manager","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/devops/monitoring/prometheus/alert-manager.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1739572825000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Prometheus","permalink":"/devops/monitoring/prometheus/"},"next":{"title":"Prometheus","permalink":"/devops/monitoring/prometheus/intro"}}');var a=n(474848),s=n(28453);const i={},o="Alert Manager",l={},c=[{value:"Grouping",id:"grouping",level:2},{value:"Inhibition",id:"inhibition",level:2},{value:"Silences",id:"silences",level:2},{value:"Templates",id:"templates",level:2},{value:"References",id:"references",level:2}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"alert-manager",children:"Alert Manager"})}),"\n",(0,a.jsxs)(t.p,{children:["The ",(0,a.jsx)(t.a,{href:"https://github.com/prometheus/alertmanager",children:"Alertmanager"})," handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integration such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts."]}),"\n",(0,a.jsx)(t.p,{children:"Flapping - when an alert has changed states more than 4 times in a one-hour time window"}),"\n",(0,a.jsx)(t.h2,{id:"grouping",children:"Grouping"}),"\n",(0,a.jsx)(t.p,{children:"Grouping categorizes alerts of similar nature into a single notification. This is especially useful during larger outages when many systems fail at once and hundreds to thousands of alerts may be firing simultaneously."}),"\n",(0,a.jsx)(t.h2,{id:"inhibition",children:"Inhibition"}),"\n",(0,a.jsx)(t.p,{children:"Inhibition is a concept of suppressing notifications for certain alerts if certain other alerts are already firing."}),"\n",(0,a.jsx)(t.h2,{id:"silences",children:"Silences"}),"\n",(0,a.jsx)(t.p,{children:"Silences are a straightforward way to simply mute alerts for a given time. A silence is configured based on matchers, just like the routing tree. Incoming alerts are checked whether they match all the equality or regular expression matchers of an active silence. If they do, no notifications will be sent out for that alert."}),"\n",(0,a.jsx)(t.h2,{id:"templates",children:"Templates"}),"\n",(0,a.jsx)(t.p,{children:"The notifications sent to receivers are constructed via templates."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-yaml",children:'config:\nglobal:\n    resolve_timeout: 5m\n    slack_api_url: https://hooks.slack.com/services/xxx/org_id/api_key\nroute:\n    group_by: [\'job\']\n    group_wait: 30s\n    group_interval: 5m\n    repeat_interval: 12h\n    receiver: slack\n    routes:\n    - match_re:\n        alertname: ^.*$\n    receiver: slack\nreceivers:\n- name: "slack"\n    slack_configs:\n    - send_resolved: true\n    channel: "#monitor"\n    title: "{{ range .Alerts }}{{ .Labels.alertname }}\\n{{ end }}"\n    text: "{{ range .Alerts }}*Alert:* `{{ .Labels.severity }}` - {{ .Labels.alertname }} - {{ .Annotations.message }}\\n*Details:* {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`{{ end }}\\n{{ end }}"\n'})}),"\n",(0,a.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://prometheus.io/docs/alerting/alertmanager",children:"https://prometheus.io/docs/alerting/alertmanager"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://prometheus.io/docs/alerting/configuration",children:"https://prometheus.io/docs/alerting/configuration"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://github.com/prometheus/alertmanager/blob/master/doc/examples/simple.yml",children:"https://github.com/prometheus/alertmanager/blob/master/doc/examples/simple.yml"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://github.com/robusta-dev/robusta",children:"GitHub - robusta-dev/robusta: Better Prometheus alerts for Kubernetes - smart grouping, AI enrichment, and automatic remediation"})})]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var r=n(296540);const a={},s=r.createContext(a);function i(e){const t=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(s.Provider,{value:t},e.children)}}}]);