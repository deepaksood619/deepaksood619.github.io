"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[47217],{738626:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"data-warehouses/snowflake/snowpipe-data-ingestion-from-aws-s3","title":"Snowpipe Data Ingestion from AWS S3","description":"1. Introduction","source":"@site/docs/data-warehouses/snowflake/snowpipe-data-ingestion-from-aws-s3.md","sourceDirName":"data-warehouses/snowflake","slug":"/data-warehouses/snowflake/snowpipe-data-ingestion-from-aws-s3","permalink":"/data-warehouses/snowflake/snowpipe-data-ingestion-from-aws-s3","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/data-warehouses/snowflake/snowpipe-data-ingestion-from-aws-s3.md","tags":[],"version":"current","lastUpdatedBy":"Deepak","lastUpdatedAt":1760616071000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Recovery","permalink":"/data-warehouses/snowflake/recovery"},"next":{"title":"Stages","permalink":"/data-warehouses/snowflake/stages"}}');var t=s(474848),o=s(28453);const a={},r="Snowpipe Data Ingestion from AWS S3",l={},d=[{value:"1. Introduction",id:"1-introduction",level:2},{value:"2. Key Concepts &amp; Components",id:"2-key-concepts--components",level:2},{value:"3. How Snowpipe Works (Overview)",id:"3-how-snowpipe-works-overview",level:2},{value:"4. Setup Steps",id:"4-setup-steps",level:2},{value:"4.1 Configure S3 / AWS Side",id:"41-configure-s3--aws-side",level:3},{value:"4.1.1 Setup S3 Bucket &amp; Prefix",id:"411-setup-s3-bucket--prefix",level:4},{value:"4.1.2 Permissions",id:"412-permissions",level:4},{value:"4.1.3 Enable S3 Event Notifications (for auto ingest)",id:"413-enable-s3-event-notifications-for-auto-ingest",level:4},{value:"4.2 Snowflake Side Setup",id:"42-snowflake-side-setup",level:3},{value:"4.2.1 Create or Use Database / Schema and Warehouse",id:"421-create-or-use-database--schema-and-warehouse",level:4},{value:"4.2.2 Create File Format",id:"422-create-file-format",level:4},{value:"4.2.3 Create External Stage",id:"423-create-external-stage",level:4},{value:"4.2.4 Create Target Table",id:"424-create-target-table",level:4},{value:"4.2.5 Create the Pipe",id:"425-create-the-pipe",level:4},{value:"5. Ingestion Methods",id:"5-ingestion-methods",level:2},{value:"Automated Cloud Messaging (S3 \u2192 SQS \u2192 Snowpipe)",id:"automated-cloud-messaging-s3--sqs--snowpipe",level:3},{value:"6. Monitoring &amp; Troubleshooting - Error Handling &amp; Retry",id:"6-monitoring--troubleshooting---error-handling--retry",level:2},{value:"7. Best Practices &amp; Recommendations",id:"7-best-practices--recommendations",level:2},{value:"Edge Cases",id:"edge-cases",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"snowpipe-data-ingestion-from-aws-s3",children:"Snowpipe Data Ingestion from AWS S3"})}),"\n",(0,t.jsx)(n.h2,{id:"1-introduction",children:"1. Introduction"}),"\n",(0,t.jsx)(n.p,{children:"Snowpipe is Snowflake\u2019s serverless, continuous data ingestion service. It allows you to load data automatically (or semi-automatically) from files as soon as they land in a stage (e.g. in Amazon S3) into a Snowflake table.\xa0"}),"\n",(0,t.jsx)(n.p,{children:"Instead of executing large batch COPY INTO loads on a schedule, Snowpipe works in micro-batches and helps your data be available within minutes.\xa0"}),"\n",(0,t.jsx)(n.p,{children:"There are two main ways Snowpipe can detect new files:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Cloud event notifications (automated ingest)"}),"\n",(0,t.jsx)(n.li,{children:"REST API calls from client applications"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"2-key-concepts--components",children:"2. Key Concepts & Components"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Component"}),(0,t.jsx)(n.th,{children:"Role in Snowpipe Workflow"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Stage (external stage)"})}),(0,t.jsx)(n.td,{children:"The location in S3 where files are stored or land. Snowpipe reads from this stage."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"File Format"})}),(0,t.jsx)(n.td,{children:"Defines how to parse files (e.g. CSV, JSON) \u2014 delimiter, quotes, null handling, etc."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Pipe"})}),(0,t.jsx)(n.td,{children:"A Snowflake object wrapping a COPY INTO statement. Snowpipe uses this definition to load new files."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Notification / Event Source"})}),(0,t.jsx)(n.td,{children:"Mechanism by which Snowpipe learns of new files (S3 \u2192 SQS, or REST API)."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Load queue"})}),(0,t.jsx)(n.td,{children:"Files get queued internally based on notifications or explicit REST calls."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Load history / metadata"})}),(0,t.jsx)(n.td,{children:"Records about which files were loaded, statuses, row counts, etc."})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"3-how-snowpipe-works-overview",children:"3. How Snowpipe Works (Overview)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Place files in S3:"})," You put your data files in an S3 location that a Snowflake stage points to."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Snowpipe detects new files:"})," It notices new or updated files using either cloud messaging (like SQS) or the REST API."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Files are queued:"})," Snowpipe keeps a list of the new files ready to be loaded."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data is loaded automatically:"})," Snowflake\u2019s serverless compute reads the files and runs the COPY INTO logic from the pipe, adding the rows into your table."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tracking and metadata:"})," Snowflake records information about each load, including success or failure, row counts, and status."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Some notes:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Snowpipe may combine or split loads into different transactions based on file size / load patterns."}),"\n",(0,t.jsx)(n.li,{children:"The order of file loading is not guaranteed to follow absolute staging order because multiple processes handle the queue."}),"\n",(0,t.jsx)(n.li,{children:"Snowpipe ensures deduplication of files \u2014 the same file won\u2019t be loaded twice (unless forced)."}),"\n",(0,t.jsx)(n.li,{children:"Event notifications older than 14 days may not be processed if the pipe was paused."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4-setup-steps",children:"4. Setup Steps"}),"\n",(0,t.jsx)(n.h3,{id:"41-configure-s3--aws-side",children:"4.1 Configure S3 / AWS Side"}),"\n",(0,t.jsx)(n.p,{children:"This setup ensures that S3 can send events / allow Snowflake to access files."}),"\n",(0,t.jsx)(n.h4,{id:"411-setup-s3-bucket--prefix",children:"4.1.1 Setup S3 Bucket & Prefix"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Decide on a bucket and \u201cprefix\u201d (subfolder) in S3 where your files will land, e.g. ",(0,t.jsx)(n.code,{children:"s3://my-bucket/data/ingest/"})]}),"\n",(0,t.jsx)(n.li,{children:"Upload initial files there."}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"412-permissions",children:"4.1.2 Permissions"}),"\n",(0,t.jsx)(n.p,{children:"You need to allow Snowflake to read from your S3 location. You can do this via:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"AWS IAM credentials (access key + secret) stored in the stage definition"}),"\n",(0,t.jsx)(n.li,{children:"Storage Integration (recommended) \u2014 a more secure way to grant permissions without embedding keys."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"If using a storage integration, you configure IAM roles and trust policies in AWS so Snowflake has permission to access that bucket."}),"\n",(0,t.jsx)(n.h4,{id:"413-enable-s3-event-notifications-for-auto-ingest",children:"4.1.3 Enable S3 Event Notifications (for auto ingest)"}),"\n",(0,t.jsxs)(n.p,{children:["To use automated ingest, you must configure S3 to send event notifications (e.g. ",(0,t.jsx)(n.code,{children:"s3:ObjectCreated:*"}),") to an SNS or SQS destination.\xa0"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Destination:"})," typically an SQS queue that Snowpipe polls"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optional:"})," Use prefix filters so only relevant file paths trigger ingest (reducing noise)"]}),"\n",(0,t.jsxs)(n.li,{children:["Make sure the S3 bucket and SQS queue are in the ",(0,t.jsx)(n.strong,{children:"same AWS region"})]}),"\n",(0,t.jsxs)(n.li,{children:["Update the SQS queue policy to allow ",(0,t.jsx)(n.code,{children:"s3.amazonaws.com"})," to send messages to that queue (via ",(0,t.jsx)(n.code,{children:"SQS:SendMessage"}),") with a condition that the source ARN is your bucket."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"42-snowflake-side-setup",children:"4.2 Snowflake Side Setup"}),"\n",(0,t.jsx)(n.p,{children:"You do this via SQL (Snowflake UI, SnowSQL, or scripts)."}),"\n",(0,t.jsx)(n.h4,{id:"421-create-or-use-database--schema-and-warehouse",children:"4.2.1 Create or Use Database / Schema and Warehouse"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE OR REPLACE WAREHOUSE ingest_wh\n\xa0\xa0WAREHOUSE_SIZE = 'XSMALL'\n\xa0\xa0AUTO_SUSPEND = 300\n\xa0\xa0AUTO_RESUME = TRUE;\n\xa0\xa0\nUSE WAREHOUSE ingest_wh;\n\nCREATE OR REPLACE DATABASE ingest_db;\n\nUSE DATABASE ingest_db;\n\nUSE SCHEMA PUBLIC;\n"})}),"\n",(0,t.jsx)(n.h4,{id:"422-create-file-format",children:"4.2.2 Create File Format"}),"\n",(0,t.jsx)(n.p,{children:"Define how your incoming CSV / JSON / other file types are structured."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE OR REPLACE FILE FORMAT ingest_csv_format\n\xa0\xa0TYPE = 'CSV'\n\xa0\xa0FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n\xa0\xa0SKIP_HEADER = 1\n\xa0\xa0NULL_IF = ('NULL', '');\n"})}),"\n",(0,t.jsx)(n.p,{children:"Adjust options (delimiters, quoting, escape, etc.) per your file pattern."}),"\n",(0,t.jsx)(n.h4,{id:"423-create-external-stage",children:"4.2.3 Create External Stage"}),"\n",(0,t.jsx)(n.p,{children:"Point to your S3 location, referencing credentials or storage integration."}),"\n",(0,t.jsx)(n.p,{children:"Using AWS credentials approach:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE OR REPLACE STAGE ingest_stage\n\xa0\xa0URL = 's3://my-bucket/data/ingest/'\n\xa0\xa0CREDENTIALS = (\n\xa0\xa0\xa0\xa0AWS_KEY_ID = '<YOUR_ACCESS_KEY>'\n\xa0\xa0\xa0\xa0AWS_SECRET_KEY = '<YOUR_SECRET_KEY>'\n\xa0\xa0)\n\xa0\xa0FILE_FORMAT = ingest_csv_format;\n"})}),"\n",(0,t.jsx)(n.h4,{id:"424-create-target-table",children:"4.2.4 Create Target Table"}),"\n",(0,t.jsx)(n.p,{children:"Create a table whose schema matches your file\u2019s structure, e.g.:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE OR REPLACE TABLE ingest_table (\n\xa0\xa0description STRING,\n\xa0\xa0industry STRING,\n\xa0\xa0level STRING,\n\xa0\xa0size STRING,\n\xa0\xa0line_code STRING,\n\xa0\xa0value NUMBER(38,4),\n\xa0\xa0status STRING,\n\xa0\xa0Unit STRING,\n\xa0\xa0Footnotes STRING\n);\n"})}),"\n",(0,t.jsx)(n.p,{children:"Adjust data types as needed."}),"\n",(0,t.jsx)(n.h4,{id:"425-create-the-pipe",children:"4.2.5 Create the Pipe"}),"\n",(0,t.jsx)(n.p,{children:"Define a pipe with a COPY INTO statement."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For automated ingest, set ",(0,t.jsx)(n.code,{children:"AUTO_INGEST = TRUE"})]}),"\n",(0,t.jsxs)(n.li,{children:["For manual ingest (REST or manual refresh), set ",(0,t.jsx)(n.code,{children:"AUTO_INGEST = FALSE  "})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Example (auto ingest):"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE OR REPLACE PIPE ingest_pipe\n\xa0\xa0AUTO_INGEST = TRUE\nCOPY INTO ingest_table\nFROM @ingest_stage\nFILE_FORMAT = ingest_csv_format\nON_ERROR = 'CONTINUE';\n"})}),"\n",(0,t.jsx)(n.p,{children:"Permissions: The executing user must have OPERATE on the pipe, USAGE on stage, INSERT on table, etc.\xa0"}),"\n",(0,t.jsx)(n.p,{children:"After creating the pipe, you can inspect its notification channel:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"DESC PIPE ingest_pipe;"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"notification_channel"})," column shows which SQS queue is associated (for auto ingest).\xa0"]}),"\n",(0,t.jsx)(n.h2,{id:"5-ingestion-methods",children:"5. Ingestion Methods"}),"\n",(0,t.jsx)(n.h3,{id:"automated-cloud-messaging-s3--sqs--snowpipe",children:"Automated Cloud Messaging (S3 \u2192 SQS \u2192 Snowpipe)"}),"\n",(0,t.jsx)(n.p,{children:"This method gives you the \u201cautomatic as files arrive\u201d behavior."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"S3 publishes new file events to SQS (via event notification)"}),"\n",(0,t.jsx)(n.li,{children:"Snowpipe polls the SQS queue and enqueues new files for ingest"}),"\n",(0,t.jsx)(n.li,{children:"Snowflake\u2019s serverless compute reads those queued files, runs the pipe\u2019s COPY INTO, and loads data"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"6-monitoring--troubleshooting---error-handling--retry",children:"6. Monitoring & Troubleshooting - Error Handling & Retry"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The ON_ERROR clause in the pipe\u2019s COPY statement defines behavior on row-level errors (e.g. 'CONTINUE', 'ABORT_STATEMENT', etc.)."}),"\n",(0,t.jsx)(n.li,{children:"You can use VALIDATION_MODE = RETURN_ERRORS to test load behavior without inserting data."}),"\n",(0,t.jsx)(n.li,{children:"For staged files that failed due to format or schema issues, examine error messages in load history and consider reformatting."}),"\n",(0,t.jsx)(n.li,{children:"You have to manually remove or archive staged files you no longer want; Snowpipe does not auto-purge them."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"7-best-practices--recommendations",children:"7. Best Practices & Recommendations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File sizing:"})," For best performance, aim for file sizes in the range ~100\u2013250 MB (compressed) instead of many tiny files. Too many small files can lead to high overhead."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Event filtering:"})," Use prefix and suffix filters in S3 \u2192 SQS to only notify for relevant files (e.g., .csv) to reduce noise and cost."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use storage integrations"})," when possible instead of embedding AWS keys in stage definitions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Pause pipe when needed:"})," You can pause ingestion with ALTER PIPE \u2026 SET PIPE_EXECUTION_PAUSED = TRUE when doing maintenance."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Recreating pipe:"})," When you recreate a pipe, its load history is dropped \u2014 be careful not to cause duplicates."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Monitor costs:"})," Snowpipe has a compute cost plus a file overhead fee (per 1,000 files). Many small files can be expensive."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Schema consistency:"})," Keep incoming file schema stable, or use a raw staging approach (e.g. load into VARIANT) and transform downstream."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Testing:"})," Use VALIDATION_MODE = RETURN_ERRORS or FORCE = TRUE in COPY statements while testing."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"edge-cases",children:"Edge Cases"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Scenario"}),(0,t.jsx)(n.th,{children:"Issue"}),(0,t.jsx)(n.th,{children:"Solution"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Extra column in new file"}),(0,t.jsx)(n.td,{children:"Load fails"}),(0,t.jsx)(n.td,{children:"Add MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE; allow flexible schema"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"File has missing columns"}),(0,t.jsx)(n.td,{children:"NULL values"}),(0,t.jsx)(n.td,{children:"Use column defaults"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Completely new schema file"}),(0,t.jsx)(n.td,{children:"Incorrect mapping"}),(0,t.jsx)(n.td,{children:"Use landing raw table + JSON approach"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Table created without schema"}),(0,t.jsx)(n.td,{children:"Snowflake needs explicit structure"}),(0,t.jsx)(n.td,{children:"Use dynamic schema with VARIANT"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Duplicate file load"}),(0,t.jsx)(n.td,{children:"Duplicate rows"}),(0,t.jsx)(n.td,{children:"Use COPY_OPTIONS = (ON_ERROR='CONTINUE') + FILE_NAME dedup"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Bad data rows"}),(0,t.jsx)(n.td,{children:"Failure"}),(0,t.jsx)(n.td,{children:"Use ON_ERROR = CONTINUE"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CSV delimiter issues"}),(0,t.jsx)(n.td,{children:"wrong parsing"}),(0,t.jsx)(n.td,{children:"specify FIELD_OPTIONALLY_ENCLOSED_BY='\"'"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro",children:"Snowpipe | Snowflake Documentation"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>r});var i=s(296540);const t={},o=i.createContext(t);function a(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);