"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[52976],{792182:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"technologies/kafka/kafka-guarantees","title":"Kafka Guarantees","description":"- Messages sent by a producer to a topic and a partition are appended in the same order","source":"@site/docs/technologies/kafka/kafka-guarantees.md","sourceDirName":"technologies/kafka","slug":"/technologies/kafka/kafka-guarantees","permalink":"/technologies/kafka/kafka-guarantees","draft":false,"unlisted":false,"editUrl":"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/technologies/kafka/kafka-guarantees.md","tags":[],"version":"current","lastUpdatedBy":"Deepak Sood","lastUpdatedAt":1769339984000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Kafka Consumers","permalink":"/technologies/kafka/kafka-consumers"},"next":{"title":"Kafka Listeners","permalink":"/technologies/kafka/kafka-listeners"}}');var i=s(474848),r=s(28453);const a={},o="Kafka Guarantees",l={},c=[{value:"Message Processing Guarantees",id:"message-processing-guarantees",level:2},{value:"Exactly Once Semantics (EOS)",id:"exactly-once-semantics-eos",level:2},{value:"Key Building Blocks for EOS",id:"key-building-blocks-for-eos",level:3},{value:"(a) Idempotent Producer",id:"a-idempotent-producer",level:4},{value:"(b) Transactions",id:"b-transactions",level:4},{value:"(c) Replication Protocol",id:"c-replication-protocol",level:4},{value:"Putting It Together",id:"putting-it-together",level:3},{value:"Limitations",id:"limitations",level:3},{value:"Replication Protocol",id:"replication-protocol",level:2},{value:"Outbox Pattern",id:"outbox-pattern",level:2},{value:"Problem it Solves",id:"problem-it-solves",level:3},{value:"The Outbox Pattern",id:"the-outbox-pattern",level:3},{value:"Event Relay (Debezium / Polling)",id:"event-relay-debezium--polling",level:3},{value:"Benefits",id:"benefits",level:3},{value:"Example Flow",id:"example-flow",level:3},{value:"Outbox to Kafka - EOS",id:"outbox-to-kafka---eos",level:2},{value:"1. The Challenge",id:"1-the-challenge",level:3},{value:"2. Solution Approaches",id:"2-solution-approaches",level:3},{value:"Approach A: <strong>Kafka Transactions (EOS Producer)</strong>",id:"approach-a-kafka-transactions-eos-producer",level:4},{value:"Approach B: <strong>Idempotent Deduplication Key</strong>",id:"approach-b-idempotent-deduplication-key",level:4},{value:"Approach C: <strong>Debezium / CDC Outbox (Best Practice)</strong>",id:"approach-c-debezium--cdc-outbox-best-practice",level:4},{value:"3. Practical Design (if writing custom relay service)",id:"3-practical-design-if-writing-custom-relay-service",level:3},{value:"4. Key Points",id:"4-key-points",level:3},{value:"Idempotent Writer",id:"idempotent-writer",level:2},{value:"Solution",id:"solution",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Considerations",id:"considerations",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"kafka-guarantees",children:"Kafka Guarantees"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Messages sent by a producer to a topic and a partition are appended in the same order"}),"\n",(0,i.jsx)(n.li,{children:"A consumer instance gets the messages in the same order as they are produced"}),"\n",(0,i.jsx)(n.li,{children:"A topic with replication factor N, tolerates upto N-1 server failures"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"message-processing-guarantees",children:"Message Processing Guarantees"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No guarantee -"})," No explicit guarantee is provided, so consumers may process messages once, multiple times or never at all."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"At most once -"}),' This is "best effort" delivery semantics. Consumers will receive and process messages exactly once or not at all.']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"At least once -"})," Consumers will receive and process every message, but they may process the same message more than once."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Effectively once -"})," Also ",(0,i.jsx)(n.a,{href:"https://streaml.io/blog/exactly-once",children:"contentiously"})," ",(0,i.jsx)(n.a,{href:"https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f",children:"known"})," as exactly once, this promises consumers will process every message once."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"image",src:s(94017).A+"",width:"525",height:"409"})}),"\n",(0,i.jsx)(n.h2,{id:"exactly-once-semantics-eos",children:"Exactly Once Semantics (EOS)"}),"\n",(0,i.jsx)(n.h3,{id:"key-building-blocks-for-eos",children:"Key Building Blocks for EOS"}),"\n",(0,i.jsxs)(n.p,{children:["Kafka achieves ",(0,i.jsx)(n.strong,{children:"EOS"})," using three main features:"]}),"\n",(0,i.jsx)(n.h4,{id:"a-idempotent-producer",children:"(a) Idempotent Producer"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Every message sent by a producer gets a ",(0,i.jsx)(n.strong,{children:"producer ID (PID)"})," and a ",(0,i.jsx)(n.strong,{children:"sequence number"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"If retries happen (e.g., network glitch), Kafka detects duplicates by checking the sequence number and ignores them."}),"\n",(0,i.jsxs)(n.li,{children:["Ensures ",(0,i.jsx)(n.strong,{children:"no duplicates on retries"})," \u2192 gives ",(0,i.jsx)(n.strong,{children:"idempotent writes"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"b-transactions",children:"(b) Transactions"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A producer can group multiple writes (to one or more partitions, topics) into a ",(0,i.jsx)(n.strong,{children:"transaction"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Kafka ensures that either:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"All writes in the transaction are committed, or"}),"\n",(0,i.jsx)(n.li,{children:"None are (atomicity)."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Consumers using ",(0,i.jsx)(n.strong,{children:"read_committed"})," isolation see only committed data."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"c-replication-protocol",children:"(c) Replication Protocol"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["With ",(0,i.jsx)(n.code,{children:"acks=all"}),", Kafka ensures that once a transaction is committed, it\u2019s ",(0,i.jsx)(n.strong,{children:"durably replicated to all in-sync replicas (ISRs)"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"This guarantees durability even if the leader fails immediately after commit."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"putting-it-together",children:"Putting It Together"}),"\n",(0,i.jsx)(n.p,{children:"Here\u2019s how EOS works in practice:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Producer"})," starts a transaction \u2192 ",(0,i.jsx)(n.code,{children:"initTransactions()"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Writes messages with ",(0,i.jsx)(n.strong,{children:"idempotence enabled"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Calls ",(0,i.jsx)(n.code,{children:"commitTransaction()"})," \u2192 Kafka writes a ",(0,i.jsx)(n.strong,{children:"transaction marker"})," ensuring atomic visibility."]}),"\n",(0,i.jsxs)(n.li,{children:["Messages are replicated to all ISRs (with ",(0,i.jsx)(n.code,{children:"acks=all"}),")."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consumer"})," reads with ",(0,i.jsx)(n.code,{children:"isolation.level=read_committed"})," \u2192 sees each committed message ",(0,i.jsx)(n.strong,{children:"exactly once"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"limitations",children:"Limitations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["EOS works ",(0,i.jsx)(n.strong,{children:"only within Kafka"})," (end-to-end with producers + Kafka + consumers)."]}),"\n",(0,i.jsxs)(n.li,{children:["If you write to an external DB/system, you need ",(0,i.jsx)(n.strong,{children:"two-phase commit or outbox patterns"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Slight overhead due to transaction coordination."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"replication-protocol",children:"Replication Protocol"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["When a ",(0,i.jsx)(n.strong,{children:"producer"})," writes a message to a partition, it first goes to the ",(0,i.jsx)(n.strong,{children:"leader replica"})," of that partition."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The producer can specify the ",(0,i.jsx)(n.strong,{children:"acks"})," setting:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"acks=0"})," \u2192 Producer doesn\u2019t wait for acknowledgment."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"acks=1"})," \u2192 Producer gets an acknowledgment once the leader writes it."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"acks=all"})," (or ",(0,i.jsx)(n.code,{children:"-1"}),") \u2192 Producer gets acknowledgment only after the message is written to the leader ",(0,i.jsx)(n.strong,{children:"and"})," replicated to all ",(0,i.jsx)(n.strong,{children:"in-sync replicas (ISRs)"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Important nuance"}),": Kafka does ",(0,i.jsx)(n.strong,{children:"not"})," guarantee replication to ",(0,i.jsx)(n.em,{children:"all available replicas"})," after the leader write. Instead, it guarantees replication to the set of ",(0,i.jsx)(n.strong,{children:"in-sync replicas (ISRs)"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["If a follower is ",(0,i.jsx)(n.strong,{children:"out of sync"}),", it won\u2019t block the acknowledgment."]}),"\n",(0,i.jsx)(n.li,{children:"As long as at least one ISR (typically the leader + followers in sync) has the message, Kafka considers it durable."}),"\n"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Kafka\u2019s replication protocol guarantees that once a message has been acknowledged with ",(0,i.jsx)(n.code,{children:"acks=all"}),", it has been written successfully to the leader replica and replicated to all in-sync replicas (ISRs)."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"outbox-pattern",children:"Outbox Pattern"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Outbox Pattern"})," is one of the most popular patterns used to achieve ",(0,i.jsx)(n.strong,{children:"reliable event-driven integration"})," between a database (like MySQL, PostgreSQL) and a message broker (like Kafka)."]}),"\n",(0,i.jsx)(n.h3,{id:"problem-it-solves",children:"Problem it Solves"}),"\n",(0,i.jsx)(n.p,{children:"When a service needs to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Update its ",(0,i.jsx)(n.strong,{children:"own database"})," (say insert a new ",(0,i.jsx)(n.code,{children:"Order"}),"), and"]}),"\n",(0,i.jsxs)(n.li,{children:["Publish an ",(0,i.jsx)(n.strong,{children:"event to Kafka"})," (like ",(0,i.jsx)(n.code,{children:"OrderCreated"}),")"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["You run into the ",(0,i.jsx)(n.strong,{children:"dual-write problem"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"If you write to the DB but crash before publishing to Kafka \u2192 event is lost."}),"\n",(0,i.jsx)(n.li,{children:"If you publish to Kafka but crash before writing to DB \u2192 system state is inconsistent."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This breaks ",(0,i.jsx)(n.strong,{children:"exactly-once semantics across DB + Kafka"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"the-outbox-pattern",children:"The Outbox Pattern"}),"\n",(0,i.jsxs)(n.p,{children:["Instead of doing both separately, you write ",(0,i.jsx)(n.strong,{children:"only to your database"})," in a single atomic transaction:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Service writes ",(0,i.jsx)(n.strong,{children:"business data"})," (e.g., new ",(0,i.jsx)(n.code,{children:"Order"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:["In the ",(0,i.jsx)(n.strong,{children:"same transaction"}),", service writes an ",(0,i.jsx)(n.strong,{children:"event record"})," into a special ",(0,i.jsx)(n.code,{children:"outbox"})," table."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Example (Postgres/MySQL):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"BEGIN;\nINSERT INTO orders (id, customer, amount, status) VALUES (123, 'Deepak', 1000, 'CREATED');\nINSERT INTO outbox (event_id, type, payload, status) VALUES (uuid(), 'OrderCreated', '{\"id\":123,\"amount\":1000}', 'NEW');\nCOMMIT;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Now DB and event are ",(0,i.jsx)(n.strong,{children:"guaranteed consistent"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"event-relay-debezium--polling",children:"Event Relay (Debezium / Polling)"}),"\n",(0,i.jsx)(n.p,{children:"Next step:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A ",(0,i.jsx)(n.strong,{children:"relay process"})," reads events from the ",(0,i.jsx)(n.code,{children:"outbox"})," table and publishes them to Kafka."]}),"\n",(0,i.jsxs)(n.li,{children:["Can be done via:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Change Data Capture (CDC)"})," tools like ",(0,i.jsx)(n.strong,{children:"Debezium"})," (reads DB transaction log, automatically streams outbox rows to Kafka)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Polling"})," (a background service queries the outbox table and sends events)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["After publishing, event status can be marked as ",(0,i.jsx)(n.code,{children:"SENT"})," or the row can be archived."]}),"\n",(0,i.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Atomicity"})," \u2192 DB update + event log are one transaction."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reliability"})," \u2192 No lost or duplicated events."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Event-driven architecture"})," works smoothly with existing DB."]}),"\n",(0,i.jsxs)(n.li,{children:["Plays well with ",(0,i.jsx)(n.strong,{children:"Kafka + EOS"})," when you integrate external systems."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"example-flow",children:"Example Flow"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Order Service"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"User places order."}),"\n",(0,i.jsx)(n.li,{children:"Service saves order + inserts event into outbox table."}),"\n",(0,i.jsxs)(n.li,{children:["Debezium streams outbox \u2192 Kafka topic ",(0,i.jsx)(n.code,{children:"order.events"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Inventory Service"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Consumes from ",(0,i.jsx)(n.code,{children:"order.events"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Updates stock accordingly."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"outbox-to-kafka---eos",children:"Outbox to Kafka - EOS"}),"\n",(0,i.jsx)(n.h3,{id:"1-the-challenge",children:"1. The Challenge"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.strong,{children:"outbox table"})," is already atomic with your business data."]}),"\n",(0,i.jsxs)(n.li,{children:["But when your ",(0,i.jsx)(n.strong,{children:"producer service"})," reads from the outbox and publishes to Kafka, two risks appear:","\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Duplicate sends"})," (retry on failure, service crash before marking event as sent)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lost events"})," (service marks row as sent, but crash happens before actually producing to Kafka)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We need EOS here."}),"\n",(0,i.jsx)(n.h3,{id:"2-solution-approaches",children:"2. Solution Approaches"}),"\n",(0,i.jsxs)(n.h4,{id:"approach-a-kafka-transactions-eos-producer",children:["Approach A: ",(0,i.jsx)(n.strong,{children:"Kafka Transactions (EOS Producer)"})]}),"\n",(0,i.jsxs)(n.p,{children:["Kafka has ",(0,i.jsx)(n.strong,{children:"idempotent producers + transactions"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Configure the producer with:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"enable.idempotence=true"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"acks=all"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"transactional.id=outbox-relay-1"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Start a ",(0,i.jsx)(n.strong,{children:"transaction"}),":","\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Read batch of unsent events from outbox table."}),"\n",(0,i.jsx)(n.li,{children:"Begin Kafka transaction."}),"\n",(0,i.jsx)(n.li,{children:"Send all events to Kafka."}),"\n",(0,i.jsxs)(n.li,{children:["Commit Kafka transaction ",(0,i.jsx)(n.strong,{children:"AND"})," update outbox table status (",(0,i.jsx)(n.code,{children:"sent=true"}),") in the ",(0,i.jsx)(n.strong,{children:"same transactional flow"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["But here\u2019s the catch: Kafka transactions and DB transactions are separate. You ",(0,i.jsx)(n.strong,{children:"cannot"})," commit both atomically in one step."]}),"\n",(0,i.jsxs)(n.p,{children:["So you need a ",(0,i.jsx)(n.strong,{children:"transactional outbox + idempotent updates"})," pattern."]}),"\n",(0,i.jsxs)(n.h4,{id:"approach-b-idempotent-deduplication-key",children:["Approach B: ",(0,i.jsx)(n.strong,{children:"Idempotent Deduplication Key"})]}),"\n",(0,i.jsxs)(n.p,{children:["Each event in outbox has a ",(0,i.jsx)(n.strong,{children:"unique event_id (UUID)"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"event_id"})," as ",(0,i.jsx)(n.strong,{children:"Kafka message key"})," (or put it in headers)."]}),"\n",(0,i.jsx)(n.li,{children:"Kafka producer with idempotence ensures retries don\u2019t create duplicates."}),"\n",(0,i.jsxs)(n.li,{children:["Consumers can deduplicate by ",(0,i.jsx)(n.code,{children:"event_id"})," if needed."]}),"\n"]}),"\n",(0,i.jsxs)(n.h4,{id:"approach-c-debezium--cdc-outbox-best-practice",children:["Approach C: ",(0,i.jsx)(n.strong,{children:"Debezium / CDC Outbox (Best Practice)"})]}),"\n",(0,i.jsx)(n.p,{children:"Instead of writing custom relay code:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.strong,{children:"Debezium"})," (reads DB\u2019s transaction log)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"When your service commits the DB transaction (business row + outbox row), Debezium streams the outbox change directly into Kafka."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["This is already ",(0,i.jsx)(n.strong,{children:"exactly-once"})," because:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"DB transaction log guarantees no duplicates."}),"\n",(0,i.jsx)(n.li,{children:"Kafka\u2019s EOS producer (in Debezium) guarantees idempotence."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:'This avoids the "dual-write" problem entirely.'}),"\n",(0,i.jsx)(n.h3,{id:"3-practical-design-if-writing-custom-relay-service",children:"3. Practical Design (if writing custom relay service)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Outbox row has:\n",(0,i.jsx)(n.code,{children:"event_id (UUID, PK), payload, status, created_at"})]}),"\n",(0,i.jsxs)(n.li,{children:["Relay service logic:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Poll outbox rows where ",(0,i.jsx)(n.code,{children:"status='NEW'"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Start Kafka transaction."}),"\n",(0,i.jsxs)(n.li,{children:["For each row:\n",(0,i.jsx)(n.code,{children:'producer.send(new ProducerRecord("topic", event_id, payload));'})]}),"\n",(0,i.jsx)(n.li,{children:"Commit Kafka transaction."}),"\n",(0,i.jsxs)(n.li,{children:["After successful commit, mark those rows as ",(0,i.jsx)(n.code,{children:"SENT"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["If crash happens:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Rows still marked ",(0,i.jsx)(n.code,{children:"NEW"})," \u2192 safe to retry."]}),"\n",(0,i.jsx)(n.li,{children:"Kafka idempotence + unique key ensure no duplicates."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-key-points",children:"4. Key Points"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Idempotence in Kafka"})," removes duplicates caused by retries."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Outbox status column"})," ensures no message is lost."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CDC (Debezium)"})," is the cleanest and production-proven way."]}),"\n",(0,i.jsxs)(n.li,{children:["If you roll your own relay, you must use ",(0,i.jsx)(n.strong,{children:"idempotent producer + unique event_id"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["So, ",(0,i.jsx)(n.strong,{children:"the safest way"})," to ensure EOS from Outbox \u2192 Kafka is:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"CDC (Debezium Outbox pattern)"})," if possible."]}),"\n",(0,i.jsxs)(n.li,{children:["If using a custom service, use ",(0,i.jsx)(n.strong,{children:"Kafka idempotent producer with unique event_id"})," + mark rows after commit."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"idempotent-writer",children:"Idempotent Writer"}),"\n",(0,i.jsxs)(n.p,{children:["A writer produces\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event/event",children:"Events"}),"\xa0that are written into an\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-stream/event-stream",children:"Event Stream"}),", and under stable conditions, each Event is recorded only once. However, in the case of an operational failure or a brief network outage, an\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-source/event-source",children:"Event Source"}),"\xa0may need to retry writes. This may result in multiple copies of the same Event ending up in the Event Stream, as the first write may have actually succeeded even though the producer did not receive the acknowledgement from the\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-stream/event-streaming-platform",children:"Event Streaming Platform"}),". This type of duplication is a common failure scenario in practice and one of the perils of distributed systems."]}),"\n",(0,i.jsx)(n.h3,{id:"solution",children:"Solution"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://developer.confluent.io/e2aafad9a007b0e88fca48e720894ec1/idempotent-writer.svg",alt:"idempotent-writer"})}),"\n",(0,i.jsx)(n.p,{children:"Generally speaking, this can be addressed by native support for idempotent clients. This means that a writer may try to produce an Event more than once, but the Event Streaming Platform detects and discards duplicate write attempts for the same Event."}),"\n",(0,i.jsx)(n.h3,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(n.p,{children:"To make an Apache Kafka\xae producer idempotent, configure your producer with the following setting:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"enable.idempotence=true"})}),"\n",(0,i.jsxs)(n.p,{children:["The Kafka producer tags each batch of Events that it sends to the Kafka cluster with a sequence number. Brokers in the cluster use this sequence number to enforce deduplication of Events sent from this specific producer. Each batch's sequence number is persisted so that even if the\xa0",(0,i.jsx)(n.a,{href:"https://www.confluent.io/blog/apache-kafka-intro-how-kafka-works/?session_ref=https%3A%2F%2Fwww.google.com%2F#replication",children:"leader broker"}),"\xa0fails, the new leader broker will also know if a given batch is a duplicate."]}),"\n",(0,i.jsxs)(n.p,{children:["To enable exactly-once processing within an Apache Flink\xae application that uses Kafka sources and sinks, configure the delivery guarantee to be exactly once, either via the\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/datastream/kafka/#fault-tolerance",children:"DeliveryGuarantee.EXACTLY_ONCE"}),"\xa0KafkaSink\xa0configuration option if the application uses the DataStream Kafka connector, or by setting the\xa0",(0,i.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/kafka/#consistency-guarantees",children:"sink.delivery-guarantee"}),"\xa0configuration option to\xa0exactly-once\xa0if it uses one of the Table API connectors.\xa0",(0,i.jsx)(n.a,{href:"https://docs.confluent.io/cloud/current/flink/overview.html",children:"Confluent Cloud for Apache Flink"}),"\xa0provides built-in exactly-once semantics. Downstream of the Flink application, be sure to configure any Kafka consumer with an\xa0",(0,i.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#isolation-level",children:"isolation.level"}),"\xa0of\xa0read_committed\xa0since Flink leverages Kafka transactions in the embedded producer to implement exactly-once processing."]}),"\n",(0,i.jsxs)(n.p,{children:["To enable\xa0",(0,i.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/installation/configuration/streams-configs.html#processing-guarantee",children:"exactly-once processing guarantees"}),"\xa0in Kafka Streams or ksqlDB, configure the application with the following setting, which includes enabling idempotence in the embedded producer:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"processing.guarantee=exactly_once_v2"})}),"\n",(0,i.jsx)(n.h3,{id:"considerations",children:"Considerations"}),"\n",(0,i.jsx)(n.p,{children:"Enabling idempotency for a Kafka producer not only ensures that duplicate Events are fenced out from the topic, it also ensures that they are written in order. This is because the brokers accept a batch of Events only if its sequence number is exactly one greater than that of the last committed batch; otherwise, it results in an out-of-sequence error."}),"\n",(0,i.jsxs)(n.p,{children:["Exactly-once semantics (EOS) allow\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-processing/event-processing-application",children:"Event Streaming Applications"}),"\xa0to process data without loss or duplication. This ensures that computed results are always consistent and accurate, even for stateful computations such as joins,\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/stream-processing/event-aggregator",children:"aggregations"}),", and\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/stream-processing/event-grouper",children:"windowing"}),". Any solution that requires EOS guarantees must enable EOS at all stages of the pipeline, not just on the writer. An Idempotent Writer is therefore typically combined with an\xa0",(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-processing/idempotent-reader",children:"Idempotent Reader"}),"\xa0and transactional processing."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://developer.confluent.io/patterns/event-processing/idempotent-writer/",children:"Idempotent Writer"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},94017:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/Technologies-Kafka-Others-image1-c116dd5d2221e9d4fc3d59d6c2a42a56.jpg"},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var t=s(296540);const i={},r=t.createContext(i);function a(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);