"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[22486],{985171:(A,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>o});var n=i(785893),t=i(511151);const a={},r="Confusion Matrix",s={id:"ai/model-evaluation/confusion-matrix",title:"Confusion Matrix",description:"The confusion matrix shows - The observations broken down by actual classes and predicted classes",source:"@site/docs/ai/model-evaluation/confusion-matrix.md",sourceDirName:"ai/model-evaluation",slug:"/ai/model-evaluation/confusion-matrix",permalink:"/ai/model-evaluation/confusion-matrix",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/ai/model-evaluation/confusion-matrix.md",tags:[],version:"current",lastUpdatedAt:1701793554,formattedLastUpdatedAt:"Dec 5, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"bias-variance trade-off",permalink:"/ai/model-evaluation/bias-variance-trade-off"},next:{title:"Evaluation",permalink:"/ai/model-evaluation/evaluation"}},c={},o=[{value:"Evaluating Models",id:"evaluating-models",level:2},{value:"Basic measures derived from the confusion matrix",id:"basic-measures-derived-from-the-confusion-matrix",level:3},{value:"Receiver Operating Characteristic (ROC) Curve",id:"receiver-operating-characteristic-roc-curve",level:2},{value:"Area Under Curve (AUC)",id:"area-under-curve-auc",level:2},{value:"Precision-Recall Curve (PR Curve)",id:"precision-recall-curve-pr-curve",level:2}];function l(A){const e={a:"a",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,t.a)(),...A.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.h1,{id:"confusion-matrix",children:"Confusion Matrix"}),"\n",(0,n.jsx)(e.p,{children:"The confusion matrix shows - The observations broken down by actual classes and predicted classes"}),"\n",(0,n.jsx)(e.p,{children:"Accuracy - The sum of true positives and true negatives, divided by the total number of observations"}),"\n",(0,n.jsx)(e.p,{children:"What is the relationship between the confusion matrix and the area under the receiver operating characteristic curve? - Each point from the curve represents a confusion matrix."}),"\n",(0,n.jsx)(e.p,{children:"Choose your evaluation metrics in light of acceptable tradeoffs between False Positives and False Negatives"}),"\n",(0,n.jsx)(e.h2,{id:"evaluating-models",children:"Evaluating Models"}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:"image",src:i(153250).Z+"",width:"1350",height:"697"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:"image",src:i(627247).Z+"",width:"617",height:"457"})}),"\n",(0,n.jsx)(e.h3,{id:"basic-measures-derived-from-the-confusion-matrix",children:"Basic measures derived from the confusion matrix"}),"\n",(0,n.jsxs)(e.ol,{children:["\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Error Rate = (FP+FN)/(P+N)"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Accuracy = (TP+TN)/(P+N)"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Sensitivity (Recall or True positive rate) = TP/P"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"False negative rate = FP/(FN+TP) or FP/P"}),"\n",(0,n.jsx)(e.p,{children:"False negative rate is the fraction of true faces that are not detected by the ML system"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Specificity (True negative rate) = TN/N"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Precision (Positive predicted value) = TP/(TP+FP)"}),"\n",(0,n.jsx)(e.p,{children:"An increase in False Positives would drive down precision"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"False postitive rate = FP/(FP+TN)"}),"\n",(0,n.jsx)(e.p,{children:"False positive rate is the fraction of the faces that the ML model detects that are not really faces"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"F-Score (Harmonic mean of precision and recall) = (1+b)(PREC.REC)/(b2PREC+REC) where b is commonly 0.5, 1, 2"}),"\n"]}),"\n",(0,n.jsxs)(e.li,{children:["\n",(0,n.jsx)(e.p,{children:"Tradeoffs"}),"\n",(0,n.jsx)(e.p,{children:"Sometimes false positives are better than false negatives or vice versa"}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(e.h2,{id:"receiver-operating-characteristic-roc-curve",children:"Receiver Operating Characteristic (ROC) Curve"}),"\n",(0,n.jsx)(e.p,{children:"The ROC curve plots - the true positives as a function of false positives."}),"\n",(0,n.jsx)(e.p,{children:"An ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:"}),"\n",(0,n.jsxs)(e.ul,{children:["\n",(0,n.jsx)(e.li,{children:"True Positive Rate"}),"\n",(0,n.jsx)(e.li,{children:"False Positive Rate"}),"\n"]}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc",children:"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5",children:"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:"image",src:i(1560).Z+"",width:"1099",height:"580"})}),"\n",(0,n.jsx)(e.h2,{id:"area-under-curve-auc",children:"Area Under Curve (AUC)"}),"\n",(0,n.jsx)(e.p,{children:"The AUC provides an aggregate measure of performance across all possible classification thresholds"}),"\n",(0,n.jsxs)(e.ul,{children:["\n",(0,n.jsx)(e.li,{children:"AUC helps us to choose between models when we don't know what decision threshold is going to be ultimately used"}),"\n",(0,n.jsx)(e.li,{children:"If we pick a random positive and a random negative, what't the probability my model scores them in the correct relative order?"}),"\n"]}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:"image",src:i(454300).Z+"",width:"359",height:"330"})}),"\n",(0,n.jsx)(e.h2,{id:"precision-recall-curve-pr-curve",children:"Precision-Recall Curve (PR Curve)"}),"\n",(0,n.jsx)(e.p,{children:"Precision-recall curves plot the positive predictive value (PPV, y-axis) against the true positive rate (TPR, x-axis). These quantities are defined as follows:"}),"\n",(0,n.jsx)(e.p,{children:"precision = \ud835\udc43\ud835\udc43\ud835\udc49 = \ud835\udc47\ud835\udc43 / (\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc43)"}),"\n",(0,n.jsx)(e.p,{children:"recall = TPR = TP / (TP+FN)"}),"\n",(0,n.jsxs)(e.p,{children:["Since precision-recall curves do not consider true negatives, they should only be used ",(0,n.jsx)(e.a,{href:"https://www.datascienceblog.net/post/machine-learning/specificity-vs-precision/",children:"when specificity is of no concern for the classifier"}),"."]}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://www.datascienceblog.net/post/machine-learning/interpreting-roc-curves-auc",children:"https://www.datascienceblog.net/post/machine-learning/interpreting-roc-curves-auc"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://www.datascienceblog.net/post/machine-learning/specificity-vs-precision",children:"https://www.datascienceblog.net/post/machine-learning/specificity-vs-precision"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification",children:"https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification"})}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.a,{href:"https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python",children:"https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python"})})]})}function d(A={}){const{wrapper:e}={...(0,t.a)(),...A.components};return e?(0,n.jsx)(e,{...A,children:(0,n.jsx)(l,{...A})}):l(A)}},153250:(A,e,i)=>{i.d(e,{Z:()=>n});const n=i.p+"assets/images/Confusion-Matrix-image1-d4f021bef8413c66b721b29e1d8de565.jpg"},627247:(A,e,i)=>{i.d(e,{Z:()=>n});const n=i.p+"assets/images/Confusion-Matrix-image2-2a48d933be9fee757ed6143d187f21b2.jpg"},1560:(A,e,i)=>{i.d(e,{Z:()=>n});const n=i.p+"assets/images/Confusion-Matrix-image3-0f92c1f5501b73be952bc036b4894f1a.jpg"},454300:(A,e,i)=>{i.d(e,{Z:()=>n});const n="data:image/jpeg;base64,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"},511151:(A,e,i)=>{i.d(e,{Z:()=>s,a:()=>r});var n=i(667294);const t={},a=n.createContext(t);function r(A){const e=n.useContext(a);return n.useMemo((function(){return"function"==typeof A?A(e):{...e,...A}}),[e,A])}function s(A){let e;return e=A.disableParentContext?"function"==typeof A.components?A.components(t):A.components||t:r(A.components),n.createElement(a.Provider,{value:e},A.children)}}}]);