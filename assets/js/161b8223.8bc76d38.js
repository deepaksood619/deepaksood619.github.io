"use strict";(self.webpackChunkdeep_notes=self.webpackChunkdeep_notes||[]).push([[71364],{925461:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>t,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>d});var s=i(785893),l=i(511151);const r={},t="Course - Big Data Computing - NPTEL",a={id:"courses/course-big-data-computing-nptel",title:"Course - Big Data Computing - NPTEL",description:"- Dr. Rajiv Mishra",source:"@site/docs/courses/course-big-data-computing-nptel.md",sourceDirName:"courses",slug:"/courses/course-big-data-computing-nptel",permalink:"/courses/course-big-data-computing-nptel",draft:!1,unlisted:!1,editUrl:"https://github.com/deepaksood619/deepaksood619.github.io/tree/master/docs/courses/course-big-data-computing-nptel.md",tags:[],version:"current",lastUpdatedAt:1734460808,formattedLastUpdatedAt:"Dec 17, 2024",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Course - Art and Science of ML",permalink:"/courses/course-art-and-science-of-ml"},next:{title:"Credit & Debt",permalink:"/courses/course-credit-risk-modeling/credit-and-debt"}},c={},d=[{value:"Syllabus",id:"syllabus",level:2}];function o(n){const e={h1:"h1",h2:"h2",li:"li",ol:"ol",ul:"ul",...(0,l.a)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.h1,{id:"course---big-data-computing---nptel",children:"Course - Big Data Computing - NPTEL"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Dr. Rajiv Mishra"}),"\n",(0,s.jsx)(e.li,{children:"CSE - IIT, Patna"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"syllabus",children:"Syllabus"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Week 1","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Introduction to Big Data"}),"\n",(0,s.jsx)(e.li,{children:"Big Data Enabling Technologies"}),"\n",(0,s.jsx)(e.li,{children:"Big Data Hadoop Stack"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Week 2","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"HDFS"}),"\n",(0,s.jsx)(e.li,{children:"Hadoop MapReduce 1.0"}),"\n",(0,s.jsx)(e.li,{children:"Hadoop MapReduce 2.0"}),"\n",(0,s.jsx)(e.li,{children:"MapReduce Examples"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Week 3","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Parallel Programming with Spark"}),"\n",(0,s.jsx)(e.li,{children:"Introduction to Spark"}),"\n",(0,s.jsx)(e.li,{children:"Spark Built-in Libraries"}),"\n",(0,s.jsx)(e.li,{children:"Design of Key-Value Stores"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Week 4","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Data Placement Strategies"}),"\n",(0,s.jsx)(e.li,{children:"CAP Theorem"}),"\n",(0,s.jsx)(e.li,{children:"Consistency Solutions"}),"\n",(0,s.jsx)(e.li,{children:"CQL (Cassandra Query Language)"}),"\n",(0,s.jsx)(e.li,{children:"Design of Zookeeper"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Week 5","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Design of HBase","\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"What is HBase?"}),"\n",(0,s.jsx)(e.li,{children:"HBase Architecture"}),"\n",(0,s.jsx)(e.li,{children:"HBase Components"}),"\n",(0,s.jsx)(e.li,{children:"Data model"}),"\n",(0,s.jsx)(e.li,{children:"HBase Storage Hierarchy"}),"\n",(0,s.jsx)(e.li,{children:"Cross-Datacenter Replication"}),"\n",(0,s.jsx)(e.li,{children:"Auto Sharding and Distribution"}),"\n",(0,s.jsx)(e.li,{children:"Bloom Filter and Fold, Store, and Shift"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.li,{children:"Spark Streaming and Sliding Window Analytics"}),"\n",(0,s.jsx)(e.li,{children:"Sliding Window Analytics"}),"\n",(0,s.jsx)(e.li,{children:"Introduction to Kafka"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Week 6","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Big Data Machine Learning 1","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Overview"}),"\n",(0,s.jsx)(e.li,{children:"Categories of ML Techniques"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.li,{children:"Big Data Machine Learning 2"}),"\n",(0,s.jsx)(e.li,{children:"Machine Learning Algorithm K-means using Map Reduce for Big Data Analytics"}),"\n",(0,s.jsx)(e.li,{children:"Parallel K-means using Map Reduce on Big Data Cluster Analysis"}),"\n",(0,s.jsx)(e.li,{children:"Decision Trees"}),"\n",(0,s.jsx)(e.li,{children:"Predictive Analytics 1"}),"\n",(0,s.jsx)(e.li,{children:"Predictive Analytics 2"}),"\n",(0,s.jsx)(e.li,{children:"Parameter Servers"}),"\n",(0,s.jsx)(e.li,{children:"Page Rank"}),"\n",(0,s.jsx)(e.li,{children:"Spark GraphX 1"}),"\n",(0,s.jsx)(e.li,{children:"Spark GraphX 2"}),"\n",(0,s.jsx)(e.li,{children:"Case Study"}),"\n"]}),"\n"]}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,l.a)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(o,{...n})}):o(n)}},511151:(n,e,i)=>{i.d(e,{Z:()=>a,a:()=>t});var s=i(667294);const l={},r=s.createContext(l);function t(n){const e=s.useContext(r);return s.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:t(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);